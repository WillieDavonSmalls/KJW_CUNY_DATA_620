Thread_Name,Initial_Post_or_Comment,Author,Response_To,Thread_Content
Google Ads,1,Vanita Thompson,Vanita Thompson,"Google Ads provides analytic reporting on how people use a website. Google Analytics tracks what people do after clicking an ad. It traces and provides information on how people found a particular website, and how the website was explored.  Using the information, a website owner can identify trends and generate ideas to enhance their website. For example, you can learn how much time is spent on a site, what items were browsed, and what items were placed in the cart. Those factors can provide leads on enhancing customers' experience, which in turn can help increase conversions like sales and return on ad spend."
Google Ads,2,Zachary Alexander,Vanita Thompson,"Hi Vanita -- I definitely agree that Google Ads provides a really good platform for analytical reporting and marketing. I used to work pretty closely with Google's suite of marketing tools and think they are really advanced in their ability to measure advertisement/marketing reach, as well as user and website activity! Google Analytics has continued to a leader on this front, and I'm curious to see if we talk much about this in our course!"
Marketing Analytics in Healthcare,1,Vijaya Cherukuri,Vijaya Cherukuri,"Marketing Analytics in Healthcare is used for Inbound and Outbound Marketing Metrics. This will help them in Building a Plan, Track results.

The business of healthcare is ruled by numbers – revenue, reimbursement and patient volumes .

These are some main KPI which will help them in driving the business.

1) Assist patients and families in navigating health care so they can make more informed decisions and access the care they need and deserve.

2) Grow referrals and admissions across the system.

3) Leverage cost efficiencies to increase ROI.

4) Increase qualified calls to the contact center."
Marketing Analytics in Healthcare,2,Abdellah Ait Elmouden,Vijaya Cherukuri,"Right. Data Analytics in the healthcare industry is changing the way patients and doctors handle care. The more data analytics involved, the more efficient healthcare can be."
Marketing Analytics in Healthcare,2,Murat Akyildirim,Vijaya Cherukuri,"With the expected increase in Virtual Care, I am curious what other KPI metrics will be added to an organization in terms of marketing analytics. Some of the metrics that comes into my mind

- time spend on session

- importance of web property metrics (acquisition , engagement and etc...) 

- purchase funnel analysis (drop offs and etc...) "
Marketing Analytics in Healthcare,2,Jeremy O'Brien,Vijaya Cherukuri,"If I'm not mistaken, one of the goals of Obamacare was outcome-based payments to healthcare providers.  I'm not clear on where healthcare policy currently stands (it's difficult to keep up with the tumult of the current administration), but if patient outcomes and population health remain part of compensation for healthcare systems then I imagine they should be reflected in some way in marketing analytics."
Online Food Ordering,1,Priya Shaji,Priya Shaji,"Food ordering business has a need to gain a better insight into the life cycles of its customers while gaining the ability to optimize sales reports and marketing campaigns in a time-efficient, cost-saving, and autonomous way.

By gaining self-service access to real-time analytical information the company was able to streamline its marketing and sales activities, make better, swifter decisions based on real-time information.

The use of a real-time dashboard has empowered many budding online food giant to monitor all significant business operations through customized KPIs.  With the help of sales, graphs and charts the data is easily interacted with, and presented on a single screen.

Therefore marketing analytics demonstrates how quickly the power of business intelligence affects the decision-making processes and creates a backbone for sustainable growth."
Online Food Ordering,2,Ken Popkin,Priya Shaji,"Good choice for this topic, Priya.  I used to work for a company called Gordon Food Service (GFS).  We distributed food to restaurants and one of our objectives was to get our customers to use more online tools, including analytics.  The online food ordering places like you mention are very open to analytics, but a lot of the older food establishments (Mom & Pop type restaurants) tend to be reluctant.

It will be interesting to see with all the recent changes due to Covid if the Mom & Pop type restaurants that I just mentioned can survive if they remain resistant to using analytics.  "
Online Food Ordering,2,Priya Shaji,Ken Popkin,"Yes, that's a good point Ken. Familiarity with online tools and analytics will be pretty useful for restaurants and shops during covid. "
Cambridge Analytica,1,Mikhail Kollontai,Mikhail Kollontai,"The Cambridge Analytica scandal is one of the most visible recent cases of data analytics being used for nefarious purposes. This British firm exploited the lack of robust privacy internet laws to collect personal information on millions of users (with the support of Facebook).

The goal of this mass data grab was to identify candidates susceptible to political advertising aimed to influence voting patterns. It identified correlations between users' posts, likes, groups, etc.  and their political leanings. By using these correlations it could identify users (or areas where such users could be found) to identify populations who's vote could be won. It then sold this information to various political campaigns, allowing them to aim their focus on people most likely to be swayed by their message. 

In terms of concrete metrics, we need only look at the 2016 election to find the fruits of this labor. Though it did identify the gaping holes in internet privacy laws controlling social media platforms, it also fed a valuable debate on the extent to which data analytics can be used within politics and the morality of this practice. 

"
Cambridge Analytica,2,Elina Azrilyan,Mikhail Kollontai,Great example of data used for political reasons and you bring up a good point of ethical implications of Data Analytics and issues with privacy.
Cambridge Analytica,2,Sheryl Piechocki,Mikhail Kollontai,"Great example Mikhail.  The analytics used here was able to find very specific target areas that would provide the most bang for their buck.  By focusing the campaign in mainly these areas, the campaign funds were able to be used where they would give the most value."
General Electric,1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"GE use marketing analytics to track country of origin for their site users. This can provide GE with a rich insight into where market demands are arising and how to better cater their web pages to different languages and cultures. GM also is implementing a site analytics tool across its dealer network. The tool uses Esri ArcGIS technology to combine US Census tract data with demographic-based consumer profiles, available through the ArcGIS platform.

Reference : https://www.esri.com/en-us/arcgis/products/spatial-analytics-data-science/gm"
General Electric,2,Jagdish Chhabria,Abdellah Ait Elmouden,"That's interesting, Abdellah. Using Census Data long with geo-location tracking seems pretty sophisticated. I'm new to this so not sure if this is common practice by now. But it sounds like it's aimed at giving dealers an insight into the potential customer's demographics and either make targeted marketing efforts or know more about their needs even before when they walk into the dealer's center."
Big Data Packages for Marketing Analytics,1,Ken Popkin,Ken Popkin,"The tech companies we most often hear about like Facebook, Google, and Twitter have had large in-house teams of data analysts and data scientists for a number of years.  Now that word is out on the success these companies have had many other companies are striving to achieve similar results.  The article at this link shares success stories that a number of companies have had using big data marketing analytics packages.  Here's a few examples...

1. A large coffee company partnered with a marketing analytics company called 4C to target audiences via the use of emojis.  The result was more than 800,000 impressions on Twitter and a 260% jump in engagement.

2. The Boston Globe partnered with Blueconic's customer data platform and by applying their metrics & reports experienced results of a more engaged audience, more subscribers, and more advertising revenue.

In total the above link covers 20 big data companies and the impact their tools & reports have had on a number of companies (some of whom are household names)."
Big Data Packages for Marketing Analytics,2,Priya Shaji,Ken Popkin,Example of coffee company reaching thousands of people by use of emojis and analytics is a good example for this topic!
Big Data Packages for Marketing Analytics,2,Mikhail Kollontai,Ken Popkin,"I'd love to see what the 800,000 impressions and 260% jump in engagement equates to in terms of sales numbers!"
Big Data Packages for Marketing Analytics,2,Steven Ellingson,Mikhail Kollontai,"Agreed on that.  Marketing folks like to talk about impressions, etc. but I want to know about the sales.  How would you go about measuring that?  You could look for an increase in sales over time, but how can you say for sure the marketing is causing the increase?"
Big Data Packages for Marketing Analytics,2,Mikhail Kollontai,Steven Ellingson,"I think that's a fascinating side of marketing - you can never truly be sure what aspect of a marketing campaign (if any) is the cause of a rise in sales. One way would be to offer certain offers alongside the ""emoji"" marketing efforts - this would at least create a clear subset of sales that were directly cause byt he marketing ploy. "
Heap and Casper,1,Jit Seneviratne,Jit Seneviratne,"This post is how an product analytics firm (Heap)  helped the mattress firm Casper revamp their analytics and improve conversion rates. I’m citing this article: https://heap.io/customer-stories/casper

Casper Marketing Analytics:

Prior to Heap, Casper had been focused on increasing customer volume. Once their sales numbers became huge, revenue became very sensitive to changes in marketing and services, and they needed help on marketing decisions. Heap helped them understand much more than sales. Heap helped them understand customer behavior. 

One way Heap achieved this was conducting A/B testing on the visibility of different offerings (such as courier delivery). Heap found that customers engage with the shipping information on Casper’s web interface to a high degree, and that the vast majority of customers use courier delivery. Casper changed their web page indicate availability of the courier option earlier in the checkout process and watched for improvements in conversion rates. 

While the article does not indicate how the A/B test was be carried out, a z-test of on the difference in proportions / conversion rates (pre and post initiative) is an example. The result of all this is that Heap helped Casper increase checkout conversion by 20%.

Heap also helped create more robust infrastructure by consolidating their ETL pipeline into one place using Amazon Redshift.

"
Heap and Casper,2,Jeremy O'Brien,Jit Seneviratne,"Neat example!  For anyone keen to learn about the application of A/B/n testing in marketing, here's a decent article Multi-Armed Bandits and balancing exploration and exploitation!"
Food Delivery in Sports Stadiums,1,Mael Illien,Mael Illien,"A friend of mine is developing a mobile app designed to improve food service in sports venues. The idea is that you shouldn't miss parts of sports event you paid for while waiting in line for a beverage. The app connects you to a food vendor who will dispatch someone to bring your purchase to your seat.

The marketing goals are clearly to expand to all kinds of sports and venues and analytic measures can help to facilitate that. Some performance metrics beyond the obvious number of times the app was downloaded include: frequency of use by the same user, number of recommendations to other users (via share links), @ or # mentions on social media platforms. With limited initial capital, the company can use analytics like the ones just described can help focus the development path by responding to these metrics and expanding accordingly."
Food Delivery in Sports Stadiums,2,Amber Ferger,Mael Illien,"This is a really interesting idea for an app! I think one of the most understated marketing strategies is providing a share link. I've seen this become an ever more present component of so many companies. By allowing a user to share their link and receive some sort of incentive, the company reaches a larger customer base for a smaller amount of money!"
Marketing Analytics - Case Study from Digital Marketing Experience,1,Zachary Alexander,Zachary Alexander,"I used to work for a digital marketing company that worked closely with brands to help push their marketing reach on digital platforms. One company I worked with in particular was a small clothing/retail company that was trying to increase their brand awareness and customer base.

In our initial meetings with company stakeholders, we first thought through and determined their current client base, and identified the types of customers that buy their clothing. We then set up marketing goals to target these individuals on online platforms. We purposely didn't create too much of a strategy over the first few months, in order to gather data and information on those that were navigating their website and digital platforms. By setting up events on certain components of their website (i.e. buttons/pages), we then could track user activity throughout their site. We also set up a robust marketing campaign to expand their reach on search engines and social media platforms like Google, Facebook, etc. Once we were able to pull in a fair amount of data, we looked at things like ""click-through-rate"" (how many times people search and then click on an advertisement for the brand), as well as time spent on website pages and product pages. We also looked how people landed on their website, was it through social media platforms? Directly searching on search engines? We then became more specific with our targeting, and did our best to funnel users on their website to ""convert"" on certain products. For instance, based on user activity, if someone had items in their shopping cart but didn't click the ""buy"" button, we could then use a ""re-marketing"" campaign to show ads to this individual on other sites and social media to remind them that they had these items in their cart. Over time, we could then track the success of these campaigns and tweak the strategy based on which practices seemed to be most effective. KPIs such as click-through-rate, impressions, and page rank were important for digital ads, and then events on the website such as button clicks, shopping cart items, etc. were important indicators as well.

Full disclosure, I only worked at this company for 10 months because I felt like the technology was becoming too creepy, but for brands and companies trying to expand their reach and sales, these tactics proved to be very effective."
Marketing Analytics - Case Study from Digital Marketing Experience,2,Murat Akyildirim,Zachary Alexander,It sounds like we work in a similar field. I think Marketing Analytics created (specially in the digital area) new business models. For example ; there are companies out there with sole purpose to become major referrals for certain products. (Example: Compare credit cards and sign up) They create web properties to become referral to organizations and further partner with them with certain annual service fees. 
Marketing Analytics - Case Study from Digital Marketing Experience,2,Sheryl Piechocki,Zachary Alexander,"Thanks for that example Zachary!

Most people don't understand how much they are being tracked through their on-line activity.  It definitely works for these companies to use this data to increase sales."
Marketing Analytics - Case Study from Digital Marketing Experience,2,Jeremy O'Brien,Zachary Alexander,"Interesting case study, Zachary.  Sounds like your client was using a mix of first party tracking (finding people who their own websites at a recent point in the past) and third party tracking (social media platforms or non-owned-and-operated web properties). 

Those who find online targeting creepy may be relieved to hear that Google (which has majority browser share in the US) will be deprecating third-party cookies for use in retargeting, attribution, and other digital marketing techniques come 2022.  Marketers will still be able to remarket to visitors of their own sites, but data brokers that hoover up credit histories or model lookalikes based on browsing behavior will have an almost impossible time selling 'segments' for programmatic advertising.

Google is still working with the world-wide web consortium (W3C) and ad tech community to align on what use cases and technologies it will support following the removal of third-party cookies, but for those interested a number of approaches are being discussed here."
Data Analytics in Marketing Strategies,1,Elina Azrilyan,Elina Azrilyan,"There are a variety of ways in which Marketing can benefit from such Data Analytics tools as network analysis and text mining. I will discuss just a few of them. Personalizing customer interactions can be very beneficial for establishing a relationship with a customer and increasing profits. Network Analysis and Text Mining can help determine what preferences and needs your customer has. Key performance indicators for this could be the percentage of return customers and website clicks and sales based on marketing communications. Marketing can also benefit from monitoring the reputation their product has on social media as it has a become a significant customer research tool. Key performance indicators for this could be profits as a function of positive social media presence. 

Sources: https://martechseries.com/analytics/audience-data/the-importance-of-data-analytics-in-marketing-strategies/"
Marketing Analytics for Insurance company,1,Subhalaxmi Rout,Subhalaxmi Rout,"Insurance is an industry that is heavily dependent on the accuracy of predicting risk. The correct assessment of risk determines the policy premium that’s payable by the insured, upon which the insurer’s losses or gains are dependent. Insurance helps to protect the customer from a potential loss, and to predict the likelihood of that loss, or claim, occurring.

With the help of analytics, an insurance company can reach to potential customers. Identifying, attracting, and retaining high-quality policyholders is a challenge that insurers across the industry face. To solve this, insurers must amass and utilize highly predictive, insurance-specific intelligence while prospecting. 

KPI for potential customers:

Source of Traffic – Identify the sources from where users come to the insurer’s website, for example – from google or banner ads.

Unique Page Visits – How many new visitors are coming each month, this gives an idea of how many visitors keep coming back for more, and how many new visitors are landing?

Social Media Engagement – Are consumers liking, commenting, and sharing the insurer's social media posts?

Bounce Rate – This metric measures the percentage of visitors to the insurer's website who navigate away from the site after viewing only one page.

Conversion Rates – This metric measures the percentage of people who take the desired action, such as fill out a lead generation form to download an offer from insurers.

 

Reference:

https://blog.hultmarketing.com/insurance-marketing/marketing-metrics-insurance-tracking"
Lending,1,Steven Ellingson,Steven Ellingson,"My company helps to service loans.  We use google analytics to help track how someone ended up on our website and to try to give attribution for a new or returning customer.


These things are always challenging, as marketing often won't directly lead to a sale, but it could keep the brand in mind for a later date.


I personally like split testing whenever possible.  Instead of just tracking after the fact, give different groups different treatments and see how they perform. This obviously isn't always feasible, I don't believe you can split test something like Google Adwords, and so tracking attribution is important in those cases."
Marketing Analytics,1,Murat Akyildirim,Murat Akyildirim,"Organization: Healthcare Product Owner. Organization has variety of web properties to connect with their consumers and give them an opportunity to purchase their products online and offline.

Marketing team has a certain budget they need to allocate within certain marketing channels. Their objective is to ensure the marketing budget is distributed to get the most consumer acquisition and conversion. High level KPI’s defined for the marketing team are User Acquisition, Engagement with marketing Assets and Conversion. Below are some examples;

For Content and Brand Web Properties:

Landing WebPage Acquisition (Top Landing Pages that users land on)
Channel Acquisition (What channels drives the users to the web property)
Campaign Acquisition (What campaigns drives the users to the web property)
Bounce Rate, Avg. Time on a Page, Time Spent on the Site and etc.. (For content consumption)
Search Behavior Analysis (trending keywords and content types in Social Media, Search engines and etc…)
For eCommerce Brand Property:

Channel Acquisition (What channels drives the users to the web property-Organic Search, Referrals, Adds(display, paid social and etc…)
Campaign Acquisition (What campaigns drives the users to the web property)
Shopper and Order Conversion (Shopper is when user lands on the purchase funnel and order is when user completes the transaction)
Search Behavior Analysis (trending keywords and content types in Social Media, Search engines and etc…)
For Lead Generation Property

Channel Acquisition (What channels drives the users to the web property)
Campaign Acquisition (What campaigns drives the users to the web property)
Submission and Completion Rates( When users completes their form completion)
Social Media Property

Campaign traffic, click through rate, cost per click and etc…
Creative traffic, click through rate, cost per click and etc..
Offer click through rate, cost per click and etc…
Offline Sales Data

Sales Trend on DoD, YOY, MOM basis
Campaign, offer sales, monthly revenue (if the product is subscription based).
Sentiment Analysis

Market Research (twitter, amazon reviews and etc..) to help with marketing creative and offers.
Social Media or Reviews Acquisition to the organization property and shopper and order conversion.
Analyzing Relationship between Marketing Assets

Consumer Journey between online and offline marketing assets
How do the organization acquire (which marketing assets) the consumers most?
How do they convert (consumer purchase -which marketing assets) the consumer most?
Relationship between online and offline marketing campaigns and assets.
Based on my experience, the challenging part is to compare and analyze web property collected data, offline data and data collected and stored via various platforms in organization’s database. There are always discrepancies between the platforms and the idea is to ensure the variance between them is acceptable. I have recently started leveraging external Platform APIs(GA, Adobe)  and internal databases in order to collect user web property engagement data. My goal is to bring the analysis on an individual level which seems difficult but with certain assumptions I believe it is possible.

If there are any suggestions around a workflow for collecting online data and creating data pipelines (merging them in cloud - Bigquery etc... ) for automated analysis, please share."
Cross Selling,1,Sheryl Piechocki,Sheryl Piechocki,"I work at a major health insurance company.  While our main product is medical insurance, we also offer dental, vision, and life insurance products.

One major marketing goal is to increase cross selling to existing customers.  The goal is to get existing medical customers to also buy another product we offer, whether that be dental, vision, or life (or all 3).  We also have customers that just have our dental or vision or life product and we would like to entice them to also purchase our medical insurance product.  Campaigns are created to offer customers discounts for bundling products.  Existing customer data is analyzed to decipher which types of customers are more likely to have multiple products.  Customer profiles are created.  Then customers with only one product are compared to the customer profiles to determine what additional products should be marketed to them.

The campaign measures used are:

Percentage of customers with only one insurance product
Percentage of customers with more than one insurance product
Looking at these measures over time, we can see if cross selling is increasing and which campaigns are successful"
Cross Selling,2,Jit Seneviratne,Sheryl Piechocki,"This reminds me of recommender systems, where we can recommend products to customers based on purchases by other customers with similar buying patterns. Cosine similarity is one approach which comes to mind. Another is alternating least squares (ALS)."
Amazon & Recommendation Systems,1,Amber Ferger,Amber Ferger,"We all know Amazon - the online retail giant that allows users to purchase anything they can think of with the click of a button. Amazon distinguishes itself from other retailers with its customer-centric model that relies on a digital marketing strategy. 

The company's sales outline a highly successful marketing strategy -- In 2019, Amazon reported $87.4 billion in revenue and in quarter 1 of 2020, they reported $75.5 billion. Their success lies in the fact that users keep coming back. The average prime member spends $1400 per year on Amazon purchases versus non-prime at $600 (Statistica source). What's even more impressive is their ad revenue -- Amazon boasts an average revenue of $15 per user from advertising. (Source)

These numbers are a result of a simple goal: make customers happy. According to John Dudovskiy, Amazon's marketing strategy is composed of four essential elements: (1) offer a large variety of products, (2) provide a user-friendly gui, (3) scale rapidly and seamlessly, and (4) market new products. (Source) This strategy is made possible in large part because of the trove of data they possess -- every page view, every purchase, and every product review is recorded and tracked. Data is aggregated and analyzed to uncover market trends, identify successful (and unsuccessful) products, and understand consumer preferences. From a consumer standpoint, this digital feedback can improve user experience by providing more accurate recommendations. Some metrics on the consumer side include: frequency of purchases, average product review, average spending, and number of repeat purchases. From a logistical standpoint, the data can be used to identify bottlenecks and improve operational metrics. Metrics on the logistical side include: delivery time, purchases per product, warehouse costs, delivery costs, and packaging time.

It really is a win-win situation. Amazon profits from your data, and you end up a happy customer with products delivered in a quick and efficient manner. 

"
Amazon & Recommendation Systems,2,Mael Illien,Amber Ferger,"The wealth of data Amazon can access is enormous. Between product ratings, comments, ratings on comments, there are so many ways to translate customer behavior into metrics. I'd be curious to know how their advertising strategy differs based on customer profiles like for example a heavy shopper vs a visitor who does not make purchases often. Overall it's clear the system is a very efficient and a success as they have plenty of data to train on!"
Amazon & Recommendation Systems,2,Subhalaxmi Rout,Amber Ferger,"Interesting post Amber, on Amazon’s recommendation system. This helps Amazon as well as customers to reach their goals. For each product Amazon provides “What other items do customers buy after viewing this item” – This is based on market basket analysis which products that are bought together. Achieving customer loyalty and repeat purchases has been key to Amazon’s success. To achieve this Amazon added some features such as Lower Priced Items to Consider, Compare with similar items, Customer questions & answers, customer reviews, and customer images. This way customers build more trust in Amazon."
Amazon & Recommendation Systems,2,Jack Russo,Amber Ferger,"Tying this into NLP CH 1. 

Amzon has access to vast amounts of data about not just what people are buying/reviewing but how people are buying and reviewing. For example how certain reviewers use different words in the products is as important what to recommend as number of stars in the review."
Uber,1,Jeremy O'Brien,Jeremy O'Brien,"Thought Uber could be an interesting example (and one I know a little about from a previous role).  Uber seeks to strike a balance between supply and demand for the services (ride shares, scooter shares, food delivery, etc.) it offers in each metropolitan area in which the company operates.  It competes with companies like Lyft and Postmates.

Key for Uber to strike that balance is to acquire an install base of drivers and delivery people that provide services and ride requests and food orders making use of those services.  With a balanced base, at any given time Uber's yield and promotional algorithms can adjust pricing to 1) attract enough drivers or discourage excess drivers in order to meet current demand, or 2) attract users from competitors or substitutes (i.e. public transportation) to utilize current supply.

As an app, Uber’s install base, monthly and daily active users are key to business success.  From a marketing standpoint, these translate to KPIs like new installs by local market and ride / order volume by market.  Not all riders, drivers, and food orderers are created equal, and attracting potential new users who use more services – or more valuable services – is important to Uber reaching profitability.  Metrics like estimated lifetime value of new users are important to ensuring that marketing tactics are correctly targeted and cost-efficient.  And building brand preference (over competitors and substitutes) improves the elasticity of all the preceding metrics, acting as a force multiplier for the KPIs above."
Marketing analytics in public sector,1,Habib Khan,Habib Khan,"Hello,

I have been working with New York City as a data analyst. Like all profit organizations, government sector has also some defined objective which is to serve public. As a public servant, our aim is to provide the public the most of our services depending on the department. In Department of Citywide Administrative Services, one of our objectives is to conduct on-time civil service exams and to engage especially minorities living in NYC. For that we get the data in terms of reviews, could be from facebook, etc. Most of times, general public don't know about the openings in public sector and thus most of the hirings are done within City employees. The marketing goals could be to spread the information about civil service exams and openings. I belive we can use web analytics in this perspective and try to find out which communities are not involved in city hirings and thus change strategies accordingly. As we will proceed further and we will learn more techniques, I will be more sure about the practical applications of marketing analytics in public sector.

Thanks,

Habib Khan"
Social network media platforms,1,Simon Ustoyev,Simon Ustoyev,"Not surprisingly,  by now, a lot of companies, from tech giants down to startups, are looking to capitalize on offering  data analytics as a service or a platform.  In this article from Springer (https://www.wired.com/story/instagram-business-accounts-analytics/), back in July 2014, the section, ""Social network media platforms"" gives a good glimpse of the companies and their services which allow other commercial companies have the power of network analysis and text mining in driving forward their marketing and business goals.  Among notable platforms that handle sentiment and semantic analysis of Web include Google Analytics, HP Autonomy IDOL (Intelligent Data Operating Layer), IBM SPSS Modeler, Adobe SocialAnalytics and many others.  Thomson Reuters and Bloomberg are incorporating Twitter sentiment analysis and visualizations into trading platforms for financial companies.

One company which caught my attention is iSpot.tv,  ""…which launched its own social media analytics platform that matches television ads with mentions on Twitter and Facebook. It provides real-time reports about when and where an ad appears, together with what people are saying about it on social networks (iSpot.tv monitors almost 80 different networks).""

It is not difficult to imagine a use case where the marketing department of a company can adjust or target where it wants to air more TV ads, by combining the sentiment of people's reactions to the ads with network analysis of  people's demographics."
Social network media platforms,2,Mia Chen,Simon Ustoyev,"This reminds me of the time I worked with data management platforms (Salesforce, Amobee and Adobe Audience Manager) where we created segmentations based on audience demographics and frequency caps. By comparing the engagement rates and sales attributions among different segmentations, we could better understand where and whom the media dollars should be spending towards when we plan the next campaign."
Social network media platforms,2,Willie Smalls,Simon Ustoyev,Wow.  iSpot.tv sounds like it will increase the efficacy of organizations ad spend. 
Harlem Coffee Company,1,Willie Smalls,Willie Smalls,"Harlem Coffee Company is a local, independent, and third wave coffee company started in Harlem, NYC with the slogan deep, rich, smoothe.  The organization’s intent is to tap into Harlem’s growing upwardly mobile and socially conscious clientele.  It is strategically positioned next to the 116th 2 and 3 train stop to take advantage of foot traffic.  

 

The company uses much of its marketing spend to increase foot traffic into the coffee shop and grow customer loyalty.  For key performance indicators, Harlem Coffee company focuses on revenue growth, customer turnover, new customer growth, spend per customer, staff turnover, and expense reduction. 

 

To grow its digital footprint and increase local, national, and international exposure, the organization forced its WiFi users to follow them on Instagram and it also partnered with Yelp for SEO (search engine optimization).  Harlem is a favorite amongst European visitors.  Harlem Coffee Company paid significant attention to its follower based growth, engagement of users, and re-grams.  Owners indicated that as its digital footprint grew, so did its customer base.  

 

Harlem Coffee Company used loyalty cards to track retention, customer loyalty, average monthly revenue per user, spending, and other customer habits, e.g., items purchase, time of day visits, etc.  

 

Because Harlem Coffee Company prides itself on being a triple bottom line organization, the organization focused a lot on reinvesting back into the community by supporting other local organizations, such as donating hot chocolate to the Marcus Garvey Christmas party in Harlem and hosting open mic night.  The organization would always track sales seven days after an event to see if there was an uptick.  One of the more profitable initiatives was it’s support of local artists, which often drew a significant amount of number customers.   "
Harlem Coffee Company,2,Jagdish Chhabria,Willie Smalls,"It's interesting that even single channel businesses like Harlem Coffee Company are so media-savvy and using different tools to market their products. Based on what you said in your post (single address), my assumption is that this is not a chain of coffee stores, but a single outlet (Mom & Pop shop?). If that is indeed true, then it's commendable that they are so marketing savvy."
Harlem Coffee Company,2,Willie Smalls,Jagdish Chhabria,"Yes, it is a single shop.  The owner is a pretty brilliant guy.  His dream was to open a restaurant and his mentors told him to first start at a coffee shop.  He studied a lot of marketing in college.  "
Mercedes social media campaign,1,Jagdish Chhabria,Jagdish Chhabria,"Mercedes is a world-class brand with tremendous recognition. However, I suspect that perhaps the brand awareness and following is likely higher amongst older adults with a higher income, and not as much amongst the younger generations that are starting their careers. It seems back in 2013, Mercedes wanted to increase its brand awareness amongst the younger audience so it ran this very successful campaign on Instagram. It hired five top Instagram photographers to each take the wheel of a new Mercedes CLA. Whoever got the most likes got to keep the car – so they all really worked at it!  By the end of the campaign, Mercedes had received:

87,000,000 organic Instagram impressions
2,000,000 Instagram likes
150 new marketing assets (stunning photos)
You can find more details here: https://ostmarketing.com/5-outstanding-social-media-marketing-case-studies/

In general, the main KPIs for social media marketing seem to be:

1) Impressions (or Reach): Number of unique visitors to social media property.

2) Engagement: Amount of time spent on social media property and actions such as liking or sharing or forwarding.

3) Leads or Clicks: Number of clicks resulting in generation of leads.

4) Sentiment: Whether positive or negative and intensity of sentiment.

5) Share of voice: Proportion of customer engagement for a group of competing brands."
Campaign Performance Reporting,1,Mia Chen,Mia Chen,"My team at UM (a media agency) analyzes digital and social data to report and make recommendations to help clients achieve their marketing goals. Some of the KPIs we use to measure the campaigns are CTR (click through rate), CPC (cost per click), VCR (video completion rate), Reach and Frequency, CPLPV (cost per landing page view), LPVR (landing page view rate) and etc. KPIs varied by funnels and campaigns - awareness campaigns' primary KPIs are impressions and views, while consideration campaigns' KPIs are more about cost efficiencies and engagement rates. By comparing the KPI performances between different target audiences, ads, and platforms, we can understand which audience is resonating with which ad, then make optimizations to shift more budgets toward well-performing groups while limiting spend towards under-performing ones. "
Campaign Performance Reporting,2,Simon Ustoyev,Mia Chen,That's pretty cool and it looks like that you'll directly benefit from this course. I think that network analysis and text mining will greatly add value in addition to the KPIs that you already use.
Personal Experience - Politics,1,Jack Russo,Jack Russo,"I once worked for an organization that measured how likely voters were to vote in an election when targeted with an add about an issue they cared about, or I should say were predicted to care about. We used predictive modeling to extrapolate data we had (likes flyfishing and school vouchers) to voter for which we only had one piece of the puzzle (likes flyfishing). I can only speculate but access to voter's SN data may have been a more direct way to measure which voters cared about what. "
Personal Experience - Politics,2,Habib Khan,Jack Russo,I am still not sure how else we can use these techniques in different sectors. Thanks for sharing your aspect.
"Going back to 3,000 BC",1,Ken Popkin,Ken Popkin,"My perspective on technology advances and job loss is that articles like the one for this discussion focus on what skills technology takes over, but don't focus enough on the increased complexity (in other words - increased opportunity) that advances provide.

If I could go back to 3,000 BC, I'd bring along some pictures of all the modern equipment we have for building.  I'm fairly confident that the construction workers (builders of caves and tents) that I'd talk to would be in awe of all the cool equipment --  they'd see one guy driving a bull dozer, another in a huge dump truck fully loaded.  But then I envision some of them getting depressed - concluding that with equipment like this you don't need many people to build a cave - they'd worry that their descendants won't have jobs.

But then I'd show them pictures of skyscrapers, large cities, huge factories.  And explain that there are actually more jobs because as the technology got better, the complexity became greater, and along with it came greater opportunity.

Carrying this analogy forward to AI in 2020, my take is that machine learning, robotic process automation, and application of these and similar technologies is going to continue to increase, not decrease the number of jobs.  To me the question we ask should be, ""how do we keep everyone learning new skills?"", but that is a conversation for another Discussion Topic."
"Going back to 3,000 BC",2,Jack Russo,Ken Popkin,"My take on this depend on how ownership of tech is distributed.  If I own a law firm and am able to cut my workforce due to the acquisition of textual analysis software, that's a benefit to me but not necessarily everyone. Sure it means better, faster, cheaper stuff for those with an income stream but not for the unemployed. "
"Going back to 3,000 BC",2,Mikhail Kollontai,Ken Popkin,"I have largely shared your view but I do find myself wondering. I think your last point hits the nail on the head - getting people to keep up with the growth is what needs to be the focus. The problem here though is that the speed with which technology is evolving. I think the point from Colvin's article that really resonated with me was the fact that Watson was already  240% faster than he had been 2 years previously. Humans can't possibly be expected to learn that quickly (without outside help, CRISPR being a potential avenue here).

With each year the effort required to transition to the new in-demand career increases. I think the concern may be that some newer careers that emerge thanks to this technological revolution will be unattainable by those whose careers are eliminated."
Text Mining Pharmaceutical Data,1,Sheryl Piechocki,Sheryl Piechocki,"Recently, BenevolentAI was able to identify a potential pharmaceutical to aid in the fight against COVID-19.  They combed through a vast digital storehouse of biomedical data to identify drugs already approved for other conditions that correlated with protein targets affected by the SARS-COV-2 virus.  All of this was done in just a few days time.  

This is not a case that will necessarily eliminate jobs, but it allows new discoveries that would not previously have been possible.  

https://www.the-scientist.com/news-opinion/ai-is-screening-billions-of-molecules-for-coronavirus-treatments-67520"
Text Mining Pharmaceutical Data,2,Steven Ellingson,Sheryl Piechocki,"Thank you for sharing Sheryl that is very interesting!  I wish I could find out more about the datasets that they are using.  I love the idea of ""drug repurposing"" as it's been so valuable to medicine so far (I/e retrovirus cancer medication used to treat AIDS) and most of the repurposing has been ""accidental"" at best. Using a targeted to try to identify these could lead to a lot of new effective medications that have already been tested and are widely available."
Process automation,1,Priya Shaji,Priya Shaji,"According to a study by Harvard business review on “Artificial Intelligence in real world” : RPA(Robotic Process Automation ) is the least expensive and easiest to implement of the cognitive technologies , and typically brings a quick and high return on investment. 

At NASA, cost pressures led the agency to launch four RPA pilots in accounts payable and receivable, IT spending, and human resources all managed by a shared services center. The four projects worked well in the HR application, for example, 86% of transactions were completed without human intervention and are being rolled out across the organization. NASA is now implementing more RPA bots, some with higher levels of intelligence.


As technology improves, robotic automation projects are likely to lead to some job losses in the future,


https://hbr.org/2018/01/artificial-intelligence-for-the-real-world"
Process automation,2,Vijaya Cherukuri,Priya Shaji,"Yes Priya, I agree with you.

RPA can be greatly benefitial but at the same time it might lead to job loss. IT is mainly focussing on RPA process for many shared services for transitions, trainings, call center etc.

There are high chances that AI can change the face of the world in future."
Hiring decisions by companies using text mining,1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"As technological advances accelerate and compound they might eliminate jobs.  As an example for  over  two  decades  information  retrieval  systems have  been  used  by  human  re-sources (HR) departments and external headhunting services to filter and sort candi-dates based on a set of weighted features gathered from the cover letters and résumés or curriculum vitae (CVs).  HR is now the prime candidate for adoption of NPL-based technology as HR inherently people centric and communication based. These  new retrieval systems combine the tasks of natural language processing (NLP), data and text mining technology will reduce human bias in decision- making application. example include resume scoring and survey analysis. More recently, systems have employed artificial  intelligence  (AI)  to  identify  which  candidates  are  likely  to  accept  the  job offer.

Reference : http://ceur-ws.org/Vol-2169/paper-03.pdf"
Hiring decisions by companies using text mining,2,Ken Popkin,Abdellah Ait Elmouden,"I agree that NLP has great potential for HR departments, but to me they've gone overboard on their dependency on this technology.  I know some great candidates that fall thru the cracks and unfortunately still see some ""not so great"" candidates moved forward in the hiring process."
Hiring decisions by companies using text mining,2,Zachary Alexander,Abdellah Ait Elmouden,"Thanks for sharing this! I also wrote a bit about advances in technology and software to support recruitment efforts. I do worry though that there could be too much dependency on NLP and algorithms to sort through resumes and candidates in the future -- although many of these tools have good intentions (i.e. reducing human bias, etc.), there's still a lot of room for unintended consequences to creep into the system. For instance, the engineers developing these technologies could unintentionally be inserting bias in their scoring system or the algorithms they write, or NLP processing on certain words or phrases could limit resumes based on particular languages or skillsets, which in a way could be its own form of bias. It will be interesting to see what the trajectory of this type of technology takes in the future, and if it'll become more of the standard practice for hiring!"
Call Center,1,Steven Ellingson,Steven Ellingson,"More and more, when you're on a website they will be trying to hide their phone number and get you to chat.  Call center jobs have steadily been moving offshore to save costs, and now companies are attempting to replace much of the client interactions with a chatbot.

Currently most of these are only really good at answering simple, common questions.  What is my balance?  When is my next payment due?  But as time goes on the idea will be to answer more and more subtle questions. 

Not only questions, but sales as well. Sales is all about overcoming objections, and describing value. Not only can an AI be trained for this purpose, it can be fine-tuned to the most effective strategies in a way that you could never do with a sales staff."
Call Center,2,Amber Ferger,Steven Ellingson,"This is a really interesting example of AI replacing humans. It seems like more and more companies are choosing to use automated messaging systems to route user calls to the appropriate area within the company, and you're absolutely right that the performance is very limited to a standard set of functions. I imagine that audio calls are typically recorded, converted to text, and analyzed for key topics -- it would make sense that this information is incorporated into the messaging systems to increase comprehension of the machines. However, I can't help but get annoyed whenever I call and hear a bot: they're slower at understanding what I need and often make me go through hoops and hurdles to find out what I really want. I wonder how long it will take for the technology to become less robotic, more humanistic, and ultimately more personable. "
Call Center,2,Vanita Thompson,Steven Ellingson,"I worked in call centers after HS. It is interesting to see how big data technologies are changing the industry. Through use of automated systems, companies have dramatically downsized their staff."
Call Center,2,Willie Smalls,Steven Ellingson,"JetBlack, now defunct, or absorbed into Wall-Mart's Jet used chat bots to act as a concierge service for ""mommagers,"" or upscale NYCers.  So, a user would text say ""Jenny I need a gift for a 5-year old Boy"".  The chat bot replies with 5 options.  The user can approve the option or ask for additional options. The option is delivered to the individuals specified addresse.  "
Call Center,2,Sheryl Piechocki,Steven Ellingson,"My own company has instituted these chat bots on their website.  It pops up to ask if it can help you.  You can then answer yes or say no thanks.  The annoying part is that if you say no, but are still on the website after some period of time, it pops up again with the same question.  I suppose it thinks you must need help since you are still on the same page or haven't done any action.  "
Social Credit,1,Jack Russo,Jack Russo,"The Chinese are developing a system of ""social credit""  which in theory is supposed to measure how good a given citizen someone is but is really just a mechanism of social control. Someone will be able to access a line of credit or get a permit will depend on their scored.   A persons ""social credit"" score depends on who that person is networked with on social media.

Network analysis may enable a handful of people to keep a billion in line."
Social Credit,2,Elina Azrilyan,Jack Russo,"That is a very interesting, if scary concept - quantifying the ""social value"" of an individual - basically expending the concept of a ""credit score"" beyond Financial implications. "
Social Credit,2,Jeremy O'Brien,Jack Russo,"Here's some more context on inputs for the China's Social Credit System:

China Social Credit System.PNG 

And consequences, which range from internet throttling to school / job / transportation bans to pet confiscation...

It's interesting to compare social credit with financial credit, which in the states has a regulatory framework focus on equity and fairness in algorithmic decisioning (i.e. clarity on what drives ones credit scores)."
Medical Coding,1,Amber Ferger,Amber Ferger,"I work in health insurance and one of the hot topics in this industry (and one that I'm excited to be participating in) is text mining for medical coding. In short, medical coders review a patient's medical chart to identify conditions and record them using standardized code-sets (ex: ICD10, DRG). The work is manual - coders must sift through irrelevant and unusable information to find sufficient evidence in support of a particular condition. Further complicating things, the layout and terminology of the documents varies drastically and code-sets and coding rules are updated yearly, so a standardized, programmatic approach is usually not feasible. The coders rely on their past experience and expertise to evaluate the text and make decisions about the conditions that the patient has. 

While this has traditionally been a profession reserved for licensed professionals (through the American Academy of Professional Coders), the past 10 years or so has seen an increase in the number of vendors providing NLP software to extract the conditions from within the text. These solutions are typically packaged into a user-friendly platform where coders can see the raw text, coding suggestions, and the extracted information overlaid on the medical chart. The coder reviews the findings and either confirms or rejects the suggestions and the feedback is cycled back to the vendor to provide additional training data for the algorithm. 

These types of platforms increase productivity of the coders, but don't currently have the ability to completely replace them. Because the field is so specific (coding guidelines are expansive and medical terminology varies drastically), human expertise often outperforms the machine in final selections. However, the health insurance industry is often lagging when it comes to technology, so more advanced techniques tend not to be applied to the problems that our industry faces as quickly as other industries. 

All this being said, as the insurance industry catches up to the rest of the tech world, software will likely become good enough to outperform our human coders. Computer programs can already recognize key terms and variations more efficiently than a human can. Although text comprehension is traditionally thought to be a humanistic trait, advances in natural language techniques and deep learning will likely enable a machine to interpret free-form text and make decisions in a similar manner.

I think computers will gradually replace tasks of medical coders until the role of the medical coder becomes completely transformed. It will take quite some time for humans to become comfortable with the decision-making from a machine, especially when dollars are tied to the decisions (inaccurate coding can lead to losses of millions of dollars in reimbursement). However, as machines become more ""human-like"" in their decision making, they will start to take over more and more responsibilities of the medical coders until the coders find themselves either out of work or performing tasks that are much different than what they do now. "
Medical Coding,2,Jit Seneviratne,Amber Ferger,"I think you pointed out the key inhibitor of progress in this area: the cost of an error. While machines will outperform humans in mundane tasks, as the complexity of the job rises, the gap will close. Also, even if robots in fact make fewer errors, if the consequences of an error are severe, we'd be very apprehensive to trust a machine with that task. Futher, from a legal perspective, a mistake by a machine can sometimes be a gray area, such as with self driving cars and accidents."
Job Hiring/Recruitment,1,Zachary Alexander,Zachary Alexander,"One example of text mining and/or network analysis that could eventually eliminate jobs is in the field of hiring/recruitment. As text mining capabilities get smarter, and become more apt at scanning text on resumes and application materials, we'll continue to see this type of software utilized more in the hiring process. Allowing AI software to do the ""dirty work"" of sifting through hundreds of resumes to find the right candidate is already being advertised as a cost-effective tool that could trim hours off of a job search process.

Here's a list of ten companies that are already providing this type of asset: https://www.selectsoftwarereviews.com/buyer-guide/ai-recruiting

As time goes on, and these types of tools become more effective in processing resumes and applications, it may be more lucrative to do away with internal positions that concentrate solely on recruitment. Right now, it seems like this type of software is mostly useful as a tool for recruitment teams, but eventually, it could perform ""better"" than humans in matching an employer to the right candidate."
Job Hiring/Recruitment,2,Subhalaxmi Rout,Zachary Alexander,"I do agree with you, Zach. We are on the same page with this idea. Due to text mining, manual effort reduces, and productivity increases. "
Text Mining in Law Firms,1,Vanita Thompson,Vanita Thompson,"During discovery, lawyers and paralegals must thoroughly examine thousands of documents, or even more depending on the case. Now, databases can use big data text mining techniques including keyword recognition and syntax analysis to accomplish these tasks in a fraction of the time.  In recent years, machine learning systems have been trained to review case history and precedents, and even draft  legal briefs traditionally reserved for junior level associates. In general, lawyers are paid to predict outcomes of major cases. However, statistical models created by researchers have been proven to predict the outcome of nearly 70% of supreme court cases. Prediction is possibly one of the most valuable services lawyers provide, and now it is easily matched by computers."
Text Mining in Law Firms,2,Simon Ustoyev,Vanita Thompson,"I also discussed on this topic.  I could easier imagine jobs lost and demands diminishing for human skills in the judicial process, but harder to imagine what new jobs can be added."
NLP in HR and Recruiting,1,Subhalaxmi Rout,Subhalaxmi Rout,"The future of work is a good article to describe humans and robots work together to get high productivity. Robert is more intelligent and efficient than humans. But the robot doesn't have human intelligence such as understanding feelings. For example, given in the article even though the robot can take better decisions in a case still human is needed to convey the result. People are more relying on a human to listen to the decision.

According to my opinion, the machine is there to help humans. Using machine-human can improve productivity. But the human job is still there. The manual work gets reduce but critical thinking, analytical thinking, and communication for this field of humans are needed. The human need to improve their skill set so that they can best use of the machine.  Because in the future more demand for highly skilled and educated workers.

Example: NLP in HR and Recruiting

Using NLP in human resources, HR professionals can speed up candidate searches by filtering out relevant resumes and designing bias-proof and gender-neutral job descriptions. Also by making the use of semantic analysis, software sifts through the considerable synonyms enabling recruiters to detect candidates that meet the job requirements.

Reference: https://www.plugandplaytechcenter.com/resources/introduction-nlp-and-how-its-changing-future-hr/#:~:text=NLP%20in%20Recruiting&text=NLP%20is%20saving%20precious%20time,want%20to%20lose%20the%20candidate."
NLP in HR and Recruiting,2,Priya Shaji,Subhalaxmi Rout,"Good example, NLP in HR can also increase their efficiency and probably lessen paper works."
NLP in HR and Recruiting,2,Subhalaxmi Rout,Priya Shaji,"Yes, due to NLP the manual efforts reduced additionally productivity of the recruitment process increases. "
NLP in HR and Recruiting,2,Jagdish Chhabria,Subhalaxmi Rout,"I believe using NLP for filtering resumes is a double-edged sword. As candidates realize that their resumes are being ""crawled"" by automated tools, they start stuffing keywords in their resumes to game the system. So I'm not sure how much of the end result is as per the original intent i.e. that job candidates would create completely honest resumes and a ""smart"" algorithm would weed out the less attractive candidates."
Sentiment Analysis,1,Mael Illien,Mael Illien,"Sentiment Analysis is a very important example of work that was not previously possible and has potential to expand further. Different scales are used to quantify emotions in language, for example positive-neutral-negative or more gradated scales. It is important because it allows us to do what was not possible beforehand, namely to quantify qualitative information from unstructured data (text) beyond tf-idf style analysis.

By putting a number on the sentiment of people towards companies or political issues, we can make some informed decisions. Sentdex (http://sentdex.com/) provides sentiment scores for financial, political and geographical topics. You can imagine how knowing the sentiment or the optimism about a company can influence you to purchase or sell a stock, especially since optimism is an expression of one’s belief of the future, which is a true driver of stock price, whose shifts are largely unidentifiable in corporate earnings reports.

Beyond the financial example, I think there is there room for sentiment analysis to be applied to many fields, especially if in the attempt to improve an AI we try to teach it how, we humans, are feeling beyond explicit phrases like “I am sad”. I also wonder if there are NLP research efforts to try to detect and analyze subtext or unconscious communications, which is something I believe computers do not do well. If they did, even psychology which is exclusively human, could be replaced with robo-therapists."
Human Tech Support,1,Jit Seneviratne,Jit Seneviratne,"Human tech support staff /call centers are declining , and it seems they are becoming casualties of service technology. However, users are become more sophisticated and as a result, their needs are becoming more complex: Many today don't call tech support to have a robot ask them if they 'tried restarting their machines'. With the advent of AI, our problems become more nuanced as well, so while level one support can feasibly be carried out by robots, level two and level three support will see a spike in handing volumes. It will be interesting to see if AI keeps up with that rapid rise in volume."
Human Tech Support,2,Sheryl Piechocki,Jit Seneviratne,"This is definitely the case.  In recent months, more and more websites I visit have a bot window pop-up asking if it can help me after a certain amount of time.  I don't usually ask any questions because I think the bot most likely has answers to only basic questions. "
Property and Workers Compensation Catastrophe Modelling,1,Willie Smalls,Willie Smalls,"Previously, Property and Workers Compensation Catastrophe modeling was a very lucrative career due to the complex nature of peril models and understanding of engineering and science concepts.  Insurance firms historically hired large teams of catastrophe modelers to process schedule of values (list of locations for a policy).  Think of Wal-mart and all of its locations.  Those would be included in a schedule.  For years, high wage workers would translate these schedule of values into a form that is recognizable by the catastrophe model.  As time progressed, insurance firms began offloading those schedules offshore to be processed.  Now, they have been using their large swaths of previously coded SOVs to build algorithms to reduce the human labor footprint.  "
Workplace email analysis,1,Mikhail Kollontai,Mikhail Kollontai,"While the morality of such an endeavor would be questionable, I can imagine a test-mining algorithm being used to analyze workplace email correspondence and identify potential disciplinary problems for HR. One of the biggest obstacles to HR being able to monitor behavior at an office is the fact that they require a party to reach out to them pro-actively before any investigation is performed. I can imagine such an algorithm constantly monitoring email communication within the office and flagging potential problem areas. Network analysis can further be used to cross-reference these areas with expected degree of communication. Network analysis of correspondences can also be used to identify communities within the office and drive both integration efforts and influence team-building initiatives. "
Workplace email analysis,2,Jagdish Chhabria,Mikhail Kollontai,"As far as I know, companies are already using such technology to monitor employee communication. So this is not some futuristic endeavor. Compliance departments in banks already monitor text and voice communications  by traders and investment bankers to ensure that they are not violating securities laws. IT departments as well as HR in large companies already monitor text communication for inappropriate content. As the technology becomes more commoditized, I'd expect smaller firms to be able to afford such monitoring tools as well."
AI in Automotive,1,Vijaya Cherukuri,Vijaya Cherukuri,"AI had already landed its foot on many industries. When we think of AI applications in the automotive industry, we might first think of self-driving cars. Tesla already made a noteworthy achievement in this.

In my opinion, AI will be useful, but it should not overtake or minimize the proiority of humans. With combined efforts of Machines and Humans we can achieve better results. Think of some places where AI scores high, one great example is Parking sensors and Active monitoring of blind spots.

Here are some references :

https://www.machinedesign.com/mechanical-motion-systems/article/21838234/how-ai-is-paving-the-way-for-autonomous-cars

https://www.cio.com/article/3355239/making-automotive-manufacturing-smarter-with-ai.html#:~:text=Artificial%20intelligence%20is%20one%20of,research%2C%20design%20and%20manufacturing%20processes."
AI in Automotive,2,Mael Illien,Vijaya Cherukuri,"The automotive industry, and particularly trucking is one of the biggest potential victims of automation. This is not like the case of the lawyer example who can now do the work of 500 by leveraging text mining. This has potential to replace all driving, whether for human mobility or the transportation of cargo, across all industries. And it doesn't stop at driving since planes can already land themselves and cargo ships rely on course correction software to reach their destination. 5G will enable even more intra device communication. The conversion of truck drivers into Internet of things engineers is not obvious so it is expected that some jobs will be lost. The classic counterpoint is that of course, jobs will also be created to maintain this new ecosystem of interconnected things. And when things are connected, there's an opportunity to leverage network analysis and graph theory. "
AI in Automotive,2,Abdellah Ait Elmouden,Vijaya Cherukuri,i am wondering if we will ever see AI or Machine Learning being used to design F1 cars or NASCAR . Perhaps it’s already happening.
AI in Automotive,2,Murat Akyildirim,Abdellah Ait Elmouden,thats a great question. Here is a brief article on that (   https://blogs.nvidia.com/blog/2017/05/18/nascar-safety/ ) .
Medical Diagnosis,1,Elina Azrilyan,Elina Azrilyan,"Similar to the example of lawyer skills being replaces with AI tools, the same parallel can be drawn to the medical field. Both fields require many years of training to master each respective skill and the use of text mining and network analysis could simplify these jobs. A tool which had the ability to diagnose a patient based on a wide array of information would save valuable time and resources. It would make diagnosing rare medical conditions easier - and allow human doctor to work with conjunction with such a tool to treat people more effectively. Additionally a tool like that can be useful in early detection of diseases when it is too early for a patient to notice the issue but there might be signs pointing to a diagnosis. Here is an example of a medical tool available for interpreting Radiology labs: https://www.siemens-healthineers.com/en-us/digital-health-solutions/digital-solutions-overview/clinical-decision-support/ai-rad-companion#Clinical_Outcomes"
Judge and Jury,1,Simon Ustoyev,Simon Ustoyev,"In trying to imagine what jobs can be eliminated, by the advance of text mining, network analysis and AI in general, I’d like to rephrase the question in the article and instead ask, “What will computers do better than people?”  To answer that question, I’d like to take the narrative of the article about diminishing demand of lawyer skills and take it to the next level and envision the whole judicial system being run by machines and “really” keep that blindfold on the Lady of Justice.  I don’t think it’s a far-fetched idea from realization at this point that machines can be better judges and jury in the near future.  Judges are trained in the rules of pure logic to arrive to decisions and to ensure that the judicial proceedings are conducted fairly, by striking down any “tricks” that may be played by lawyers and/or witnesses to influence a jury.  AI has already progressed impressively in NLP, CV (image/video) processing, as well as in processing visual and biological factors in “reading” humans, in order to arrive at “truth” classification of a testimony better than a polygraph test can.  Network analysis, for example, can be employed in determining how parties in a case are involved, the flow of events and etc.  The appeals and review process can still be performed by qualified humans (when requested), but even that, with time, will diminish.  A human may still, occasionally, win the AI system in rendering proper justice, by perhaps using imagination or following some “hunch” to turn the outcome around, but then only to discover the “short-lived” advantage to be programmed into the next upgrade for the AI Judicial System."
Judge and Jury,2,Willie Smalls,Simon Ustoyev,"When I first saw the subject for the post my heart stop for a second.  I went back to moot court where I noticed above the bench, where the judge sat these words: ""The law must be stable, but it must not stand still."".  It would be slightly difficult to completely turn the judicial system over to AI because the law is ever evolving.  There are ""their rules"" and then there are ""there rules.""  Being a POC, I would love it if lady justice was blind.  Maybe we could have avoided much of what we are seeing today."
Customer Assistants - Analysis,1,Murat Akyildirim,Murat Akyildirim,"Geoff Colvin’s article, “ Future of the Work”, is an interesting read, giving his perception on what skills and career paths would be more valuable with the current technological advancement. Couple examples provided by him are Google self driving cars, self vacuum cleaner and other mobile robots such as iRobot and Baxter robot and the recently popular law analytical services such as Lex Machina and Huron Legal.

The idea behind the article is similar to every phase of the change in the work environment, even though computers can perform certain jobs better than humans (such as skimming through and analyzing, sorting documents , predicting the result of a case in Supreme Court), the jobs don’t disappear and rather the new jobs and opportunities become available with new required skills. As a conclusion, he states the jobs and skills that will be valuable would be the ones that us humans insist to be performed by humans rather than computers.  

As the text mining and network analysis are becoming advanced in terms of technology and applications, in my opinion, jobs that require analysis might get eliminated. For example, automation of business and marketing reports, easy use of platforms for businesses might eliminate Data Analyst positions which would allow business units to work directly with the platforms. Human aspect of analysis such as breaking down business objectives, creating high level problem statement for business solutions and breaking that statement down into incremental problems would become more important than solely providing analysis.

Another possible elimination of skills and work would be due to the voice-enabled cloud connected assistants. For example ipsoft technology (Amelia) is being leveraged in many ways such as Customer Service Agent, IT Operations Expert and even a phycologist (https://www.ipsoft.com/amelia/ ) . These assistants can be used in many ways to provide seamless consumer interactions and transactions. They can be trained to help sell insurance or prequalify people for mortgages which can eliminate mortgage brokers and insurance sales people. However , these assistants don’t build any relationship with the customer or bring any empathy."
Customer Assistants - Analysis,2,Habib Khan,Murat Akyildirim,I agree with you. I think data driven positions have already started eliminated those jobs.
Text mining's potential impacts on publishing,1,Jeremy O'Brien,Jeremy O'Brien,"The publishing world has been debating what impact to expect from text mining.  While it might be far-fetched for to imagine authors replaced in the creative process (particularly for fiction, where generative algorithms haven't broken the blood-brain barrier - meaning - needed to succeed at story-telling), there are many other potential impacts.  For example, machine-based translations of foreign-language texts to aid publishers in deciding whether to option them, preemptively developing promotional campaigns with WIP manuscripts based on their similarity to other, successfully marketed titles, or even creating a much-dreaded feedback loop using sales data and text analytics to inform editing (i.e. encouraging authors to write what sells).

A number of these possibilities are discussed in this thesis paper, which is an interesting if non-technical read."
Network analysis in fraud detection,1,Habib Khan,Habib Khan,"Data driven analysis are being widely used globally for business process reengineering in both profit and non-profit organizations for better optimization. Banking sector is using fraud detection through network analysis and other techniques to identify the potential frauds for better security of the customers and their accuracy is also getting better with the inclusion of big data. I think few jobs might be eliminated with reference to fraud detection but at the same time data analysts would be required. I have found this article quite useful on how text mining is being used in different sectors.

https://expertsystem.com/10-text-mining-examples/"
Using text mining to identify contracts that need re-negotiation,1,Jagdish Chhabria,Jagdish Chhabria,"One significant undertaking going on in the financial services sector is the migration of interest rate benchmarks from LIBOR to other Alternate Reference Rates (ARRs). There are literally trillions of dollars of contracts (loans, derivatives etc) that reference the LIBOR rate. As a result of fixing collusion scandals, the Bank of England decided that it would no longer force banks to provide LIBOR quotes after 2021.

As banks rush to replace the benchmark rate in millions of contracts, the use of text mining techniques to scan millions of pages of legal contracts for words such as ""LIBOR"" and the context it is used on and whether there are fall-back provisions is replacing what would traditionally have been done manually by armies of clerks. So this is definitely one example where these techniques are replacing humans and increasing productivity and efficiency."
Frida vs the CEO,1,Mael Illien,Mael Illien,"I found example from The Power of Informal Networks in the readings very interesting, where it was actually Frida and not the CEO that was the central node of the network. This makes me think about the companies I’ve worked for in a similar context where it is often how long a person has served for that determines their centrality.

This article referenced below provides a good explanation of the types of individuals mentioned in the readings such as the connectors, the boundary spanners, the information brokers and the peripheral specialists. All are examples that can be identified using graphs and centrality measures.

In the Frida example, she can be identified as a connector by looking at the degree of edges spanning from her node, which is the maximum in the small office network.

https://hbr.org/2002/06/the-people-who-make-organizations-go-or-stop

"
Frida vs the CEO,2,Jack Russo,Mael Illien,"It's quite striking how those ""informal networks"" clash with the formal structure of an organization. Makes you wonder about diseconomies of scale balancing increasing returns to scale. In classical economics an increasing return to scale can mean an infinite quantity is produced.... theoretically. In reality increasing complexity and informal networks cap the feasible scale of any firm."
Frida vs the CEO,2,Steven Ellingson,Mael Illien,"I've found this example to be very accurate in my experience.  There are always people that others come to with their issues, and they are usually not the boss. Whether it's due to experience or just having the right personality, certain colleagues get asked things constantly and are extremely important nodes in their networks."
Frieda's Bow Tie Network,1,Jack Russo,Jack Russo,"Keeping things simple, Frieda Bow-Tie Network at AMCE is an obvious example. You could compute the betweenness centrality for each member of the network and it would likely show you that the veteran secretary controlled the bottleneck. Though this may have been sufficient in that instance to produce a positive outcome, further analysis could have use a ""grey cardinal metric to access the importance of peripheral figures."
Microsoft success,1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"Paul Revere was an information broker, a person who occupies a key role in a social network by connecting disparate groups of people. Now imagine that the information being transmitted by the messengers is not about redcoats, but about a new product idea or a different way to manage a team. If that information isn’t delivered to the right people, it will wither and die.

For example, before Microsoft was a household name, Bill Gates had a singular distinction in his network—his mother, Mary Gates, who sat on the board of United Way with John Akers, a high-level IBM executive. At the time, Akers was helping to lead IBM into the desktop computer business. Mary Gates talked to Akers about the new breed of small companies in the computer industry, which she felt were underappreciated competitors of the larger firms with which IBM traditionally. partnered. Maybe she changed Akers’s vision of who to go to for the new IBM PC’s DOS, or maybe her comments confirmed what he already knew. In either case, after their conversation, Akers took proposals from small companies, one of which was Microsoft. The rest is history: Microsoft won the DOS contract and eventually eclipsed IBM as the world’s most powerful computer company.

Without Bill Gates’s potent network, a sensational new operating system might have faded into obscurity just like William Dawes.

So  the most important or central person in this network (Centrality measures) is Mary Gates.

Reference"
Microsoft success,2,Amber Ferger,Abdellah Ait Elmouden,"This is very interesting and highlights the importance of Mary Gates' betweenness centrality. She was able to serve as the connection between Gates and IBM, ultimately leading to Microsoft winning the contract!"
Kardashians,1,Vanita Thompson,Vanita Thompson,"Kim Kardashian and The Kardashian family have been effective at hacking/navigating their social networks. They have ammased a tremendous following, and are ranked amongst the most popular public figures on popular social networking apps, such as Twitter, Instagram, and Youtube. Their analysts may use degree centrality (both inward and outward), betweness centrality, closeness centrality, and eigenvector centrality to analyse their social networks. Since degree centrality measures the number of edges on a node, it can be considered a measure of popularity. Betweeness centrality is a measure of a nodes centrality in the network equal to the number of shortest paths from all other verticies to all others that pass through that node, or a node's ability to bridge different subnetworks. Higher betweeness centrality scores may indicate the importance of a node (or Kardashian) in a network. Closeness centrality is a measure of the average shortest distance from each vertex to each other vertex. Direct connections and shortest paths are important. A lower closeness centrality score shows more direct connections (closeness). Eigenvector centrality is a metric that measures the degrees of the nodes that a node is connected to. It can be used to calculate how “connected” are the nodes connected to a Kardashian. It is a way of determine how popular the Kardashian's friends are. Using subgraphs show all the nodes that node is connected to. These centrality measures can be used to predict positive and negative outcomes, such as icreasing social media engagement for marketting opportunities, or filtering bad publicity and comments on their social platforms."
Kardashians,2,Amber Ferger,Vanita Thompson,"This is an example that I wouldn't have thought of! Celebrity social media activity can definitely be used as a proxy for their influence. The larger the following on any account, the wider the audience for their messages. This popularity can be used to engage supporters while promoting themselves (a really smart marketing technique) and advance their personal agendas. Nice job!"
Kardashians,2,Vanita Thompson,Amber Ferger,"Thank  you Amber. I thought this would be an interesting choice. I believe the website Social Blade uses similar centrality measures to rank popularity amongst youtubers. They analyze profits based on traffic generated from video views.

Vanita"
Kardashians,2,Zachary Alexander,Vanita Thompson,"Really enjoyed this example, Vanita -- very interesting how you demonstrated the Kardashian's prowess on social media, and I agree, it would be really interesting to measure degree centrality for many of the close connections to the family to measure the real impact that this family has on other people's networks! I also had an example that highlighted Justin Beiber's online reach, and find celebrity networks to be quite fascinating. Thanks for sharing!"
Cindy Kimberly,1,Zachary Alexander,Zachary Alexander,"In 2016, Justin Beiber posted a photo of Cindy Kimberly on his feed with the caption, ""OMG, who is this!?"". Since then, Cindy Kimberly has become a famous model, and launched her successful career on Instagram, amassing over 6 million followers on the social media site. Based on her connection with Justin Beiber, her betweeness centrality measure with him and many of her new connections allowed her to expand her network, and to interact and engage with new groups of people over a very short period of time. Justin Beiber's degree centrality on Instagram is quite high, and he currently has over 138 million followers, making him one of the biggest influencers on Instagram. With this large of a following, he holds a lot of clout in driving the narrative on the platform. We can see here that Cindy Kimberly had a positive outcome from this interaction, and her talent and savvy has made her as famous as she is today. These two measures seem to be the most relevant for this example. I do think that centrality measures would allow me to predict the relative positive or negative outcomes in this example.

Source:  https://medium.com/@goboldfish/social-media-careers-famous-for-being-famous-4f603a7c7993"
Johannes Gutenberg,1,Mikhail Kollontai,Mikhail Kollontai,"I think one of the original ""hackers"" of the social network was Johannes Gutenberg with his invention of the printing press. His invention was a large step in trivializing the spread of information. Before this invention, each piece of literature was unique and created through hours and hours of manual labor. They were therefore difficult to procure and reserved for higher society and the church. Not only the content, but those exposed to it could therefore be fairly well controlled. 

Gutenberg's invention essentially allowed information to be shared with an entire network without a single point of contact (the owner of a book). It also significantly reduced the cost of creating a piece of literature, allowing those of much lesser means to also share the information they wanted with the world. If this isn't hacking the system, than I don't know what is. "
Johannes Gutenberg,2,Abdellah Ait Elmouden,Mikhail Kollontai,Thanks for sharing. Johannes Gutenberg is credited as the inventor of modern mechanical printing but I as know he introduced the printing to Europe Bi Sheng  did in China four centuries earlier. https://en.wikipedia.org/wiki/Bi_Sheng.
Johannes Gutenberg,2,Mikhail Kollontai,Abdellah Ait Elmouden,"I must say I'm embarrassed not to have heard about this - thank you so much for pointing it out. Just goes to show how much ""Western"" accomplishments are glorified in the education system here! I'll make sure to fix this gap in my knowledge of history."
Russian Twitter Bots,1,Amber Ferger,Amber Ferger,"Although this isn't a specific person, it's a good example of how fast and far fake news can spread. This was a big issue with the last US election, and, not surprisingly, it continues to be an issue with other natural disasters and events (like coronavirus). 

Russia took advantage of twitter's social network to spread false information in the last presidential election, ultimately creating distrust and anger in the American population. The bots' targeted messaging aided in further dividing our political system by curating tweets that attacked Clinton and supported Trump. Due to the inherent connectedness of twitter, these tweets reached a large audience on the platform in a short amount of time.

The hackers were successful because they understood the inherent nature of social behavior - we tend to interact with and support individuals that have similar opinions to ours. It's not surprising then that Trump supporters tended to interact with messages from pro-Trump twitter bots. These in turn were spread to other Trump supporters and so on. 

The most relevant centrality measures to this example would be degree centrality (number of raw connections a twitter user has) and eigenvector centrality (how connected the twitter user is to other well-connected nodes). Both of these metrics would allow us to see what exposure the bots have to the twitterverse. The number of raw connections would be the base population for the initial tweet, but the eigenvector centrality would tell us how expansive the overall exposure of the tweets would be. 

In this particular case, the centrality metrics would help us to analyze the extent of the spread of information throughout the network. The higher the degree and eigenvector centrality, the further the information can traverse through the network. Although these centrality measures can tell us the potential of exposure, it doesn't tell us much about the likelihood of spread. In order to make a more accurate prediction, we would want to incorporate the user activity for each account. The more active a user base, the more likely the tweet will be interacted with and relayed. Thus, centrality metrics should be combined with additional user attributes to make a better prediction. 

"
Russian Twitter Bots,2,Vijaya Cherukuri,Amber Ferger,Good example Amber. Fake news is spreading its wings and became a big issue now a days. In elections it played a crucial role and changed the face of parties.
Russian Twitter Bots,2,Subhalaxmi Rout,Amber Ferger,"Nice explanation Amber, these days difficult to identify real and fake news. due to social media sources, people get influenced more by fake news and fake news spread quickly. Using social network analysis we can find out fake news sources. "
Kane Gamble vs CIA,1,Vijaya Cherukuri,Vijaya Cherukuri,"Kane Gamble successfully used social engineering to get into the email accounts of CIA Director John Brennan and James Clapper, Director of National Intelligence, amongst others. This gave him access to highly sensitive military documents and intelligence operations in Iraq and Afghanistan.

His method was simple but efficient, leading him to change security questions and numbers and gain access to many other accounts. He also managed to set up an auto-forward service directing phone calls from Clapper’s home to the Free Palestine Movement."
Kane Gamble vs CIA,1,Vijaya Cherukuri,Vijaya Cherukuri,"One more example i can think of it  Associated Press’ (AP) Twitter account posted a fake tweet stating, “Breaking: Two Explosions in the White House and Barack Obama is injured” to it’s more than 2 million followers."
Different Centrality Measures,1,Jit Seneviratne,Jit Seneviratne,"Degree centrality is useful to determine the reach a person or entity has. A Youtube influencer is an example of high degree centrality. Closeness centrality is useful to find out how close someone is to another person. Unlike degree centrality, closeness centrality is based on the shortest paths across all nodes. This concept is useful on a platform such as Linked In, where relationships are ranked according to degrees (1st, 2nd or 3rd, not a graph theory concept). Another concept similar to closeness centrality is betweenness centrality. Betweenness centrality looks at the number of times a node acts as a bridge along the shortest path across two other nodes. This concept might be critical in power grid setups, where distance is of interest to minimize cost.

As a whole, centrality measures are used in a wide variety of industries. Intelligence agencies use these to understand key players in clandestine networks and neutralize threats. Citibike probably does frequent network analyses of their bike docks, to optimize distribution."
Different Centrality Measures,2,Priya Shaji,Jit Seneviratne,Nice information about difference between centrality measures. Use of these in Intelligence agencies is a good use case for  SNA.
centrality measures as indicators of leadership,1,Priya Shaji,Priya Shaji,"The findings here suggest that degree centrality helps as an indicator of local opinion leadership, since a high degree centrality means many connections in the direct environment of a vertex. 


To assess global opinion leadership, the closeness and betweenness centrality measures are better suited. Individuals who are easily reachable by others have a higher chance of being noticed (closeness centrality), while individuals who lie on communication paths can exert a greater influence on that communication.

https://www.sciencedirect.com/topics/computer-science/degree-centrality"
centrality measures as indicators of leadership,2,Elina Azrilyan,Priya Shaji,Thank you for sharing this link - a lot of in-depth information about Degree Centrality which really helped me understand the concept!
centrality measures as indicators of leadership,2,Jit Seneviratne,Priya Shaji,"Reminds me of network analyses involving emails. If a CEO has high closeness centrality where nodes include all employees irrespective of title, it shows that the CEO is reachable (which is a good thing I suppose)."
Elon Musk,1,Elina Azrilyan,Elina Azrilyan,"Elon Musk is an example of effective social network personality and he is in the center of the public’s eye at the moment. He is considered to be a “visionary” by many due to his Tesla and SpaceX achievements. Elon Musk is the influencer who built and continues to use his personal brand in connection with the company’s brand. It is pretty unusual for a CEO to take that role and can have some negative consequences when controversial issues are discussed on his platform, such as his public announcement against government’s stay-at-home order during the pandemic.

Eigenvector centrality will be a useful metric in measuring Elon Musk’s influence. Eigenvector centrality which assigns relative scores to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes. Centrality measures are very useful in determining the extend of his influence and measuring the consequences of the messages he shares. We could measure the impact of his communications on Tesla sales or people refusing to follow stay-at-home orders."
Gayle King,1,Sheryl Piechocki,Sheryl Piechocki,"When I think of someone who hacked their network, I think of Gayle King.  The only reason anyone ever heard of Gayle King was because she is Oprah's best friend.  She was Oprah's best friend before Oprah became famous.  As Oprah rose to fame, she often mentioned Gayle, had her on her show, etc.  This is how Gayle King then became famous.  In the beginning she was a very close network connection to Oprah, a person with high degree centrality.  Through that relationship she was able to increase her own degree centrality.  "
Cambridge Analytica,1,Subhalaxmi Rout,Subhalaxmi Rout,"Cambridge Analytica is an example of hacking/navigating to social networks. Cambridge Analytica’s goal was to harvest data, primarily psychographic, in order to target and persuade swathes of people. They collected as much as data they could from Facebook login, they created an app which gathered psychometric data from the user’s personality quiz. Like this, they created an exponentially large feature-rich dataset representing psychological profiles for almost 100 Million people. Then they used complex machine learning to ‘fill out’ these psychological profiles and build up a model to target these individuals with highly personalized advertising; to optimize persuasion and conversion rates. This model was infamously used during the 2016 Presidential Election and the Brexit vote.
For Cambridge Analytica, Degree centrality and eigenvector centrality measures are more relevant. 

Reference: 

Cambridge Analytica network Analysis: https://uxdesign.cc/social-network-theory-cambridge-analytica-and-what-it-means-for-design-b241a495a1fd

Centrality Measure: https://cambridge-intelligence.com/keylines-faqs-social-network-analysis/"
Cambridge Analytica,2,Mael Illien,Subhalaxmi Rout,"I always find Cambridge Analytics to be a fascinating example. Even more so now, with the understanding of centrality measures. Given how effective this persuasion campaign was, I wonder how many other campaigns are using network analysis to spread their message. Funny to think that a data scientist could have an equally important role to a campaign spokesperson in the success of the campaign.  "
Cambridge Analytica,2,Sheryl Piechocki,Subhalaxmi Rout,"This was certainly a hack of social networks.  Two things I find interesting about this:

The vast power there is in data.
The fact that people's decision making is easily influenced by repeated, targeted ads."
Cambridge Analytica,2,Murat Akyildirim,Subhalaxmi Rout,"Great read and example. Thank you for sharing. I think in the recent future, there will be vast policy change and application on collecting and sharing data at a point the only available way to capture user information would be through first party data collection with consent."
Cambridge Analytica,2,Habib Khan,Subhalaxmi Rout,I watched a movie on Netflix about that and I was quite amazed the way they used data science techniques to do so. Thanks for sharing
My Most Recent Job Search,1,Ken Popkin,Ken Popkin,"It's a statement we all hear over and over that goes something like this, ""xx% of all job offers come from networking, not from just submitting your resume to job sights"".   But I wasn't heeding the advice even though I knew I needed to...

I was ten days into my Covid-19 furlough, my employer's revenue was down over 50%, and I knew it would be months (if ever) to call me back.  I was submitting resumes to job sites, even though I secretly knew that it was about the same as chewing a Certs candy instead of taking an aspirin to get rid of a headache.

But, then I saw a job posting for ""Principal Project Manager - Data Science"" from my former employer.  Having been a project manager in IT for years and pursuing my passion for Data Science the past two years, this job posting described me perfectly.  Here's what happened next...

1. On a Thursday evening I submitted my resume to HR and emailed a friend (George) still at my former employer.  He replied back with the hiring manager's name (which is listed on the internal posting, but not the external one).

2. On Friday, I sent an email to the hiring manager (Steve), explaining how I got his name, my passion for Data Science, and that I was a former employee.

3. On Monday morning, Steve replied back and we arranged a phone call for Wednesday morning.

4. Several interviews and three weeks later, I had an offer, which I gladly accepted.

5. I just finished my third week at my new employer and things are going great.

Social networking works, even though introverted types like me often try to convince ourselves that it doesn't. I do admire (and at times envy) you extroverts that more easily accomplish all the social networking both online and in real life."
My Most Recent Job Search,2,Sheryl Piechocki,Ken Popkin,"Thanks for sharing your story Ken.  I am reminded of the saying:  its not what you know, its who you know.

I, too, consider myself an introvert, and can relate.  It is not in an introverts nature to develop a large social network and this can work against us, especially in a job search.  "
My Most Recent Job Search,2,Murat Akyildirim,Ken Popkin,I am on the same boat here. Definitely an introvert. But i still dont understand how being connected with someone with little to no strength can bring any value in job search. 
My Most Recent Job Search,2,Jit Seneviratne,Ken Popkin,Congrats on the new job. It would be interesting to see what my LinkedIn network looks like. I'm sure it'll yield a few influential individuals who can help me with my next job :)
My Most Recent Job Search,2,Mikhail Kollontai,Ken Popkin,"My 3 last jobs were all results of either a former colleague or former manager contacting me about a position. Though I haven't been out of college all that long (8 years), only my first job wasn't a direct result of networking - though even that one was through a recruiter. 

As a fellow introvert I feel like this does make us feel a little less confident in our prospects in the job market, so I'm happy to hear your turnaround time was relatively low. 

I myself am starting to look for jobs because my wife an I are planning to move to Detroit in October, but I have no contacts there and I'm attempting a shift from engineering into Data Science, so I'm extremely reliant on the hiring websites. Expecting this to be a very painful process.  "
My Most Recent Job Search,2,Willie Smalls,Ken Popkin,"Congrats, Ken!  You made it very easy for them!  They probably already knew the quality of your work (since you worked there) and you had someone internal to vouch for you.  "
My Most Recent Job Search,2,Jagdish Chhabria,Ken Popkin,I completely agree Ken. Most job searches seem to be influenced heavily by social networking - essentially through multiple loose ties with a host of people (nodes) as opposed to a few strong ties with just a handful of people. I am seeing that play out in real time.
Facebook Groups in Colleges,1,Murat Akyildirim,Murat Akyildirim,"College Students – Social Network sites are important for students specially in the beginning years. These networks will allow them to build their networks in and out of the campus. In the process, the most important variable that can be measured is centrality. In this case, How many first year students has connected to the social network (whatever this network may be, school network, fb , linkedin group and etc…) Degree of centrality would be the number students connection with other students.

Students can be connected to the multiple different networks. This will allow them to keep the cost of maintaining their relationship with others. If students message continuously through these social networks, it will allow them to maintain their relationships.

 

Below link is a pdf that has a sample study on Social Networks with student participation.

1-      Selected students become a part of a Facebook group based on the study.

2-      They are asked to answer some questions and friend FB account so the researchers can track their social network.

3-      They become fb friends within each other through the research.

4-      Network data is collected every first of the month for 9 months.

The study measured;

1-      FB usage

2-      Find out how students maintain their communication (what kind of strategy they use)

3-      General Behaviors within Facebook

4-      Visual Representation of the networks are defined.

5-      Centrality, degree of centrality and betweenness is measured.

 

Reference: https://www.tandfonline.com/doi/pdf/10.1080/10510974.2020.1725081"
"Steve Jobs, Trump … and the divide",1,Simon Ustoyev,Simon Ustoyev,"disclaimer: I’ll try to stick to data science here and avoid politics. :)


In my attempt to come up with a different example of a person who was effective and influential to his or her social network, two names from the modern times, such as Steve Jobs and Trump can readily come to not just my mind, but I’m sure to lots of you as well.  So, what kind of metrics or network attributes can explain their impact in social and traditional media?  One attribute, in my opinion, is the position that such individuals step into, such as CEO, POTUS or any other similar position of power and influence, which inherently carry a high degree metric of followers.  Another attribute is that it matters who the person is.  For example, it matters if a message is from Steve Jobs vs. Tim Cook or from Trump (vs. or I don’t know…) vs. anybody else.  I couldn’t associate this personality factor to any metric from Paul Revere’s analysis article.  But perhaps there is another metric that should be identified which can quantify the amount of “charge” (“electricity” if you will) or potential that is formed in the network around such personalities and in response to the messages they propagate through such “supper-charged” networks.  In the case of Paul Revere, there was a “highly important” alert that invoked a unified response against impending British invasion.  However, for Steve Jobs and Trump, the network around them can be categorized as divided or highly polarized (there are “never-iPhone or iAnything” camp against Steve Jobs and “never-Trumpers” against Trump).  Such high degree of passions pro and against, create some degree of “charge” in the network with both polarized camps being highly in tune to every message coming from these individuals.  Such network, although polarized or divided, becomes “supper conductive” and therefore have vast outreach, as the messages reach and then propagated more effectively by the “opinionated” connectors (“salesmen/saleswomen”) in the network.  Maybe that’s why Trump’s tweets spread like wild fire."
Footballer's influence in sports gear,1,Habib Khan,Habib Khan,"There are bunch of footballers such as Messi, Christiano Ronaldo who heavily influences the audience significantly that's why brands such as Adidas, Nike, etc have made these footballers as their brand ambassadors to change the perception of general public towards their brand. Now if you think of playing sports or hitting gym, you want to put on these clothing brands that already had influenced us. Lionel Messi has 2.9 million followers on twitter that's why Adidas has life time deals with him and bunch of other athletes. These companies know how footballers can influence people and change people's perception towards these brands."
Musical Artists,1,Willie Smalls,Willie Smalls,"Many artists often do collaborations with other artists to increase the degree of centrality.  Frequently we see pop stars feature with hip hop and R&B stars to popularize a particular song, increase the rank of the song on the billboard 100 charts or expose one artist or both to a new genre or country.  One person who capitalizes on features to increase her popularity or the popularity of a song is Nicki Minaj.  While Nicki Minaj is a bona fide hip hop artist, she has used features to score number ones on the Latin, Pop, R&B, Hip-hop, Reggae, Dance, Electronic, and Gospel charts.  These crossovers have benefited her and other artists, exposing each's fans to new genres.  I am sure that there are numerous analysts in the back crunching numbers trying to figure out which artists should feature with with other artist to increase sales or score a no. 1 single. "
MLM,1,Steven Ellingson,Steven Ellingson,"We've all seen these pop up in our facebook feeds, or in conversations with family members, etc.  Multi-Level Marketing schemes.  It used to be vacuums and tupperware, now it's yoga pants, essential oils, and health patches. 


Most companies have to work very hard to build trust in their brand.  These companies hack social networks to appropriate the trust that family and friends have with each other. I don't trust that some random health shake company has my best interests in mind, but what if it's my sister who's selling the product?  This is something she swears by, and she is telling me that X product is life-changing. All of the hard steps to selling a product (getting an audience, gaining rapport, etc.) are already done. The rest is easy."
Boundary spanners and crossovers,1,Jagdish Chhabria,Jagdish Chhabria,"When I think of people navigating social networks well, the examples that I find interesting are those of crossovers - people who had extensive connections in their chosen field, who then decided to parley their very high levels of degree centrality to enter another network where they got a lot of connections as a virtue of their role in the previous network. The examples that I can think of are people like Marc Andreesen who was responsible for creating the first (or maybe second) Internet Browser called Netscape Navigator. He then went on to become a successful venture capitalist in a firm called Andreesen Horowitz.

Other interesting examples are couples who had very high degree centrality in two different fields (large network of fans) who then gained credibility or connections in another field (or social network) by virtue of establishing a relationship (with very high weightage) with this other person (or node). Examples: David Beckham (sports network) and Posh Spice (pop music network), Prince Harry (British royalty) and Meghan Markle (American films). One can think of these power couples as boundary spanners i.e. they enjoy a prominent place in 2 different networks by virtue of this one really strong edge."
"Apple ""trust scores""",1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"Apple is quietly giving people 'trust scores' based on their iPhone data
Apple has introduced ""trust scores"" for people based on how they use their iPhones and other devices.To help identify and prevent fraud, information about how people use their devices, including the approximate number of phone calls or emails they send and receive, Data will be used to compute a device trust score when they attempt a purchase.

Though Apple doesn't provide any details on how this works, the company has previously deployed a privacy measure called ""differential privacy"" that allows for some aggregate data-gathering and analysis that theoretically protects the subjects' privacy.

References :

- Original article

- How trust score are calculated"
"Apple ""trust scores""",2,Priya Shaji,Abdellah Ait Elmouden,"Thanks for the article link Abdellah, good to know the ""trust score"" term. Clearly more information should be provided to users by companies using these techniques."
"Apple ""trust scores""",2,Ken Popkin,Abdellah Ait Elmouden,"Good to know that Apple is continuing to introduce protective measures and the ""Trust Score"" doesn't sound too intrusive to me.  I'm all for Apple engaging in the information sharing as long as they really are protecting sensitive information as you describe."
"Apple ""trust scores""",2,Jeremy O'Brien,Abdellah Ait Elmouden,"For those interested in getting some background on differential privacy, here's a text I've found a helpful reference:   https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf"
Auto Insurance Fraud,1,Ken Popkin,Ken Popkin,"Professional fraud in auto insurance has been a problem for decades and probably will never cease being a problem.  Fortunately machine learning and specifically social network analysis has become a significant contributor to identifying potential fraud. 

According to research from the School of Industrial and Systems Engineering there are,"" new approaches for identification, representation, and analysis of organized fraudulent groups in automobile insurance through focusing on structural aspects of networks, and cycles in particular, that demonstrate the occurrence of potential fraud.""

On page 3, the article mentions, "" The detection of suspicious components starts in this expert system after creation of a network. Afterward, the system determines the suspicious entities in each of the detected suspicious components by displaying the social network of these entities. Unlike other solutions, this system uses network and graph to display data... the researchers have provided an algorithm called Iterative Assessment Algorithm (IAA) to identify the fraud entities. Along with the original and inherent characteristics of entities, this algorithm explores the relationships between entities.""

On page 6, there is mention of a ""DFS algorithm"" that  establishes the local social network location of each entity (node) in order to overcome posed issues by unbalanced data sets.

In total, the article mentions social networking 18 times and the references to algorithms I have yet to learn about is eye opening to the power and capability of social network analysis.  For now, I'll stick with the centrality measures that we've learned to date, but I can definitely see the great potential that social networking could contribute to the reduction of fraud in auto insurance."
Auto Insurance Fraud,2,Sheryl Piechocki,Ken Popkin,This is very interesting.  I didn't know there was an issue with fraud in auto insurance.  Groups of individuals scheming and setting up fake accidents in order to make insurance claims is something I never heard of before.  Scheming individuals are very keen.  I like this use of cycles to identify them.  The likelihood of these cycles being quite low is a good measure for detecting the fraud.
Auto Insurance Fraud,2,Vijaya Cherukuri,Ken Popkin,Interesting information. I dont about this claiming the fraud insurance claims. I like the model you chooses to identify the fraud.
Link analysis in investigations,1,Priya Shaji,Priya Shaji,"Criminal investigations worldwide face a monumental big data problem that is escalating in the digital age. Today’s data is massive, complex, continuously changing and varied. The reality is that many investigators have become overwhelmed with information, and identifying connections in data is often a difficult and time-consuming task.


Link analysis can be used to evaluate relationships and connections among people, organizations and transactions. It can be a powerful tool to identify patterns and trends and drastically reduce the time and effort required to expose patterns indicative of fraud, money laundering and a host of other criminal activities.

Issues with link analysis:

Information overload: With the vast amounts of data and information that are stored electronically, users are confronted with multiple unrelated sources of information available for analysis.Data itself has inherent issues including integrity (or lack of) and continuous changes. Data may contain “errors of omission and commission because of faulty collection or handling, and when entities are actively attempting to deceive and/or conceal their actions”.

These may contribute to increase of error rates. There are few proposed solutions to overcome these here https://en.wikipedia.org/wiki/Link_analysis 

Basic information of link analysis: https://www.ravelin.com/insights/link-analysis-and-graph-database-for-fraud-detection"
Link analysis in investigations,2,Elina Azrilyan,Priya Shaji,"Priya, I think you make a great point - the more data there is - the more difficult it becomes to investigate and identify connections. Thank you for sharing the resources with more information on Link Analysis, it it very interesting. "
Link analysis in investigations,2,Zachary Alexander,Priya Shaji,"Hi Priya,

Very much enjoyed your post -- I definitely agree that criminal investigations are prone to carry large and complex networks, many times very difficult to parse through. I thought the lecture video was quite interesting, when Veronique touched on how they measured fraud scores based on proximity to already fraudulent nodes, something that could be done for criminal investigations but could hold catastrophic consequences if not executed correctly (wrongly identifying individuals that are actually innocent while simultaneously classifying individuals as innocent when they are actually guilty). Thanks too for providing the error rate information on link analysis -- very helpful!

Best,"
Credit card fraud detection,1,Subhalaxmi Rout,Subhalaxmi Rout,"Frauds are everywhere — wherever a transaction is involved— but credit card fraud is probably the most known case. Credit card frauds have always existed but the magnitude is only growing recently due to increasing online transactions taking place through credit cards every day. 

How to detect fraud by the bank?
Purchase transactions on the Internet are handled in credit card networks through an authorization process. Tools are in place which allows a typical behavior to be flagged and alerts to be raised so that the issuer bank can check with the cardholder whether the transaction is valid or not. If not, the card will be blocked (so that no further transaction can be made with it) and a fraud declaration will be filed for the next investigation (by the bank and the police). Usually, the first case of fraud on a card is not detected, only the second or the third … Of course, early detection will reduce the cost of fraud.

Below are the techniques apply to resolve frauds:

predictive mode
exploratory mode
Fraud detection performance is measure through two indicators i.e Coverage and Relevance. 

Coverage: Rate of fraud cases detected by the systems

Relevance: It is the rate of correct detection, i.e. the ratio of alerts which are real cases of fraud. Coverage = TP/(TP+FN)Relevance=TP/(TP+FP)

Where TP = True Positive, FP = False Positive, TN = True Negative, FN = False Negative.

Reference:  

Credit card fraud detection:  https://www.researchgate.net/publication/265291917_Using_Social_Networks_for_On-line_Credit_Card_Fraud_Analysis"
Credit card fraud detection,2,Jack Russo,Subhalaxmi Rout,"You beat me to this one. You didn't mention any network characteristics, like similar transactions between fraudulent purchases. "
Credit card fraud detection,2,Subhalaxmi Rout,Jack Russo,"Thank you for mentioning that point, Jack. 

Detecting unauthorized credit card transactions is an extremely complex problem but there is some hidden pattern in the fraudulent activity such as unusual purchasing situation (card being used to make purchase different place at the same time), purchase from unusual store (i.e., a store never visited before by the card owner, located in a different city), etc. "
Credit card fraud detection,2,Abdellah Ait Elmouden,Subhalaxmi Rout,"Applying social network analysis for detection does come with some limitations . SNA is retrospective in nature, we can only react to a fraudulent instance after it has occurred.  Unlike other data analytics tools and techniques, social network analysis is not a modelling technique."
Credit card fraud detection,2,Steven Ellingson,Subhalaxmi Rout,"I'm not sure I agree with this.  SNA itself isn't a predictive model, but can't it be used in a predictive model?  Couldn't you take measures from your SNA and add them as predictors in a regression model? If you have historical information on the SN for past customers, I don't know why you couldn't use it for predictive analysis going forward."
Tax fraud,1,Jack Russo,Jack Russo,"As pointed out by Ms.Vlasselaer, 

Any shared reasource between two nodes can be evidence of fraud. In the presented case of fraudulent companies, shared assets, addresses, phone numbers could be used to weight the edges of each edge. Using this method the Belgan SSA was able to detect new fraudulent companies within 1 percent presicion. A similar approach could be applied to tax returns here in the United States. Shared Addresses, phone numbers, and places of work with fraudulent returns could be used to construct a graph with weighted edges. A precision rate  in this use case may or may not be comparable given that 250K companies is far less than 300 million potential tax returns."
Tax fraud,2,Amber Ferger,Jack Russo,"This is a really great point to make and is true of many different types of fraud -- individuals connected to confirmed fraudulent nodes tend to also be fraudulent. We see this in the case of health insurance fraud as well, especially in cases where a provider creates new aliases to bill under. Visualizing the connections between parties can be so useful in detecting fraud early on!"
Provider Fraud,1,Amber Ferger,Amber Ferger,"Most health insurance companies have an entire department dedicated to identifying fraud, waste, and abuse in provider billing. While waste and abuse tend to be easier to identify and correct, fraud is much more complex because it is (1) constantly evolving, (2) hidden within the data, and (3) a lot less obvious. Our Special Investigations Unit utilizes software that combines data from a variety of public data sources and allows the investigators to visualize the provider networks and more easily identify connections within the communities. The network is multi-modal: it includes different types of nodes (physicians, offices, relatives, facilities) and different types of edges (familial relationships, business partnerships, affiliations, contact). The incorporation of bankruptcies, lawsuits, and foreclosures makes the software a very powerful and informative tool for visualizing a suspected provider's fraudulent activity.

With respect to the network attributes we've been discussing in class, there are a few that I can think of that are directly applicable to these types of networks:

Fraudulent providers can have a low degree centrality - in this type of fraudulent behavior, the individual operates independently of the other providers in the network. In a typical provider network, there is high connectivity, so this metric is indicative of potentially suspicious activity.
Fraudulent providers can have high betweenness - in this type of fraudulent behavior, the provider serves as the boundary spanner between the densely-connected network core and nodes with very few (or no) other connections. The betweenness metric can help to identify providers that are operating under fake aliases in order to gain more revenue. 
Fraudulent providers can have open triads - in this type of fraudulent behavior, a provider has relationships with other providers that do not have relationships with each other. This ensures that the fraudulent provider controls the information that is passed from one node to the other. 
Fraudulent providers can form their own cliques - in this type of fraudulent behavior, many providers are in on the same ""scheme"" and tend to be clustered together. If a provider is found to be fraudulent, it is a good idea to look at the other providers that are within that cluster.
Since fraudulent providers are such a small portion of the entire provider network, creating an algorithm that is 99% accurate may actually classify all providers in the network as non-fraudulent. Because we are interested in identifying the providers that are actually fraudulent (positive cases), we should measure the accuracy of the model in terms of the true positive rate (sensitivity). Sensitivity, or recall, is the proportion of true fraudulent cases that are actually detected. A high sensitivity means that we detect a large number of the providers that are fraudulent. "
Provider Fraud,2,Vijaya Cherukuri,Amber Ferger,"Very nice information Amber. With enhanced provider network we can have high chances to identify the fraud.
Similarly from the front end, by using big data and better network model we can reduce many frauds."
Provider Fraud,2,Jagdish Chhabria,Amber Ferger,"Hi Amber - is it just medical providers who perpetrate this fraud or does the network include patients as well? My understanding is that if a particular set of patients show unusual and repeated visits to medical facilities, they would end up seeing increased medical premiums, isn't it? So how exactly does fraud against health-care companies work? And don't the medical facilities or providers involved in this, risk losing their license to practice medicine? Given that medical providers typically make higher than average income, I wonder how high is the payoff from fraud to make this attractive to someone like that?"
Detecting Corruption,1,Murat Akyildirim,Murat Akyildirim,"Similar to Fraud Detection example we can use network analytics to detect corruption such as insider trading or cash payments for favorable actions for other companies and bribery within organizations. “Which person will commit to corruption based on the supplier (or companies or individuals or resources) they work with?”

People commit corruption because they know other people who have done the same. Challenges are the same as the fraud example; uncommon (number of corrupted activities are smaller), well considered (recent data is more important), imperceptibly concealed (expert level input might be required -investigators, detectives or someone with similar past), time evaluating (something that is considered as corrupt and not ethical may not be considered the same tomorrow – for example, I heard real estate broker’s had something called finder’s fee in the past which would allow them to give preference on the buyer with a certain fee in the past which is now illegal) , carefully organized (example: organized crime family)

We can use bipartile graph 2 nodes where one node represent the people and the other represents the suppliers (or resources) they work with. Transactional data we can use are the phone calls between the suppliers and people and between everyone’s, bank data (wire transfers and etc…) and text messages between everyone.

Nodes <- individuals

Black nodes <- corrupted individuals (maybe individuals that committed corruption in the past)

Triangle nodes <-suppliers

Triangle black nodes <- corrupted suppliers

Similar to the example, we also want homophily , where people tend to connect to other people with similar interest and goals. Which leads to the corrupt individuals would most likely be connected to each other. We want homophily for model accuracy.

In terms of feature extraction, we can look at the degree (how many corrupted individuals connected to each other)

The network model that we would create would be better than a model that does not include the network in terms of predicting corrupted activity as it would distinguish the bribery or other corrupted behavior better. We look at accuracy, precision and recall. Precision with network model would be better in terms of giving us the potential corrupted individuals. Network model would also detect more corrupted individuals compare to non network model"
Detecting Corruption,2,Mikhail Kollontai,Murat Akyildirim,"Murat, this is a fascinating take on corruption that reminds me a little of the stereotypical cork boards with red string used in investigations on TV. Find the individuals and track their networks. In addition to the number of corrupt individuals connected to each other, having information of the extent of their interactions would provide a potential ""weight"" to the edges, helping track individuals who have a more than normal amount of contact with the corrupt, perhaps assisting in identifying new players. "
Insider Threats,1,Mikhail Kollontai,Mikhail Kollontai,"Monitoring internal network interactions can help a firm identify potential insider threats. There are certain types of behavior and trends associated with network access activity, time logging, etc. that can help identify high risk individuals automatically. Each account within a network can be considered a node as can every network device. With time each employee will have a regular network of machines they interact with. Sudden changes within the edges between the user node and the machine nodes (especially a large number of new edges leading to previously unused machines) can be an early indicator of malicious activity. There is software available that will track the network connections within an organization and automatically flag such outliers for deeper analysis. 

Relevant Article:

https://www.plixer.com/blog/how-to-mitigate-insider-threats-with-network-traffic-analytics/"
Insider Threats,2,Subhalaxmi Rout,Mikhail Kollontai,"Great post, Misha, insider threats make trouble to the organization. Companies applied some measures to identify the treat such as user credential being used from different locations, different devices to connect (user never log in to that device), login attempt to multiple devices, etc. Using “network traffic analytics” companies can monitor and identify that device that has been infected."
Insider Threats,2,Mael Illien,Mikhail Kollontai,"That's interesting. While it makes sense, I didn't think the proportionality of negligent employees would be so high in insider breachers. It now makes a lot of sense why my company's IT is always testing us with phishing attacks."
Russian Twitter Troll Detection,1,Mael Illien,Mael Illien,"Here is a great example of social network analysis involving the interference of Russian twitter trolls in the 2016 US election. A Neo4j analysis was performed to identify the troll networks as reported in the NCB News article sourced below below. You can see the twitter trolls in action by examining the dataset provided which contains sample tweets from 10 influential twitter trolls. The Neo4j case study explains how they studied relationships between username, tweet content, hashtags and links. By using centrality measure like pagerank and community detection algorithms the researchers were able to find who were the primary influencer trolls, and who were the retweeters that amplify the message. Using the temporal aspects of the the dataset, they were also able to identify that troll tweets were mostly posted by computers instead of a mobile device, and that tweet spikes occurred during the working hours in Russia.

Out of the different types of troll account, some of the usernames were chosen to resemble typical Americans such as @LeroyLovesUSA. Others mimicked news sites such as @ OnlineCleveland. A third category pretended to be political organizations such as @TEN_GOP, which represented itself at the Tennessee Republican Party.

In looking at the error rate, I think it is easier to correctly identify the influencers, based on the patterns discussed above. However, I imagine the error rate would be higher when detecting amplifier trolls because it is possible that false positive users are simply retweeting the original troll without being a participant in the troll network. A lot of the propagation strategy has to do with normal users diffusing the tweet containing the misinformation to their own ego networks.

Sources:

NBC News: Twitter deleted 200,000 Russian troll tweets. Read them here.

NBC News Analyzes Hundreds of Thousands of Russian Troll Tweets Using Neo4j

Dataset - Ten sample influential Russian trolls"
Association Health Plans,1,Sheryl Piechocki,Sheryl Piechocki,"Association health insurance plans are health insurance plans for individuals that are part of some professional group.  By banding together in the association, the individuals who are not otherwise eligible for a company insurance plan, can get cheaper premiums and better benefits than buying individual health insurance.  Examples include: professional associations for self-employed individuals like plumbers or electricians, and freelancers.   

Fraudulent associations have been discovered by insurance companies.  In these cases, members of the association are not part of any professional group, but rather are extended family groups or social groups.  Social network analysis could be used to identify these fraudulent associations.  Members that are included in a health care association form a network, this network could be compared to other public social networks (FB, Twitter, etc.) to determine if there is overlap in the networks and how much overlap.  A suspected fraudulent association could then be analyzed further, comparing addresses of individuals, and known family relationships.  "
Association Health Plans,2,Jit Seneviratne,Sheryl Piechocki,"I wonder if insurance companies can avoid these networks forming altogether by allowing groups (maybe 20 to 50 people) get a community plan. I know it sounds a bit far-fetched, but why not? Anyway, this is a good example of using network analysis to identify questionable clusters.

"
Tax Evasion Fraud,1,Elina Azrilyan,Elina Azrilyan,"The presentation in the video lecture makes a very good point about considering Fraud as part of a Social Network - it is likely that people who commit fraud are telling their friends and business connections about it and there could be a benefit in considering that in Fraud detection efforts. This could be utilized when identifying tax evasion fraud - if there is a node on the network that an individual committing fraud uses as a “write-off” (charity or an employee) - an investigation of all other nodes (tax-payers) linked to this entity would need to be suspected of fraud as well. We could use centrality measures to identify the node that might be driving this fraud on the Network and thus further improve detection by focusing on their direct connections. Maybe there is a common geography, business partnership or tax preparer. Corporate tax evasion might be detected for companies based on shared resources such as infrastructure, employees or equipment. "
Insurance Fraud Detection,1,Vanita Thompson,Vanita Thompson,"Social networks help insurance agencies connect with their customers for branding and marketing purposes. In addition, insurance companies use acquired data for fraund detection. Social Network Analysis allows insurers to proactively look through large amounts of data to show the reltionships of links and nodes. Having the ability to collect this data gives an insight to the parameters involved in an insurance fraud case. The Social Network Analysis Approach includes organizational business rules, statistical methods, pattern analysis, and network linkage analysis. When looking for fraud, SNA uses cluster analysis, like linkage analysis to rate claims. Public records like judgements, foreclosures, criminal record, and address change frequency can all be used for rating. A high rating, indicates fraud. Technologies such as text mining, clustering, sentiment analysis and content categorization are used in SNA to build predictive models.

Reference
https://www.the-digital-insurer.com/wp-content/uploads/2013/12/53-insurance-fraud-detection.pdf"
Network Analysis - Organized Crime,1,Zachary Alexander,Zachary Alexander,"As mentioned in the lecture by Veronique Vlasselaer, network analysis can be used in myriad fields. One field in particular that I found is incorporating network analysis is via law enforcement and organized crime. Similar to Veronique's example of working with unipartite and bipartite graphs, measuring connections as well as resources, this is also true for organized crime networks. A paper published by Anine Kriegler, from the Institute for Security Studies (ISS) titled, ""Using social network analysis to profile organised crime"" documents the social network analysis conducted on a massive and complex South African arms deal in the late 1990s, which raised allegations of corruption resulting in numerous criminal cases.

By attaching different types of relationships to edges, the ISS team was able to graph out the extensive network of contractors, senior-level officials, and shareholders throughout the ordeal. Similar to the lecture's tactic, the ISS team categorized, and then isolated the types of relationships, measuring which relationship types were most common in terms of facilitating the potentially corrupt transfer of resources. This tactic has proven to be very insightful, and could be developed further for more recent corruption analysis and to better inform how these types of exchanges of resources and bribery tactics play out in a larger social network. The paper does also go into detail about the centrality measures that were measured, but is quick to warn that many of these centrality measures are limited based on the number of connections between nodes, and doesn't touch on the weights of edges. If this type of analysis were to be utilized in the future, considerations of the level of severity of corrupt exchanges would need to be better formalized (in order for officials tracking the network to triage the most corrupt players), as well as making sure that there was a good handle on the temporal aspect of nodes moving in and out of the network -- the ISS team acknowledged that this was lacking from their analysis of the famous arms deal.

An ""error rate"" may be quite high if this type of network were adapted to a current illicit organized crime network. Without these factors established (i.e. temporal players, edge weights based on severity of resource exchanges, etc.), it could potentially lead to false positive predictions of individuals that ""will become corrupt"", (but actually don't) while simultaneously flag false negative predictions of individuals ""that will not become corrupt"" (but actually do)."
Physical Risk to Patients,1,Vijaya Cherukuri,Vijaya Cherukuri,"Shockingly, the perpetrators of some types of health care fraud schemes deliberately and callously place trusting patients at significant risk of injury or even death. It's distressing to imagine, but there have been many cases where patients have been subjected to unnecessary or dangerous medical procedures simply because of greed. Unnecessary procedures can result in countless irreversible outcomes such as patients losing their ability to have children or losing full physical mobility.

In health care there is a seperate depatments called Utilization management and Fraud, waste and abuse them that uses natural language processing and many algorithms to identy the fraud cases and also determine where fraud schemes are followed by few practitioners/providers.
In fact, Medicare conducts reviews on less than three percent of medical claims before sending out checks.

How network analysis can help reduce the fraud.

1) More reviews on medicare claims while processing.

2) Stopping Fraud on the Front-endUsing big data and what’s called “social network analytics,” healthcare agencies can now reverse the traditional investigative process. Rather than starting with one suspect individual and then building out the network of contacts and business relationships, the new process begins with data. Lots of data — as much as 50 terabytes.

3) In Providers, if we can conduct a degree of centrality, and advanced algorithm to find the fraud providers.

"
Physical Risk to Patients,2,Habib Khan,Vijaya Cherukuri,Nice work VIjay. Thanks for sharing.
Physical Risk to Patients,2,Sheryl Piechocki,Vijaya Cherukuri,It seems the insurance industry is a target for fraud in many different ways by many different people.  By implementing these types of fraud detection we can help to lower insurance costs for everyone.
Fraud detection in banking sector,1,Habib Khan,Habib Khan,"Social network analysis is one of the emergent data mining methods in fraud analytics which comes out pretty useful to identify irregular payment transactions to avoid any loss to the bank and customer both. In fraud detection, the interactions can be viewed as heterogeneous networks with multiple participants. Usually, number of participants are huge. Graph analysis techniques can be used further to identify suspicious individuals, groups, relationships, unusual change over time or geography. Some of popular network analytics are following:

1- Network visualization and eg-centric canalysis

2- Graph walking to identify rings

3- Centrality measures

4- Snowball method

5- Network topologies

There are lot of challenges for fraud detection which can be helpful to improve the accuracy of fraud detection. Lack of automation in network analytics in fraud detection and the need for expert analysis and interpretations are needed to improve the error. Data analysts should have a good knowledge of domain which would be very helpful for effective network analysis.

Reference:

https://www.mphasis.com/content/dam/mphasis-com/global/en/nextlabs/resources/home/whitepapers/Social-Network-Analytics-for-Fraud-Detection.pdf"
Fraud detection in banking sector,2,Simon Ustoyev,Habib Khan,"I suppose in banking, the success of fraud detection is centered around KYC (know-your-customer) in order to establish the patterns of legitimate transactions and behavior for a given client.  SNA would then be well suited to find outliers or unusual behavior and also to detect if anything is connecting to already known or highly suspected fraudulent nodes.  I agree that a good knowledge of domain is required here."
Enron and SPEs,1,Jit Seneviratne,Jit Seneviratne,"We briefly discussed Enron last week, and I remembered how Enron used Special Purpose Entities (SPEs). One way it used SPEs whas to consolidate assets of the SPEs and not the liabilities. I wonder if there is a network structure that can identify unusual SPE's where edges are asset/liabilities owed to and expected from the parent entity. Just a thought!"
Distinguishing Manipulated Stocks,1,Simon Ustoyev,Simon Ustoyev,"Here's a link to a study which attempted to distinguish manipulated stocks from non-manipulated, by analyzing trading behavior using network analysis.

http://www.bigdatalab.ac.cn/~shenhuawei/publications/2011/pa-sun.pdf

Below is an extract from the conclusion of the study:

""...By comparing the degree and strength distributions between non-manipulated stocks and manipulated stocks, we find that manipulated stocks have a higher lower bound of the power-law tail, and higher average degree of the trading network than non-manipulated ones. By analyzing the correlation between the price return and seller–buyer ratio, we find that manipulated stocks have a lower correlation than non-manipulated stocks.""

 

It could be a challenge to interpret and understand the study.  If you're wondering what power-law is, I found this link helpful: 

https://www.statisticshowto.com/power-law/

 

I could be wrong in my interpretation, but here's how I understood the conclusion of the study in more lame terms.

With manipulated stocks one can observe more aggressive trading done with more investors (i.e. trading counterparts).  Intuitively this makes sense because in order to capitalize on a stock manipulation, you would increase trading activity and enlarge the pool of market participants.

 

Below is a link to another interesting market manipulation scandal (on LIBOR rate), which one can think about how useful SNA could've been in detecting it.

https://www.theguardian.com/business/2017/jan/18/libor-scandal-the-bankers-who-fixed-the-worlds-most-important-number"
Distinguishing Manipulated Stocks,2,Murat Akyildirim,Simon Ustoyev,This is a good one. thank you for sharing Simon.
Fraud detection in online lending,1,Steven Ellingson,Steven Ellingson,"With online lending, fraud is rampant and is something that is constantly being combatted with. 

One piece of data that could be attempted to validate with social network analysis is The employer.


We could look at a bipartite social network to determine the likelihood that this person works where they say they do. How many connections do they have with other people in that field, in that specific employer?

Error rates are tough for this type of thing.  You are looking for something that doesn't happen often, so if your model ALWAYS said that there was no fraud involved, the error rate would actually look pretty good.  You would never deny only customers who are more than 50% likely to be fraudulent, you need to have a probability to determine the level of risk you are ok with. If the model makes your overall fraud model more accurate, then it is worth pursuing.  The difference between a 1% fraud rate and a 1.1% fraud rate could have a huge effect on the profitability of a company."
Using network analytics to detect money laundering,1,Jagdish Chhabria,Jagdish Chhabria,"I came across an interesting article published by Mckinsey & Co. that discusses the use of network analytics to detect money laundering. The underlying use case has the same properties as others where SNA is used - compared to the total number of money transfers, the proportion of those used for money laundering is very low. Having said that, the article suggests using relationships between different types of nodes - 1) individual account holders or business entities and 2) accounts, the attributes of these nodes such as location and the depositary institution, and finally the attributes of the transfers (edges) such as direction, frequency and amounts, as a way to detect money laundering.

The article is available at the following link:

https://www.mckinsey.com/industries/financial-services/our-insights/banking-matters/network-analytics-and-the-fight-against-money-laundering"
Uber API Restrictions Controversy,1,Simon Ustoyev,Simon Ustoyev,"I found 2 articles (one siting the other), which describe controversies around Uber's restrictions of its data.Â  There may not be as much limitation on using Uber's data for some downstream analysis, as oppose to the limitations as to how you can use this data and the type of products you are allowed to develop based on this data.Â  In the article, Uber cut off access to its API for a Boston based startup which was looking to provide price comparisons between major ride-hailing services.Â  There's a possibility that this move by Uber could violate antitrust law.Â  Ironically, Uber itself relies on 3rd party API for maps, payments and messaging.
This article essentially demonstrates that while a 3rd party, private data provider, like Uber, may increase or promote a wider use of its data, it may also decrease or impose on the scope of what can be built on top of its data.
http://fortune.com/2016/06/06/harvard-uber-api-restrictions/
http://www.benedelman.org/news-053116/"
Uber API Restrictions Controversy,2,Subhalaxmi Rout,Simon Ustoyev,"Interesting post, Simon! Due to Uber API restriction, there are benefits and flaws. The benefit is API restrictions are designed solely to advance the companyÃ•s business interests by blocking competition. So, Uber alone controls information about the price and availability of its vehicles. Due to the restrictions, a third-party company uses real-time information about vehicle location (how many minutes until a vehicle can pick up a passenger at a given location) impacted."
Freedom of Information Act (FoIA),1,Habib Khan,Habib Khan,"The Freedom of Information Act is a federal freedom of information law that requires the full or partial disclosure of previously unreleased information and documents controlled by US government if requested. It has somehow discouraged government officials to follow the constitution and facilitate the US Citizens as per the role in government. The citizens can always ask for the information, evaluate and criticize those decisions.Â 
Reference:
https://en.wikipedia.org/wiki/Freedom_of_Information_Act_(United_States)"
NBA Play by Play,1,Steven Ellingson,Steven Ellingson,"Detailed play by play statistics used to be available for free for the National Basketball Association.Â Amateur analysts were taking that data and coming up with metrics to evaluate basketball players. Tons of interesting work was being done.Â  Then it was gone.Â  Â I'm not 100% sure if the NBA itself provided the data or if there was a company that was providing it for free that started monetizing, but it became completely inaccessible to most of us.Â 

More than anything, this is a bummer for those of us who like to sports analysis in our free time.Â  There was so much interesting information in those datasets, and most of us aren't going to pay to get it as we aren't getting paid for our work."
Fintech Data Aggregators,1,Jagdish Chhabria,Jagdish Chhabria,"One area where there have been many interesting twists and turns over the past decade has been that of financial data aggregatorsÂ such as Mint (owned by Intuit), YodleeÂ (owned by Investnet) and Plaid (owned by Visa) that allow customers to download anÂ appÂ (mobile or desktop)Â and aggregate their banking, investment and other data held with different institutions and providersÂ in a single consolidated view. There seem to be 2 ways for these data aggregatorsÂ to access this data - either through an API or through screen scraping. Also there are differences in how these aggregatorsÂ set up the initial authentication and on-boarding process of connecting to a ""new"" account. In general, it looks like initially many banks were fine with providing this access as long as customers provided the permission, but over time, a combination of regulatory scrutiny about customer data privacy, data security and lastly the evolution of their own business models to monetize or come up with their own competing services (typically as a consortium) kicks in and they start limiting access or the mechanism of access available to the data aggregators. For example, it seems you can integrate a Bank of America accountÂ on the Mint appÂ but not a PNC bank account. It's hard to argue that each bank is taking its own view of data privacy and security. To me, it seems more of a business strategy being played out as banks who initially let fintechsÂ take the lead to figure out if a business model is viable are now wanting to enter the game themselves.Â 
In any case, the data aggregatorsÂ could find themselves in trouble if more banks restrict access via screen scrapingÂ  - at the very least they'll need to make changes to their data access layer in case the API changes. Some could even see a significant change in cost of business. It seems safe to say that while ""Data is the new Oil"", it's important to keep an eye on who owns the drilling infrastructure and when they may decide to start their own refineries and gas stations."
Provider In/Out network data accessibility,1,Vijaya Cherukuri,Vijaya Cherukuri,"Provider In/Out network data accessibility :
Whenever there is a need to visit hospitals or doctors we might take an appointment and go to the hospital/physician.We dont know wheter the doctor/physician is IN/Out network to the health insurance.
Health insurance companies charges seprate maximum out of pocket charges and diagnosis charges for Out network when compared to IN network doctors/hospitals/physicians.
We have lack of data availability to check whether the doctors/hospitals/physicians is IN network or not. If we have ability to see this data then we can choose the nearest IN network physician and get the medication.Good example is if IN network maximum out of pocket is 3k then for OUT netowrk it will be around 6K.
All of us will be benefitted if we have the availability of data to check who is IN network or not."
Provider In/Out network data accessibility,2,Sheryl Piechocki,Vijaya Cherukuri,"Vijaya,
Transparency is needed in all aspects of the health care system.Â  One never knows what their bill will be if they go to the doctor.Â  We cannot shop around.Â  The ability to compare provider costs would greatly benefit the consumers."
Provider In/Out network data accessibility,2,Simon Ustoyev,Vijaya Cherukuri,"The cost information, I would think, is not available as it depends on your medical case or situation.Â  However, In/Out of network data and co-pay data should be available through the insurance provider.Â  Perhaps such data should be more readily available and accessible in a convenient UI or API form."
Facebook's Graph API,1,Zachary Alexander,Zachary Alexander,"This is actually a very timely article, since recently a friend reached out to me asking if I could assist in a project that required utilizing Facebook'sÂ Graph API to search for relevant statuses and posts based on a certain set of keywords. I have worked with Twitter'sÂ API in the past, and was interested in diving into Facebook'sÂ Graph API a bit given the context I'm learning in this course. I found documentation onlineÂ to utilize Facebook'sÂ API to conduct this keyword search, however, I realized when running the script, the function(s) I used had been deprecated. One in particular was the searchFacebook() function.Â After doing some investigative work, a few of the functions had been deprecated back in 2015 when Facebook did a massive overhaul of it's API.
Although I was hoping to work with a friend on a small project, as mentioned in the Wall Street Journal Article, these changes have huge implications for company's and developers that rely heavily on this data to create third-party applications. These changes over the past couple years have limited the types of things startups and entrepreneurs are able to do with social network data, and some would argue that it stymies the growth of the field. I do think that many of these changes are positive for social network users, and allows for broader protections of privacy of information and data. It'll be interesting to see how this progresses over the next few years, as a person's individual ""data"", whether it be social network data, health data, financial data, etc., is becoming more of a central part of one's capital. As we can see, this change by FacebookÂ has limited me and my friend's ability to do any downstream analysis (or at least making us go back to the drawing board), and for product development, it's completely changed the way certain startups develop their products and what types of ideas will be successful in the future."
Patriot Act,1,Mikhail Kollontai,Mikhail Kollontai,"Passed shortly after 9/11 during a time of heightened fear and paranoia, the Patriot Act significantly altered access to a wide swath of data on everyday Americans' communications. The trouble is that the access to the data was opened up to the government and no one else, allowing for unprecedented surveillance by various branches of the government without previously proven cause and court-approved warrants. The passage of this bill was widely supported by both parties; public sentiment at the time was something akin to ""whatever it takes to keep us safe"". It was a time when the public was so worried about what would come next, it was ready to accept a rule that allowed the government to spy on it without any real oversight.
What seems interesting to me is that the act has since been renewed consistentlyÂ every time it has needed to. On May 19, 2020 a provision allowing the government to search a citizens browser history was added.Â Â (https://thenextweb.com/security/2020/05/14/the-us-senate-just-voted-to-let-the-fbi-access-your-browser-history-without-a-warrant/)
Obviously access to such a glut of information can provide invaluable intelligence to law-enforcement agencies. The merit of such measures though assume that it will never be used inappropriately.In light of what we have been seeing over the last month or so I think that assumption needs to be closely looked at and re-evaluated."
Patriot Act,2,Habib Khan,Mikhail Kollontai,"Hello Mikhail,
That was a good topic. Thanks for sharing.
Regards,
Habib Khan"
Patriot Act,2,Sheryl Piechocki,Mikhail Kollontai,"Mikhail,
Excellent example and topic!Â Â The government uses times of heightened fear to expand its power.Â  They claim it is being done to protect the people at these times, but as you note, it quickly becomes a rule of law.Â  Some have theorized that the government likes to keep the people in a state of fear.Â  This allows them to pass these sorts of acts that increase regulations and surveillance, and sometimes increase taxation.Â  Privacy is invaded and freedoms are reduced.Â 
Will the COVID-19Â pandemic lead to new regulations?"
General Data Protection Regulation,1,Jit Seneviratne,Jit Seneviratne,"TheÂ General Data Protection Regulation (GDPR)Â is popularly known as 'the right to be forgotten'. The EU regulation lays out how and when data can be collected, processed and erased. It (theoretically at least) gives users of social media platforms more agency, and more protection. Perhaps the catalyst for the GDPR was the Cambridge AnalyticaÂ scandal, where user data was used for highly unethicalÂ psychological profiling and manipulation."
General Data Protection Regulation,2,Priya Shaji,Jit Seneviratne,Good information!Â Perhaps GDPR needs to be followed by many organizations.
LinkedIn,1,Sheryl Piechocki,Sheryl Piechocki,"In 2015,Â LinkedInÂ restricted some of their publicÂ APIsÂ accessibility to only partners ofÂ LinkedInÂ (e.g.Â Samsung,Â Evernote).Â  The company said restrictions were put in place because not all the applications being developed by third parties were providing value.Â  The connections, groups and people searchÂ APIsÂ would no longer be available to non-partner developers.Â  Â In addition, permissions were put in place to restrict access to some of the APIs to only administrators or to require LinkedIn approval.
Many third-party developers that had LinkedIn data integratedÂ were affected by this change.Â  Some of them were job board apps and apps that showed users their network.Â  Not having access to the connections API greatly affects any network analysis.Â Â 
By restricting access to this data, more traffic will go through LinkedIn or its partners thus increasing potential ad revenue.
https://venturebeat.com/2015/02/12/linkedin-revamps-its-developer-program-to-focus-on-partnerships-will-limit-its-apis-on-may-12-2015/"
LinkedIn,2,Zachary Alexander,Sheryl Piechocki,"Thanks for posting this,Â Sheryl -- your points made me think about the ramifications this may have for access to data in the future.Â As an aside,Â I'm a strong proponent for broader privacy protections for users, but API restrictions such as these could also lead to negative consequences of allowing a few large tech companies (i.e. LinkedIn, Facebook, etc.), harnessing all of the individual data capital. As discussions develop about one's data being an instrumental piece ofÂ their identity in the future, it'll be interesting to see how this all plays out! Anyways, appreciated your post!

Best,
Zach"
LinkedIn,2,Murat Akyildirim,Sheryl Piechocki,"I believe since the restriction of the use of the api, some developers scrape linkein profiles and connections in order to access the data. (Regardless of the data being behind the login) I think stricter data privacy rules are ahead of us. Thank you for sharing!"
Managing impacts of data changes,1,Elina Azrilyan,Elina Azrilyan,"The following article discusses the approach to managing changes in the APIs used for Shopify App and brings up a lot of interesting questions about down-steam data dependences we are discussing this week. Shopify is a Canadian website that allows a person to manage, market and sell their product, and APIs are widely used by tens of thousands of partners. A new versions are released quarterly to minimize the impact of changes and the changes are clearly marked and breaking and non-breaking to make sure that all required diligence is applied. Similar approach should be taken on data availability, if there is a regulatory or financial reasons for the change in data level access - there should be a significant thought given to such changes. If facebook data availability decreases - there should be a way to view a subset of the data anonymously if at all possible.Â 

https://engineering.shopify.com/blogs/engineering/shopify-manages-api-versioning-breaking-changes"
Google's monetization of Google Maps API,1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"Last year Google announced a new pricing strategy for users of their previously free Google Maps API in which depending on monthly user flow, they now charge a significant amount of money to the creators. Many developers claimed that the new strategy killed some of their larger projects. Other developers were forced to switch to other map system like Apple Maps, or OpenStreet map."
Google's monetization of Google Maps API,2,Mikhail Kollontai,Abdellah Ait Elmouden,I think this is an unfortunate but inevitable result when an appÂ grows to such popularity without having an obvious revenue stream - there is simply too much untapped potential to let that go to waste and a company is loathe to let that go.
Available Real Estate and Brokerage Data,1,Murat Akyildirim,Murat Akyildirim,"Scraping data from web and applications along with use of different provided apis have increased in the recent years with the hopes of generating leads for marketing and sales teams. Prior to the recent privacy changes developers were able to scrape and use data from linkedin, twitter, foursquare and even real estate portals such as trulia or zillow. Zillow used to offer free access to their listing database along with the real estate brokers in the past, which helped individual local Real Estate Firms (such as Exit, Coach and etcâ€¦ in certain locations) to collect and use this information. These small local firms and even individual brokers were able to work with developers to collect and consolidate the available data from Zillow and create their own web property to acquire consumers.
With the recent data privacy changes and the change in the business model, Zillow now requires individual real estate firms and brokers to sign up for membership in order to receive this data. They also have a new program where they share consumer information from the data they collect via their newsletter."
Deprecated Financial Data APIs,1,Mael Illien,Mael Illien,"The Google Yahoo Finance APIs were the go to API for acquiring free financial data. A lot of apps using data from these APIs abruptly lost their data source when the services were either deprecated or became service users needed to pay for. These days, there are ways to connect to the yahoo api but the endpoints are few and the documentation poor. Many alternatives such an Quandl, Alpha Vantage, etc have sprung up to fill that hole in demand. These sources offer free access to data up to a certain number of calls a day, and paid versions for premium access.
While in some cases switching the data source can be as simple as changing the python library you are using, in others, entire databases relying on a previous source of data may need to be recreated and the code to update it rewritten. This makes the case for abstraction in object oriented programming where data handler components should be written in such a way that swapping a data source leaves the rest of the programâ€™s execution unaffected.
In operations where lots of money is traded and timing can be critical, losing a data source is a big problem and the implications serious for a business as was the case in the examples mentioned in the reading. This brings to the forefront the issue of relying on third parties for data sources and the way to preserve the continuity and integrity of data."
Electronic health records,1,Priya Shaji,Priya Shaji,"Electronic health records have been widely adopted across healthcare organizations large and small. While there are many benefits to EHRs like improved accessibility to patient data, increased charge capture and improved preventative health , there are inherent problems in adopting this technology.

Since EHRs allow for easier access to sensitive information, there is an increased risk of privacy violations. These may include intentional ""snooping"" or may be accidental by using improper security measures. But there are many systems that have implemented a forensics piece to track what files are accessed when and by whom.

Taking the time to evaluate new technology andÂ Â  implement a new process, such as to evaluate workflows and identify and eliminate waste before implementing a new EHR system, will help improve implementation, foster communication, decrease non-value added work and ultimately increase adoption.

More information on EHRs:Â https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5171496/"
Electronic health records,2,Vijaya Cherukuri,Priya Shaji,"Great information Priya.
EHR is a sensitive data. With enhanced ability to identify who is accessing the data and more information of how they are collecting can reduce the risk."
Electronic health records,2,Abdellah Ait Elmouden,Priya Shaji,"Electronic Health Records Can Improve Patient Care, but the largest technology companies benefit more Including Microsoft and Apple because they they could create products for the health industry."
Flight Prices - Skyscanner,1,Amber Ferger,Amber Ferger,"Access to travel information has increased drastically over the past decade or so.Â With so many airlines to choose from, some companies have found success in providing a one-stop-shop for flight information across airlines. This allows users to more easily compare prices, flight times, and durations when making their travel decisions. Some companies, like Skyscanner, have taken this a step further by providing developers with access to this information through a RESTfulÂ API. The company appears to be marketing to website owners -- a quick look at their website specifically markets the use of the API to build websites allowing users to search for information themselves.
Any company looking to provide the search functionality to their users (ex: travel sites) can benefit directly from this information. Rather than having the user go to another site to compare flight information and prices, they can view everything in one spot. This provides for a seamless user experience and might influence a customer's decision to use the site again.Â 
Unfortunately, any business that utilizes this information as a main component of their website is at the hands of skyscanner. Should skyscannerÂ remove access to the information, an entire component of a company's business model might be removed. This is similar to what happened with Google'sÂ deprecation of the Google Flights API...many users that were dependent on this information were left scrambling trying to find an alternative solution."
Flight Prices - Skyscanner,2,Ken Popkin,Amber Ferger,"Good example for this discussion, and your note that any business using this API is at the hands of SkyScanner is definitely a risk worth considering.Â 
I wouldn't expect there to be privacy issues like Facebook has been dealing with.Â  But, I could see SkyScanner make an effort to monetize their API's, at which point the ROI for some businesses would not be high enough to continue using this data."
Twitter web-based data restriction,1,Subhalaxmi Rout,Subhalaxmi Rout,"Twitter restricted access data after the New York Times revealed that Facebook had given device makers deep access to data on Facebook users and their friends, via device-integrated APIs.Â The goal of twitter is ensuring platform safety and promoting the privacy and safety of users, and providing a level playing field commercially.
Who was impacted negatively by these changes?
Third-party developers are negatively impacted since their business model relied on users' data. Twitter removed more than 143,000 apps that violated its policies between April and June 2018, and they are continuing to invest in building out improved tools and processes to help them stop malicious apps faster and more efficiently.
Who impacted positively by these changes?
Twitter users are impacted positively because their data has not been exploited. Twitter has given users more control over their data by making privacy settings easily accessible.
What implications if any are there from the standpoint of being able to use this data in downstream analysis and/or product development?
The changes will impact multiple developer-facing APIs, including those used to create social experiences on the site, as well as those for media partners, and more. Many third-party developers will look elsewhere (other social media platforms) to collect user data to innovate and stay in business. I also think the availability of data helped many developers create innovative products. These products make us efficient and add value to our lives. Due to some bad actors, a lot of good work has been impacted.
Reference:Â Â https://blog.twitter.com/developer/en_us/topics/tools/2018/new-developer-requirements-to-protect-our-platform.html"
Twitter web-based data restriction,2,Amber Ferger,Subhalaxmi Rout,"Great example!Â Any developer that uses third-party informationÂ as a key component to their business is at the mercy of the third-party and the twitter data restriction is a great example of that.Â Apps, sites, and businesses that rely heavily on previously-available data have to adapt or go under."
Stock Market Data,1,Ken Popkin,Ken Popkin,"In 2006, I read a book called ""Rule 1 Investing"" by Phil Towne.Â  In sum, the book shared a value based (think Warren Buffett) approach to find stocks to invest in. I decided to write my own application that would input a large number of stocks, complete my analysis, and provide a recommendation. (I was sure I'd become wealthy :)
I wrote the application, but when it came time to start analyzing in bulk, I hit a snag.Â  The lowest priced real-time stock prices subscription that I could find would run me a few thousand per year for the raw data I needed. I ended up becoming really good at screen scraping (And in case you're wondering, ""Nope, I didn't become wealthy).
This evening, I did a similar search on real-time stock price subscription services. Here's my perception based on a quick review of the search results...
1. there are more companies offeringÂ this type of service
2. finding articles comparing stock services is easier, i.e. titles like ""Best Free Real-Time Stocks for Day Traders"", ""API for Free Real-Time Stock Market Data"", etc...
3. I looked at prices for three companies promoting real-time stock API's.Â  Two of them where charging several hundred per month (same as my experience in 2006).Â  But, one called Alpha Advantage looks promising and says they are free.
So, in sum my perception is that real-time stock data (and other information about stocks) is more available today than it was ten-plus years ago and is offered by more providers.Â  As for price, maybe it's cheaper too, but you still have to search pretty hard to find a good deal (if there really is one).
(Note: this is a biased comparison as I spent days/weeks in 2007 on this research, versus minutes on my search for this discussion)."
Stock Market Data,2,Jack Russo,Ken Popkin,"That's fascinating!Â At the end of the day there really dosen'tÂ appear to be free lunch here. Even if the data you needed to automate your strategy becomes affordable do to availabilityÂ and competition, the consequenceÂ Â will be more investors applying the same strategy."
Stock Market Data,2,Mael Illien,Ken Popkin,"I wrote a discussion post on the same issue.Â I have been usingÂ https://finnhub.io/Â as my API of choice these days. I don't pay for any of the data so I have to introduce calls to sleep() every so often in order to avoid overloading the 60 apiÂ calls per minute offered under the free plan. This is kind of a problem if speed of execution is an issue. If I am updating 600 stocks, it will take 10 minutes, which is fine for a daily strategy, but not so much for an intradayÂ one. Since I don't intend to trade 600 stocks at once, I could get data down to the minute by making prioritized calls to get the tickers of interest and updating the remainder at a later time in off market hours. Otherwise, payment for data remains an option but it can add up to be a significant cost as you've mentioned."
Stock Market Data,2,Steven Ellingson,Ken Popkin,"This is very interesting. Stock data is interesting because everyone wants to make money on the stock market and it's so competitive.Â 

I will have to look into Alpha Vantage. I don't expect to get rich :)Â  but it could be fun!Â  Thanks for sharing."
Stock Market Data,2,Jagdish Chhabria,Ken Popkin,"Nice observations. In general, the initial data collectors for stock prices in the USÂ (NYSE, NASDAQ, CME) and distributors (Bloomberg, Refinitiv) will always have priority in deciding who they sell this data to and how much their charge. So retail investors who believe they will somehow strike it rich by writing a few lines of Python code will always be at the mercy of upstream access changes to the underlying data. The onlineÂ brokerages typically provide stock screening services sitting on top of the data they have, but don't act as straight-up data providers. In any case, it's not free, because one needs to open an account with them which typically has some cost associated with it."
Stock Market Data,2,Murat Akyildirim,Ken Popkin,I had no idea there was a free option.Â I did get burned(still burning)Â with a stock investment soÂ i have no intension to ever invest in stocks but thankÂ you for sharing.
EU GDP - Small to large.,1,Jack Russo,Jack Russo,"In April 2018 the EU General Data protection act went into force restricting what data could be shared inside and outside the EU. While this seemed to be common sense privacy protection It did restrict what information charatiesÂ could be shared about sucessfullÂ aproaches to their work.
Review the article here.
https://www.economist.com/business/2018/04/05/europes-tough-new-data-protection-law"
EU GDP - Small to large.,2,Jit Seneviratne,Jack Russo,"I made a post about the GDPR as well.Â I don't have access to The EconomistÂ unfortunately.Â Anyhow,Â after the Cambridge Analytica scandal,Â it seemed imperative that regulations were set in place. Clearly there would be drawbacks, but I believe it was a necessary step."
Trending Topics Drivers,1,Sheryl Piechocki,Sheryl Piechocki,"Understanding drivers for trending topics could help determine ways to deal with the spread of misinformation.Â Â The study referenced in the link below concerns COVID-19 and the trending topic that 5G is a cause.Â  The goal of the study was to look for the drivers of the 5G COVID-19 theory.
In this study, Twitter data in the U.K. with the #5GCoronavirus hashtagÂ from March 27, 2020 to April 4, 2020 was collected.Â  Influential users were determined using graph clusters and nodes were ranked by betweenness centrality score.Â  Results showed two large networks.Â  One was a group of isolates (users who tweet without any mentions) and the other was a broadcast group (users whose tweets led to retweets).Â  A detailed look at some sample tweets revealed that 65.2% were actually non-supporters of the theory.Â  So, even though it became a trending topic, the majorityÂ  did not believe the theory that 5G causes COVID-19.Â  In addition, a single Twitter account created only to spread the theory was discovered.Â  No corresponding account to counter the theory was found.Â  The authors believe that users tweeting about the topic jokingly were a major driver in spreading the theory.Â  They propose that an authority or public figure Twitter account actively combating the theory would reduce its spread.Â  They also feel that users should not re-tweet or tweet even in jest, but rather should report it in order to avoid it gaining trending status.Â  (They go on to say that Twitter could then shut down the spread.Â  The topic of whether Twitter and other social media sites should remove content isÂ  a whole other discussion.Â )Â Â 
Â Ahmed W, Vidal-Alaball J, Downing J, LÃ³pez SeguÃ­ FCOVID-19 and the 5G Conspiracy Theory: Social Network Analysis of Twitter DataJ Med Internet Res 2020;22(5):e19458URL: https://www.jmir.org/2020/5/e19458DOI: 10.2196/19458PMID: 32352383PMCID: 7205032
https://www.jmir.org/2020/5/e19458/"
Social Network and Text Analysis for Marketing Creative,1,Murat Akyildirim,Murat Akyildirim,"Combining network analysis and text processing to perform a market research on certain category of products (cell phone providers, cable companies, consumer health brands and etcâ€¦) in order to influence marketing creative for social media. Business goal is to improve consumer acquisition through social media by leading the creative with data insight. For example, if we perform text analysis and network analysis of Cable and Cell Phone Organizations such as Verizon, AT&T and T-Mobile, we can further see how they stimulate the conversation and how our company can benefit from it with their next social media marketing creative.
Possible available data: Twitter data (Verizon, AT&T, T-Mobile Tweets and responses)"
Resume Filtering,1,Jack Russo,Jack Russo,"Job postings these days can receiveÂ many more applications than can be realistically reviewed by humans. Text miningÂ resumes of quality applicants, businesses can build word frequency matrices to weighÂ the value of future candidatesÂ without having to review every resume."
Resume Filtering,2,Sheryl Piechocki,Jack Russo,"Jack,
I know my company has some sort of system that scans resumes for key words that are required based on the job posting.Â  If those key words are not found, the resume is automatically rejected.Â  I don't believe any network analysis is used here as it seems to be a straight search for certain words."
Resume Filtering,2,Mikhail Kollontai,Jack Russo,"While I agree that this would be an effective way to filter resumes,Â the thought makes my skin crawl. Getting interviews relying solely on your resume when you don't have any connections is hard enough. Although one could potentially do the inverse and write a program that would write a resume based on a similar analysis of job postings. Hmm...."
Resume Filtering,2,Mael Illien,Jack Russo,"Love the idea of reverse engineering resumes based on job posts. You also mention how important connections are to getting interviews which is certainly true. These days I see the word connection and immediately think graph. I'm curious now about the social network behind linkedin and whetherÂ influentialÂ individuals and boundary spanners could be identified (if I (genuinely) connect with this person, I can be exposed to his network via his recommendation)."
Movie Galaxies,1,Steven Ellingson,Steven Ellingson,"MovieGalaxies.com has been the source of a couple of assignents for me.Â  What they did was take movie scripts and build social networks for the movie universe out of them.Â  I have currently only used the processes network data, but I do think trying to re-create some of their work could be very interesting. I personally could see something like this being interesting for books, tv shows, etc. as well."
Movie Galaxies,2,Zachary Alexander,Steven Ellingson,"Hey Steven,Â very much appreciate your link to moviegalaxies.com -- I was wondering where you found all of that data for the projects you've been presenting. Very cool! I agree with you, it would be very fascinating to expand this out to different media including books and TV shows. I'm not sure if you've seen this website before (and whether or not you are an ""Office"" fan), but some of this reminded me of an analysis that pudding.cool did about the TV show. They utilized this website to analyze the transcripts and create some funny/interesting visuals. Anyways, definitely liked the resource you shared!"
News Articles,1,Mikhail Kollontai,Mikhail Kollontai,"In this day of sensationalized news it is often very interesting to trace the life of a story. For the more reputable sources it usually starts with a significant amount of leg work,Â primary research and in-depth interviews. Publications with integrity will wait until they have at least 3 independent sources corroborating a story before publishing.Â 
Newer media, however, does not hold to these lofty standards. A story you see on some news channels will at times be the result of a ""reporter"" seeing a tweet or a blogÂ post and running with the story. Little or no fact-checking is done since the point of the story is internetÂ traffic, not educating the consumer. With social media such stories can get caught up in a retweetÂ or repost craze that spreads the story far and wide with many of the readers not even questioning the validity of the information.Â 
I can envision a system that scrapes news articles for quotes, headlines, punchlines (basically key predictors) and developing networks of connected stories to identify trends in the way sources/information are reused. These networks could then be analyzed to identify echo chambersÂ  as well as islands of diversified information. The business goal of such an endeavor would be to provide an objective evaluation of the quality of sourcing used by a news organization. Each network would be scored based on the connections it maintains and the sources it uses."
News Articles,2,Jit Seneviratne,Mikhail Kollontai,Nice example. The connected stories can probably be constructed using topic modeling or keyword extraction.
Identifying Breast Cancer Trends,1,Amber Ferger,Amber Ferger,"I came across a really interesting article byÂ Jurca, Addam, Aksac, Gao, Ozyer, Demetrick, and Alhajj titled ""Integrating Text Mining, Data Mining, and Network Analysis for Identifying Genetic Breast Cancer Trends"" that is a great example of the convergence of text mining and social network analytics.
The Problem: Literature containing information aboutÂ biomarkers that are indicative of breast cancer is non-standardized and unstructured, making it difficult to process in large quantities.Â Although research papers contain a trove of information, the sheer volume of it makes sifting through relevant articles a very tedious task.Â 
The Goal: Utilize natural language processing and text mining techniques to extract relevant information from the research papers. Identify key relationships between entities and terms through the use of social network analytic techniques.Â 
The Added Bonus: By combining NLP and text mining techniques with social network analysis, the authors of the study were able to identify functional relationships (like those between different genes) and associative relationships (like those between authors in different geographic regions). The functional relationships are important for understanding the disease itself, which has obvious benefits. However, the identification of associative relationships provided a much different set of insights -- how the discoveries themselves varied by region and time.Â 
Sources of Data:Â The papers were sourced from PubMedÂ based on a keyword search. The authors then performed entity extraction using open-source dictionaries (ex: becas, uniprot, hcnc)Â to identify important terms in each text, such as those related to specific genes and proteins. Once complete, they were able to bucket similar papers based on terms and analyze the text and relationships accordingly. Geographic relationships were extracted based on the address of the authors in the paper.Â 
I think this is a really neat application of the merging of 2 different analytical techniques to derive insights into the disease itself and the discoveries around it!"
Identifying Breast Cancer Trends,2,Elina Azrilyan,Amber Ferger,This is fascinating -Â I think we can make a lot of medical advances with data science and this is a great example!
Identifying Breast Cancer Trends,2,Vijaya Cherukuri,Amber Ferger,Good example Amber.Â It will be really helpful in identifying the patterns and also how likely they might get few geneticalÂ disorders from ancestors.
Biomedical Literature for Understanding Disease Associations in Drug Discovery,1,Vijaya Cherukuri,Vijaya Cherukuri,"Biomedical Literature for Understanding Disease Associations in Drug Discovery :
We all might be aware of Covid-19. Finding the medicine for Covid-19 became a biggest challenge because of the change in classifications for the disease.
Generally for finding a drug for a diease involves lot of analysis, tests but most important is identifying the root cause and what the disease is impacting. In some cases what kind of drug will help cure/kill the diseases cells.
One example is using obesity and psoriasis as examples by analyzing the frequency of disease-related MeSH terms in PubMed abstracts over time.Network Analysis and Text mining is used to predict emerging trends at a relatively early stage and we analyze the literature-identified genes for genetic associations, druggability, and biological pathways to explore any potential biological connections between the two diseases that could be utilized for drug discovery.
Reference :Â  https://pubmed.ncbi.nlm.nih.gov/24788268/"
Twitter text data analysis,1,Priya Shaji,Priya Shaji,"As a fundamental component of the analysis, it is important to find ways of communicating the results, i.e.Â data visualization.Â 

In the following link, twitter text mining and analysis is broadly explored in R. It shows how we can cluster these words to get meaningful groups defining topics.

https://juanitorduz.github.io/text-mining-networks-and-visualization-plebiscito-tweets/

For example, we can analyze NYC 311 twitter data and create sentiment analysis from them and then create network analysis to see how communities are connected and also analyze complain types which can give us more insight about variousÂ solutions to service requests."
Twitter text data analysis,2,Vijaya Cherukuri,Priya Shaji,Good Example Priya. Twitter text data and networkÂ analysis can be helpful in identifying the tweets. We will really interested to see the recent tweets when a new movie is released.
Twitter text data analysis,2,Habib Khan,Priya Shaji,Nice work Priya. Even sentiment analysis can be used on tweets to see general audience' reaction on certain topics.
Twitter text data analysis,2,Abdellah Ait Elmouden,Priya Shaji,"Thank you Priya. This is a good example. The worldâ€™s most valuable resource is no longer oil, but data. last week I read an article about how they were able to use Twitter posts to reveal polarization in Congress on COVID-19.
Here is the article : https://news.osu.edu/twitter-posts-reveal-polarization-in-congress-on-covid-19/"
Text Processing (Google Searches) and Network Data Analysis,1,Zachary Alexander,Zachary Alexander,"The New York Times posted an OpEd article in early April titled, ""Google Searches Can Help Us Find Emerging COVID-19 Outbreaks"", that highlighted a data scientist's approach to mapping out the spread of COVID-19 throughout the world by mining Google's search data.Â Through keyword and text analysis for spikes in searches such as ""I can't smell"",Â or ""my eyes hurt"",Â or specific searches related to fevers, chills, etc. in multiple languages,Â the author was able to pinpoint emergingÂ hotspotsÂ around the same time the confirmed case counts rose in those areas. It's been mentioned before, but Google search term analysis has continued to intrigue data scientists for years, since Google is typically a private way for humans to search the web without having to consult with other people. In this context, it's providing insight into people's anxiety about the virus, and could even help predict where case counts will rise before they actually happen. On top of this, I think it would be interesting to incorporate networks into this type of analysis -- since searches can be subsetted by location and time, networks and graphs could be used to help map the ebbs and flows of those being exposed to the virus. Additionally, based on certain spikes in search terms, it would be interesting to attach edge weights or node attributes that help measure the severity of the hotspots and the trends in Google searches by people in those areas.
Business Goals -Â the obvious goals of this would be to provide analysis or a visualization tool that could be used to help map and predict where new hotspotsÂ are emerging before they actually happen. If there do appear to be trends in searches based on these factors, this could help government officials and local entities combat the virus before it reaches it's full potential in a given hotspot.Â Â 
Potential Sources of Data -Â Google Search Terms and any other Google-related keyword searching data. This could also be expanded out to different social networks, i.e. Facebook, Twitter, etc., but would possible fall a bit more outside of the scope of traditional text processing."
Text Processing (Google Searches) and Network Data Analysis,2,Subhalaxmi Rout,Zachary Alexander,"Interesting post Jach, based on symptoms of search words can find the potential place where the infection cases can arise. The line graph (in the above-mentioned article) shows an interesting trend, March 15th to March 20th there is a spike in the graph this means can expect more people may get infected. I do agree with you on the potential data sources, if this analysis would have involved other social media sites then result may more accurate."
Book recommendations,1,Elina Azrilyan,Elina Azrilyan,"I am thinking it would be beneficial to combine network data analysis with text processing to improve book recommendations. We can use text processing with Goodreads API to obtain some key â€œtagsâ€ from book reviews and see if there is a connection between people in the same social network and the books they read and enjoy. Maybe the nodes with high influence and high degree centrality recommend books they like to their peers and that can help with marketing strategy. New book releases can target those individuals for advertising and use the key words and genres that were shown to be significant for that particular network. Data sources would be Goodreads, Facebook, Twitter APIs and the business goals would be marketing and assistance with identifying popular publishing trends."
Legal Network,1,Mael Illien,Mael Illien,"There is already software out there that leverages text mining to comb through and classify legal documents. Iâ€™d be curious to see how this data could be combined with network analysis. Node types could include cases, particular laws being referenced, even law firms and judges. The case attributes could include how the case was ruled (maybe +1, -1 in order to add weights to the edges of the graph). One could map a graph of cases defended by particular law firms and their outcomes in order to identify which firms have been more succesful dealing with particular types of cases. This could be valuable information. I am guessing that case information is public and that the text mined using topic modeling and named-entity recognition techniques."
Use of NLP and network analysis techniques to describe the network of drug cartels in Mexico,1,Subhalaxmi Rout,Subhalaxmi Rout,"Focusing on Mexican cartels and affiliated drug trafficking organizations examines how self-proclaimed cartel members use social media to further the criminal activities of their organizations. Researchers collected data of alleged cartel members over a period of 4 months from social media platforms (Twitter, Facebook, Instagram, etc). After data collection ended, quantitative, qualitative, and social network analysis were performed to identify how subjects made use of Facebook to assert their cartel/ drug trafficking organization (DTO) affiliations, how they communicated with others, and how they were connected to one another. Results indicated that cartel members actively use Facebook to plan, organize, and communicate in real-time.
Business Goal: Identifying and observing online behavior of self-identified members of Mexican drug trafficking organizations. Additional research in this area is needed to further understand the behavior of cartel members on social media and to validate their use of these platforms to further their criminal activities.
Potential sources of data: The research methodology called for identifying potential drug trafficking organization (DTO) members on social media, systematically gathering information from their posts, and then analyzing the resulting data using descriptive, qualitative, and social network analytic techniques.
Reference:Â  https://digitalcommons.unomaha.edu/cgi/viewcontent.cgi?article=1057&context=criminaljusticefacpub"
Use of NLP and network analysis techniques to describe the network of drug cartels in Mexico,2,Mia Chen,Subhalaxmi Rout,Interesting topic as I've been watching the Breaking Bad lately.Â I can imagine how this combination of NLP and network analysis techniques could be implemented to track drug cartel activities.
Social media,1,Habib Khan,Habib Khan,"I think of social media such as facebook, twitter, instagram, etc where we can use network analysis to create clusters of group that link together and use text processing as well from their posts or tweets. I found this article quite useful for usage of network analysis and text processing in social media.
https://www.researchgate.net/publication/226416001_Text_Mining_in_Social_Networks"
Social media,2,Priya Shaji,Habib Khan,"Nice article Habib, seems likeÂ using a combination of linkage and content information for mining purposes would lead better results."
Characters in Shakespearean Plays,1,Jit Seneviratne,Jit Seneviratne,"Characters in ShakespeareanÂ playsÂ can be visualized via a social network. Their spoken wordsÂ can also be analyzedÂ for sentiment and topicality. When clusters appear in the network, sentiment and topic modeling can be used to determineÂ what type of cluster it is. For example, the principalÂ antagonist will have his scheming network, which will share the same sentimentÂ and possibly keywords from topic modeling. The NLP component can replace attributes of a given node in a social network here."
Week 4 Part 1,1,Vanita Thompson,Vanita Thompson,"Hello Class,
Here is the link to my discussion:Â  https://github.com/Vthomps000/DATA620/blob/master/Discussions/Week%204%20Part%201.ipynb 
Vanita"
Public Deliberation on Social Media,1,Mia Chen,Mia Chen,"Some advocacy organizations produce social media messages that inspire far-ranging conversation among social media users,Â while the vast majority of them receive little or no attention. To understand the reasons behind,Â a social scientist used natural language processing,Â network analysis, and a social media application to analyze how cultural bridges shaped public discourse about autism spectrum disorders on FacebookÂ over the course of 1.5 years, controlling for various characteristics of advocacy organizations, their social media audiences, and the broader social context in which they interact. The study shows that organizations that create substantial cultural bridges provoke 2.52 times more comments about their messages from new social media users than those that do not, controlling for these factors. It offers a theory of cultural messaging and public deliberation and computational techniques for text analysis and application-based survey research.
source:Â https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5081586/"
Combining SNA and Sentiment Analysis to explore potential for online radicalization,1,Jagdish Chhabria,Jagdish Chhabria,"I came across this very interesting research paper by a group of researchers from Ireland, that uses a combination of Social Network Analysis and Lexical and Sentiment Analysis on YoutubeÂ data to explore the potential for onlineÂ radicalization. By studying the lexicon and sentiment of posts by certain radical users (known previously) and the subsequent interaction with other users in their network with no known jihadistÂ tendencies, the researchers explore whether they can better identify when someone in a alter network is being influenced by the egos. The full paper is available here:
https://core.ac.uk/download/pdf/147597985.pdf"
Dialog Network,1,Simon Ustoyev,Simon Ustoyev,"I see a great value in developing an ability, given a body of text, to automatically detect spoken quotes, their source and target audience so that a [social] network of interactions can be created.Â  It may be very ambitious and a challenging undertaking but applications can be valuable in so many areas, such as fraud detection and crime investigation, literature, movie scripts and court case analysis and many more.Â  Detecting quotes and who is uttering them (the source) may not be as challenging as detecting a change in context, location and audience of a text narrative, as those things can be made evident in a subtle ways pre or post the quotes in the text.Â  Sometimes there is no audience as the quotes may represent characterâ€™s thoughts."
Topics and Authors for Book Publishers,1,Ken Popkin,Ken Popkin,"A friend of mine is an author and regularly connects with four other authors via social media and occasional lunches.Â  Last week she shared that two other members of the group were both contacted by a publisher and asked if they'd like to write a book for them.Â  I have no idea how the publisher goes about identifying topics, or authors they'd like to have write for them, but here's what it might look like if they chose to do so via network data analysis and text processing...Â  
   


Business Goal: Equip book publishers with a tool/model that enables them to identify topics of high interest to the American people and authors to reach out to write the books. 
   


Approach:


     1. Identify topics that are of... 
   


      highest interest (threshold to-be-determined) across America 
    

      identify if a lot or a little (threshold to-be determined) has been written already about the topic 
    



     2. Identify authors that... 
   


      have expertise (criteria to-be-determined) in the topics identified 
    



      have an expansive (threshold to-be-determined) social network 
    



     3. Marry steps 1 and 2 together to identify books to write and authors to write them 
   


Potential sources of data:


Topics:


     1. Social Media (Facebook, Twitter, Instagram, etc...) posts 
   

     2. Main-stream media headlines and articles 
   


Authors:


     3. New York Times and other best seller lists 
   

     4. Amazon ranks books online across categories, so successful authors could be identified 
   

     5. Facebook followers to assess social network"
Topics and Authors for Book Publishers,2,Amber Ferger,Ken Popkin,"This is a really interesting convergence of text and social network analytics - one that I would not have thought of! It would be interesting to see how the topics change over time and if there's a relationship between when an author publishes vs when the topic becameÂ ""relevant"". Social media platforms hold a wealth of information about topics of current interest, but they seem to change so often (things going viral), that I could see it being potentially misleading when determining what would be of the most interest to write about. Nice job!"
Topics and Authors for Book Publishers,2,Steven Ellingson,Ken Popkin,"I think this is a really cool idea Ken.Â Â Maybe we could go a step further and create an AI to write the books for us? :)

I think Amazon Sales could help for step 1 as well as 2.Â  The social media mining could give you an indication of the topic, but an uptick in sales could help to solidfy that a certain idea is ripe for sales in the future."
Search Engine Optimization and Text Mining,1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"Search engine optimization (SEO) is normally used to push content to the top of Google search results page. However, using the data available today as well as text analysis and visualization techniques, we can apply SEO approachfor something much more interesting: discovering the gaps in public discourse. Those gaps are discrepancies between what people are looking for and what they actually find. Once we identify these gaps, we can produce relevant content to fulfil the lack between the demand and supply, be it political discourse, a niche market, or scientific research.
InfraNodus is text processing and network analysis tool. data can be generated by using the Google search query option provided by the application.
Reference : InfraNodus"
Search Engine Optimization and Text Mining,2,Jack Russo,Abdellah Ait Elmouden,Would you happen to know what tools Google use'sÂ to bridge those gaps?
Search Engine Optimization and Text Mining,2,Abdellah Ait Elmouden,Jack Russo,"Hi Jack, No i don't know what tools is Google using. i am also interested to know."
Search Engine Optimization and Text Mining,2,Ken Popkin,Abdellah Ait Elmouden,"It seems so obvious now that you mention it, but prior to reading this it never occurred to me to use SEO in this manner.Â  My post for this discussion topic was somewhat similar -- how publishing houses could use text mining to identify topics (and potential authors) to write books on subjects that are of high interest, but not many books have been written yet."
Search Engine Optimization and Text Mining,2,Murat Akyildirim,Abdellah Ait Elmouden,"This is really interesting topic idea. Thanks for sharing this as wellÂ Â Â https://infranodus.com/docs/search-engine-optimization Â . The business goal of creating relevant content seems to align with my idea of analysis. If we can analyze the conversation between brands and their consumers in social media, we can serve them the content they want in our next social media marketing campaign."
Sentiment Analysis on Candidates,1,Ken Popkin,Ken Popkin,"Polls have lost a lot of credibility across our country over the past five years, so alternative measures of assessing a given candidates popularity and/or chances for re-election are of interest to me.Â  
To identify a good github/python notebook link for this discussion I tried a number of unsuccessful search strings -- the results either yielded good tutorials with insufficient examples, or good examples that were not robust in their application of text mining.Â  Finally, the search string, ""Github and Python and response to Trump tweets"", yielded the link below from Conor Dewey's github...
conordewey3/Trump-Sentiment-Tracker
What I like best about this notebook (and this entire project) is that...
1. Conor provides a clear, concise, ReadMe that any layperson could easily understand (this served as a gentle reminder for me to start doing the same on my projects). Â  Â 
2. His Python notebook is short and fairly easy to follow.
3. He also created an easily understood web app sentiment tracker that visually displays the sentiment results.
What might be added to this notebook 
1. is to expand it beyond only handling Trump's tweets.Â  I realize that data availability and performance would become factors in adding this feature, but I'd be willing to wait a few minutes (or even longer if necessary) to find out how my governor (Michigan - Gretchen Whitmer), Joe Biden, Mitch McConnell, and other politicians are faring from a sentiment analysis perspective.
2. he could have inserted comments throughout the notebook, but as I stated previously even without comments the code is fairly easy to follow."
Sentiment Analysis on Candidates,2,Murat Akyildirim,Ken Popkin,This is great.Â With my previous group from Data Acquisition and Management class we did analysis of Trump tweets and impact to the stock market (Â Â https://rpubs.com/anilak1978/tweetsÂ  )Â  You can see all of his tweets from here alsoÂ Â Â http://www.trumptwitterarchive.com/archiveÂ . I agree on possible expansion of the tweets from Trump.
Sentiment Analysis on Candidates,2,Amber Ferger,Ken Popkin,"What a great example! I had come across this somewhere a little while ago and completely forgot about it. I love thatÂ it's such a simple graphic, yet it reveals so much information.Â I agree that the code is pretty easy to follow, but I also wish there were a few more comments explaining the process.Â 
I, too, have to remember to keep my code clean and concise in my github repo. (And organize my repoÂ in a cleaner way in general)"
Twitter Text Analysis,1,Murat Akyildirim,Murat Akyildirim,"Reviewing text mining I wanted to find out how the process looks like in terms of steps from loading required packages, data, selecting creating objects and etcâ€¦ Initially I wanted to see basic examples to understand the possible steps.
Below articles helped:
https://towardsdatascience.com/text-mining-for-dummies-text-classification-with-python-98e47c3a9deb
https://medium.com/towards-artificial-intelligence/text-mining-in-python-steps-and-examples-78b3f8fd913b
https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk
I am interested in social media data, there are many different articles and tutorials out there.
https://www.toptal.com/python/twitter-data-mining-using-python
I like this article because it shows how to access the twitter data including tweets from a specific account. I am not sure about some of the code as grabbing the tweets with for loop and printing sounds costly to me. I like the fact that there is an example of NYT tweets but I donâ€™t like that there is no analysis of the text , it is simply mining the data.
https://towardsdatascience.com/creating-the-twitter-sentiment-analysis-program-in-python-with-naive-bayes-classification-672e5589a7ed
This article captures on access to twitter data along with creating the corpus file and tokenizing and analysis using nltk package. I also like the fact that the provided approach gives us a classification model using NaÃ¯ve Bayes."
Twitter Text Analysis,2,Vijaya Cherukuri,Murat Akyildirim,"Hi Murat,
Thanks for sharing the articles.Â It really helps us in understanding and learn basics on text mining.
Using text mining we can do twitter analysis that might help in identifying the movieÂ tweets and other tweets."
UCSF Covid-19,1,Jack Russo,Jack Russo,"These notebooksÂ use sentimentsÂ analysis toÂ evaluate COVID-19Â research.
https://github.com/geoffswc/GCP-AutoML-Workshop"
Text mining to decide which Ted Talk to watch,1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"The idea is to demonstrateÂ  how one can generate recommendations just using content. This becomes essentially important when you donâ€™t have any user-item interaction data, essentially when you are starting out new and still want to provide the consumers of your content relevant contextual recommendations.
The python code is her: Notebook 
Reference: Original article"
Text mining to decide which Ted Talk to watch,2,Mael Illien,Abdellah Ait Elmouden,I like how simple that is.Â  Recommendations byÂ TDIDF matrix and cosine similarity inÂ just a few lines of code.
Scraping Wiki,1,Mikhail Kollontai,Mikhail Kollontai,"I will shamelessly plug my own notebook here in the hope that I will get some advice on ways to clean it up and improve the approaches.Â Our group was struggling with identifying viable bipartite datasets for Project 2 so I decided to venture forth and create one of my own.Â SubhalaxmiÂ found this project from a previous student:Â  https://github.com/hvasquez81/Data620/tree/master/Project%202Â but I was unhappy with using data when I didn't have an original credible source. I decided to try and put something together on my own.Â 
I used the following article for pointers on how to get started:Â  https://medium.com/analytics-vidhya/web-scraping-wiki-tables-using-beautifulsoup-and-python-6b9ea26d8722
And started chugging away at scraping aÂ wikipedia table and cleaning it up until I could create a clean bipartite network. I won't lie - I'm still not there. I must, however, admit that the process of figuring out how to clean the data and how to massage it to turn it into a clean network has been very rewarding.Â 
https://github.com/mkollontai/DATA620/blob/master/Discussions/DATA620_Wiki_Lang_Scrape.ipynb
I appreciate any advice or pointers!"
Customer Service Analytics,1,Priya Shaji,Priya Shaji,"Customer service analytics is the process of collecting and analyzing customer feedback to discover valuable insights.

Most companies are already tracking quantitative operational metrics like first response time (FRT) andÂ  average time to resolution to measure the performance of their customer service teams. Also, many businesses are monitoring customer experience (CX) by quantifying scores of customer satisfaction and customer effort surveys.Â 

The following link explores data set on mall customers to try to see if there are any discernible segments and patterns which gives us a generalized idea about text mining techniques and uses: https://towardsdatascience.com/customer-segmentation-analysis-with-python-6afa16a38d9e

I liked how this notebook explains to segment ideal customers since customer segmentation is useful in understanding what demographic sub-populations there are within your customers in a business case.

Customer Service Analytics use cases, techniques and tools:

https://monkeylearn.com/blog/customer-service-analytics/"
Customer Service Analytics,2,Vijaya Cherukuri,Priya Shaji,"Good information Priya. Thanks for sharing the links.
In Customer Service Analytics, text mining really help inÂ tracking quantitative operational metrics like first response time (FRT) andÂ  average time to resolution and for many other use cases."
Customer Service Analytics,2,Jit Seneviratne,Priya Shaji,Thanks for sharing.Â This might be a case for controlling for confoundersÂ (such as age and income) and running a pairedÂ t-test on the difference in spending of each closely matched pair of man and woman. That's one way to truly know if one sex is more prone to spending than the other.
Customer Service Analytics,2,Jit Seneviratne,Priya Shaji,*Â knowing
Text Processing - Customer Reviews of Hotels,1,Zachary Alexander,Zachary Alexander,"I thought that this IPythonÂ Notebook:Â  https://github.com/jonathanoheix/Sentiment-analysis-with-hotel-reviews/blob/master/Sentiment%20analysis%20with%20hotel%20reviews.ipynb , with the accompanying Medium Post:Â  https://towardsdatascience.com/detecting-bad-customer-reviews-with-nlp-d8b36134dc7eÂ were quite fascinating. Sentiment analysis has very often been used to analyze social media posts and data, however this author decided to expand the analysis to hotel customer reviews. He matched up the customer ratings with their corresponding textual reviews, and used both components to build predictive models to help predict future ratings based solely on customer reviews.Â 
It was very useful to read about the Python libraries he used to conduct this analysis (vader, sklearn, etc.), and the measures he used to evaluate his machine learning models - I think these components were what I liked best. I think it would be interesting to expand this idea to other industries such as restaurants, Amazon reviews, etc. Also, he did go into a bit of detail about the limitations of working with some of the sentiment analysis libraries. Given that this article was posted in 2018, I'd be curious to expand this a bit using new libraries that have emerged since the time this was published.
I'm an avid reader of Medium, specifically ""Towards Data Science"". I find many of the articles helpful, and it keeps me informed on what others are doing in the Data Science field. I was able to track down this post by reading a few others first that were related to text mining, and found this one to be very intriguing."
Text Processing - Customer Reviews of Hotels,2,Subhalaxmi Rout,Zachary Alexander,"Thank you Zach for posting ipython notebook. Well,Â explained the prediction of positive and negative reviews based on customer reviews."
Game of Thrones Gender Imbalance,1,Sheryl Piechocki,Sheryl Piechocki,"Here is a link to a github repo that contains a few notebooks regarding gender imbalance in Game of Thrones.Â  This analysis uses the scripts fromÂ episodes of the Game of Thrones TVÂ show.Â  I like this analysis because I often heard of Game of Thrones being characterized as sexist and negative towards women, but having watched the show did not necessarily agree with those assertions.Â  As the seasons progress, more and more women are seen in powerful roles.Â  They exude confidence and strength.
This analysis does show that men talk more than women overall and it does show that there is an increase for females in their share of the talking as seasons progress.Â  It does not necessarily address the quality of the spoken words.Â  As in many things, quality can be more important than quantity.Â  It does look at the most frequent words and some sentiment analysis by gender, but I think a deeper analysis of the quality of the words would be beneficial.Â Â 
https://github.com/anahitabahri/NLP-Final-Project
Â I found this notebook using Google search terms of ""github"", ""Game of Thrones"", ""nlp"""
Game of Thrones Gender Imbalance,2,Elina Azrilyan,Sheryl Piechocki,Thank you for sharing that - it is an interesting topic since this show was very popular and it is interesting to see what sort of subliminal messages in sent to its giant audience. I am glad that they seemed to have improved on the gender equality as the seasons progressed.
Game of Thrones Gender Imbalance,2,Habib Khan,Sheryl Piechocki,Thanks for sharing Sheryl. I think it would be quite interesting to work on Game of Thrones for final project and work on different aspects to see more in-depth analysis.
Text mining in Uncarnate Lyrics,1,Vijaya Cherukuri,Vijaya Cherukuri,"There are some great tutorials to learn text mining. I found these 2 resources to be helpful in understanding the text mining and learn text mining easily.
https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908
https://medium.com/towards-artificial-intelligence/text-mining-in-python-steps-and-examples-78b3f8fd913b
I like this Uncarnate_lyrics workbook, it gives a detailed explanation how to do text mining, do some exploratory analysis using good visualizations and finally the word count to determine which words are mostly used.
Here is the workbook : https://github.com/adam-ra/text-mining-exercises/blob/master/Uncarnate_lyrics_analysis.ipynb
In this workbook if they provide more details by providing some bar graphs to identify the top 10 words used in the lyrics."
Text mining in Uncarnate Lyrics,2,Priya Shaji,Vijaya Cherukuri,"That's an informative notebook,Â I like the use of Â log-likelihood ratio which allows to answer the question ofÂ how significant is the difference between frequency of a word W in corpora A and B.Â Seems like interesting metricÂ in text mining."
Gensim,1,Jit Seneviratne,Jit Seneviratne,"This is the link the parent page of numerous tutorial notebooks on GensimÂ (https://radimrehurek.com/gensim/auto_examples/index.html). It's very easy to follow and links to articles underlying core concepts of SkipgramÂ models CBOW models, etc. I can't really find fault with anything here. Personally, I have been drawn to Scikit-Learn'sÂ implementations, but this library is very easy to use."
Gensim,2,Jeremy O'Brien,Jit Seneviratne,"This is a great overview of Gensim - wish the tutorials for NLTK were as intuitive and clear as this!
   
Dig into Gensim a bit more after reviewing the tutorial. Per this article (https://medium.com/activewizards-machine-learning-company/comparison-of-top-6-python-nlp-libraries-c4ce160237eb), Gensim is used for topic modeling, vector space modeling, and document similarity; doesnâ€™t support supervised learning; and needs to be used in conjunction with NLTK or Spacy as it lacks a full NLP pipeline. Attached is a handy chart comparing Gensim with other Python NLP libraries which I found a handy reference."
Gensim,2,Jit Seneviratne,Jeremy O'Brien,Interesting comparison! I'd love to see actual runtime comparisons.Â I've used SpaCyÂ before but never thought if it as advantageousÂ in terms of runtime.
Text Mining EDA  & Reddit,1,Mael Illien,Mael Illien,"The notebook provided below along with the associated article give a very nice overview of text mining EDA and reveal some of the most talked about topic in subreddits. The notebook is clearly laid out and the plots give meaningful information. I also like the authorâ€™s use of method chaining to transform the data.
I thought it would be easier to find a notebook through a series of articles which is good because the article gives the narrative that the notebook would otherwise be missing.

https://github.com/datanizing/reddit-selfposts-blog/blob/master/02-data_exploration.ipynb 
https://medium.com/@datanizing/modern-text-mining-with-python-part-2-of-5-data-exploration-with-pandas-ee3456cf6a4"
Text Mining EDA  & Reddit,2,Mia Chen,Mael Illien,Thanks for sharing this notebook!Â It has plenty of nice visualizationsÂ and it's easy-to-follow.
Text mining - Clinton and Trump election Tweets,1,Subhalaxmi Rout,Subhalaxmi Rout,"About Notebook: One of the major battlegrounds of the 2016 presidential election was Twitter. It was one of the most publicized US Presidential elections in history and Twitter had played an increasingly prominent role in it.
Why this notebook?
This notebook describes sentiment data from Twitter about 2 presidential candidates Donald Trump, and Hillary Clinton neat and interesting way. I like the tweet word cloud of Trump and Clinton and the network analysis on hashtags.Â 
What do you like best?Â Â 
Sentiment analysis I like the most. Using â€˜TextBolbâ€™ package, calculated polarity score of tweets and based on scoreÂ  tweets divided into 3 categories i.e positive (score > 0), negative (score < 0), and neutral (score = 0).
Useful/interesting addition:Â Â Twitter sentiment analysis described precisely however the other lexicon such as Bing, AFFIN, and NRC could display sentiment analysis more coherently.Â Â Â 
Github link: https://github.com/chouhbik/Sentiment-Analysis-of-Tweets/blob/master/Tweets%20Analysis%20HillaryvsTrump.ipynb
Kaggle Link: https://medium.com/analytics-vidhya/twitter-deep-dive-analysis-us-presidential-election-d6b32acc449b"
Text mining - Clinton and Trump election Tweets,2,Sheryl Piechocki,Subhalaxmi Rout,This is a very interesting notebook.Â Â It is a very thorough analysis.Â Â I like the word clouds and the end with the generated sentences.Â Â The overwhelming sentiment of positive is surprising.Â Â Perhaps it is the media that puts a negative spin on things and we end up attributing it to the candidates.
Text processing on twitter,1,Habib Khan,Habib Khan,"I found this python notebook very interesting as it the author used sentiment analysis on the tweets. Although the specific topic may vary but I liked the concept of extracting data from twitter that are trending and use different NLP techniques and text processing to see the insights. I used ""github, text processing project"" as keywords to find out the project. The project is not very descriptive and I think it should be more explored and described to make the analysis useful.
https://github.com/sharmaroshan/Twitter-Sentiment-Analysis/blob/master/Twitter_Sentiment.ipynb"
Text processing on twitter,2,Abdellah Ait Elmouden,Habib Khan,"Thanks for sharing Habib. I learned how to do text sentiment using R, but this is a good reference to do an analysis using python."
Text processing on twitter,2,Subhalaxmi Rout,Habib Khan,"Thank you for sharing Habib! Interesting ipythone notebook on twitter data analysis. The analysis could be more interesting if plot the comparison graphs on sentiments of tweets (e.g. positive, negative, neutral)."
Books,1,Elina Azrilyan,Elina Azrilyan,"The following Notebook is exploring a Goodreads Dataset and the author looks at the data from various angles. I like how much we learn from just a few simple queries such as the most prolific authors (Agatha Christie and Stephen King), best rated authors (Rumiko Takahashi and P.G. Wodehouse), and identify other interesting patterns in the data. I think I would have tried to extract some more data from book titles to see if there is some king of pattern that we can observe for frequently used words in highly rated book titles. I selected this notebook by searching for a goodreads mining notebook through google since I am interested in the topic and wanted to see what sort of work has been done on the subject. https://github.com/kart-projects/Goodreads-books/blob/master/Queries.ipynb."
Amazon Food Reviews,1,Vanita Thompson,Vanita Thompson,"Hello Class,
Here is the link to my discussion:Â  https://github.com/Vthomps000/DATA620/blob/master/Discussions/Week%204%20Part%202.ipynb 
Vanita"
Amazon Food Reviews,2,Murat Akyildirim,Vanita Thompson,Thank you for sharing. I think analyzing Amazon or any Reviews are norm for a lot of marketing companies but at the same time becoming unreliable due to user generated content(reviews). There are 3rd party vendors which provide curation of these reviews in order to help the brands.
NLP with Disaster Tweets,1,Mia Chen,Mia Chen,"This IPython notebook (https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert) fromÂ Kaggle.com provides step-by-step demonstration on how to tell whether or not a disaster tweet is real. I like the writing style of the code and markdown - it's very neat. It also gives clear explanations for what each step is doing. A possible improvement for this code is to use libraries and functions instead of going case by case for replacement and expansions. I know Kaggle.com has lots of great IPython notebooks and tutorials, so I Google searchedÂ ""kaggleÂ text mining"" keywords to find this dataset and then selected the most up-voted notebook from the kernels."
LDA on the Texts of Harry Potter,1,Simon Ustoyev,Simon Ustoyev,"I found a good introduction on LDA Topic Modeling in this article (https://towardsdatascience.com/basic-nlp-on-the-texts-of-harry-potter-topic-modeling-with-latent-dirichlet-allocation-f3c00f77b0f5), where the text consists of all 7 books (192 chapters) of Harry Potter series.Â  The article refers to a Python file on Github, which I think can easily be done on IPython Notebook.Â  I like how the author intuitively explained the topic and presented nice graphs and how to choose an optimal number of topics.Â  It wouldâ€™ve been nice if the author expanded more on how to make use of this analysis to help him understand the books better, since he didnâ€™t read or watch any Harry Potter movies before that.Â  This article came up under the list of NLP topics in https://towardsdatascience.com/ website (https://towardsdatascience.com/tagged/nlp)."
NLP on financial statements,1,Jagdish Chhabria,Jagdish Chhabria,"As investors look for alternative data sources to provide them with the ""edge"", one area that is receiving a lot of attention is using NLP to perform sentiment analysis of financial report filings by publicly traded companies with the SEC.
I found this notebook by Roshan AdusumilliÂ (GithubÂ link here:Â  https://github.com/roshan-adusumilli/nlp_10-ks/blob/master/NLP_on_Financial_Statements.ipynb) quite interesting because of a few different reasons:
1) He is a 16 year old.
2) He explains the different steps in NLP quite well.
3) His notebookÂ also shows how to download 10-K filings from the SEC website, so it's not just about NLP.
The corresponding article that walks through his process is here (https://towardsdatascience.com/nlp-in-the-stock-market-8760d062eb92).
In terms of improvements, I cannot think of anything significant. Perhaps he could have analyzed more thoroughly, whether the sentiment analysis could be used to predict the sock price return on the date of filing."
Predicting Hospital Readmission with Discharge Summaries,1,Amber Ferger,Amber Ferger,"GithubÂ Link:Â  https://github.com/andrewwlong/mimic_bow/blob/master/mimic_bow_full.ipynb
Towards Data Science Article:Â Â Introduction to Clinical Natural Language Processing: Predicting Hospital Readmission with Discharge SummariesÂ 
Why this notebook?Â I attended Open Data Science Conference East last year and had the opportunity to listen to a talk by the author of the above article, Andrew Long. As an individual working in healthcare, I was intrigued by the topic because I deal with quite a bit of of unstructured and unstandardized medical text. When I saw this discussion post, I immediately thought of this talk because I think it is one of the best articles I've read about NLP that is specifically geared towards beginners.Â 
Background: When an individual is seen by a doctor, notes are recorded in an Electronic Medical Record. These notes are free-form -- although doctors tend to ask similar questions to their patients, the information that is recorded varies drastically from provider to provider, both in terms of semantics and format. The unstructured nature of the note makes it difficult to perform rules-based entity extraction, but makes it an ideal candidate for NLP modeling.Â 
The Purpose: Long takes the reader through a step-by-step guide for developing a model to predict the patients that are most at risk of being readmitted to a hospital. He develops features for the model using term frequencies that are extracted from the text.Â 
The Pros: I like this article for 2 main reasons. First, Long assumes no background knowledge of the material and instead takes the user step-by-step through the entire process of creating a model from start to finish. He explains his reasoning for doing each step and provides sufficient background material so that even someone that has never been exposed to NLP techniques can follow along. Second, he spends a fair bit of time cleaning up the data and analyzing it before using it. I feel like a lot of tutorials start off the bat with unrealistic, tidy data, so it's nice to see someone walk through the pre-processing steps before jumping right in.Â 
Useful Additions: I can't think of much that I don't like about the notebook, but one thing I can think of that might make this notebook even better is to incorporate additional sources of data. Although discharge summaries themselves provide a lot of great information about the patient, adding in information about condition-specific features (ex: temperature, side effects, specific meds, etc) might make the model even more accurate."
Predicting Hospital Readmission with Discharge Summaries,2,Jack Russo,Amber Ferger,This is brilliant!Â Though I'm wondering what the actual consequencesÂ are off this practice. What should a hospital do if the text analysis predictsÂ  re-admittance?
Predicting Hospital Readmission with Discharge Summaries,2,Amber Ferger,Jack Russo,"Hey Jack!Â A lot of the time these are patients that are enrolled in risk management programs so that they are assigned a care manager to check up. It doesn't seem like much, but even just a phone call a day can ensure that the patient is educated and often prevents the readmittance!"
"Using sentiment analysis to predict employee satisfaction based on Glassdoor data
COLLAPSE",1,Jagdish Chhabria,Jagdish Chhabria,"I came across an interesting study carried out by some researchers at Stanford University. In this study, they conducted sentiment analysis on employee reviews on www.glassdoor.com. This website is a very popular website used by job seekers to learn more about their target employers. It allows employees to anonymously post their opinions about working at different companies. The Stanford researchers ' objective was to use sentiment analysis to predict the ""number of stars"" rating that is sometimes provided by the employee reviewers - the underlying idea being that an employee review that is deemed to be very positive from a sentiment perspective would be associated with a 5-star rating and so on. Companies can adopt a similar approach to analyze what their employees are feeling (employee satisfaction and perception) about different policies based on internal data (surveys) and external data (websites such as Glassdoor) and use that to modify or re-affirm their messaging as well as their policies. The full study can be found here:

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/reports/6880837.pdf"
Monitor Marketing Efforts,1,Mia Chen,Mia Chen,"Real time sentiment analysis can track campaigns at specific point in time, such as when new ad launches. Take Dove for example, the company posed an ad on Facebook showing a woman transforming into an entirely different race after using their product. They received a huge backlash from women saying that the ad made them angry and uncomfortable. Dove picked up on these negative sentiments right away, removed the ad from Facebook, and released an apology. Quick actions like this are essential to limit damage to the brand's reputation and retain clients, and can quickly tell you if a campaign or ad is successful or not. 

source: https://monkeylearn.com/blog/brand-sentiment/"
Week5 Discussion,1,Vanita Thompson,Vanita Thompson,"Discussion Prompt
This recent article describes how organizations are using sentiment-analysis software to better understand how employees are feeling, since the ability to attract and retain key employees is increasingly necessary for an organization to succeed:

Rachael King (2015): Companies Want to Know: How do Workers Feel?

Describe an interesting use case that describes how an organization uses (or could use) sentiment analysis to gain insights about employees, customers, products, or...? Include the business goals, and the available or potential sources of data.

Discussion
Companys may use sentiment analysis to assist with recruiting new hires. Similar to sites like LinkedIn and Indeed, companies use sentiment analysis software to extract data from job applications. Recruiters can filter applications and connect eligible applicants to companies based on certain criteria. This can be a useful tool, as it minimizes the work required from recruiters. Previously, recruiters spent hours going through resumes. These advancements have made the hiring process more efficient."
ASAPP,1,Jeremy O'Brien,Jeremy O'Brien,"ASAPP is a company I came across late last year.  They create software to support customer service teams using real-time speech transcription, sentiment analysis, next step prediction, knowledge based information retrieval, and content summarization.   They claim that customer service agents still interact with customers by phone 90% of the time, but also mine chat and text to get as well-rounded a view of individual customers as possible.

ASAPP focuses on a few use cases for customer like jetBlue, dish, and Sprint.  The first two - customer care and sales - leverage learning what the best customer service personnel do well (identified based on desired outcomes) in order to guide others in either efficiently resolving customer needs on first contact or garnering higher close rates / conversions / yields for sales calls.  Additionally, ASAPP provide cross-channel customer analytics that provide real-time insights and don't require costly, laggy surveying.

For anyone who's interested, their R&D team publishes a good deal and writes a lot of art (i.e. patents)."
Performance Reviews,1,Jit Seneviratne,Jit Seneviratne,"I'm unable to access the WSJ article and the link to the PDF does not exist.

In any case, here are my. thoughts on using sentiment analysis on performance reviews. Employees are often asked to rate their managers as well as the company on certain metrics. these rating s are usually on a 3 - 10 point scale. They are also given the opportunity to comment via text boxes. While many employees will be reluctant to given low ratings or be explicit in their criticisms, many implicit sentiments can be gained from NLP. Even if an employee does not use terms such as 'bad', 'terrible', 'ineffective' or 'poor' a neutral review can speak volumes, especially against a pre-defined benchmark. 

Companies can use sentiment analysis to gauge if the general morale of staff is falling, or if a particular manager seems to be getting more 'neutral'  text reviews than others, even if his/her point scale ratings are high.

It's about reading between the lines!"
Performance Reviews,2,Vanita Thompson,Jit Seneviratne,Nice use case scenario. It seems efficient and straight forward.
Stanford Talks on Sentiment Analysis,1,Simon Ustoyev,Simon Ustoyev,"There is a series of YouTube videos on Sentiment Analysis by Dan Jurafsky from Stanford University.  In his introductory video, https://www.youtube.com/watch?v=S4z0UG07-b0, he mentions several good use cases for sentiment analysis.  For example, I liked the one where SA can be applied to products, like printers, where customer reviews are analyzed not just for the overall rating of the product but also on sentiment about key aspects of the product as well, such as ease of use, value, setup, print speed, customer service and etc."
Stanford Talks on Sentiment Analysis,2,Subhalaxmi Rout,Simon Ustoyev,"Thank you, Simon, for sharing the video link for sentiment analysis (SA). I got to know the interesting tasks of SA from this video such as simple tasks, more complex tasks, and advanced tasks.

Simple task: need to find, text/document is positive or negative?

Complex task: Rank or rating of the text 1 to 5.

Advanced task: detect the source (who write the text), target (text about what topic), and complex attitude (like, love, hate, value, desire, etc.)"
Sentiment Analysis for Customer Interactions,1,Elina Azrilyan,Elina Azrilyan,"Sentiment analysis can be used to prioritize customer support tickets and improve satisfaction. If an issue the customer is experiencing with the product is the kind that requires immediate attention and causes major grief - those tickets would be handled as a priority. Especially when resources are limited - this could be an efficient way of interacting with customers and resolve problems in a way that will minimize the damage to your company’s reputation. In our highly digital day and age - it is very easy for a customer to spread the negative news about their experience with a company and influence the opinions of their network about the quality of customer service and products. Sentiment analysis can also be used to quickly measure that aspect of things as well - so that the company can see if the customer service strategy they use is paying off and what issues are at the top of customers’ mind so that those can be resolved pro-actively. For instance, if customers are unhappy with the ease of contacting customers service - they might give up on that effort all together and the company will never become aware of the issues and lose customers even before it has a chance to improve anything.  "
Sentiment Analysis for Customer Interactions,2,Simon Ustoyev,Elina Azrilyan,"Good ideas, Elina, about improving the customer service process.

I would also suggest that if the backlog of less critical issues builds up, that someone in the organization should pay attention to it as well, because these cannot be ignored and are likely to be more in numbers than any major complaints unless the product or service has serious flaws.  My guess is that most of these issues can be a matter of improving knowledge base about the product and perhaps require pushing the information closer to customers (distributed literature or phone app.) or building these minor knowledge or issue resolutions in to an automated chatbot.  These measures will take away the load from customer representatives and allow them to pay more attention to unique and more complicated cases, thus improving the overall customer experience."
Sentiment Analysis for Customer Interactions,2,Mia Chen,Elina Azrilyan,"I agree with Simon that most of the common Q&A type of supports can be effortlessly provided by an automated chatbot  and thus allow customer representatives to spend more time on critical or unique issues that still persist. In this case, sentiment analysis will be very useful to determine what should be included and added to the Q&A support inventory."
Sentiment Analysis for Customer Interactions,2,Murat Akyildirim,Elina Azrilyan,Thanks for Sharing Elina. Something similar is being done where i work. It all depends on what question the business wants to get answered. I think coming up with the right problem statement is really important when it comes to analyzing customer service support text.
Teams Chat Messages,1,Sheryl Piechocki,Sheryl Piechocki,"Many companies have some sort of instant messaging app for employees to communicate.  My own company recently switched from Skype to Teams Chat.  With about 95% of my company of over  50,000 employees working at home now, we have been using Teams Chat extensively to communicate with each other.  We use if for work-related chat and also for personal chat.  A company could analyze all of this message data to gain insight into how the employees feel about a wide-range of topics, including the leadership team, the company goals, employee morale, etc.  It would definitely be a better barometer of employees' feelings than the many surveys we are bombarded with that only ask for ratings of 1 to 5 on some preselected questions."
Teams Chat Messages,2,Elina Azrilyan,Sheryl Piechocki,"Sheryl, you make a very good point - since the data is out there it would be a good way for a company to measure employee satisfaction and improve employee engagement without resorting to surveys which I believe can introduce bias. Looking at the data in bulk - would remove the dangers of singling out a particular employee or group and risk punishment or consequences for an unpopular opinion. "
Advertising Billboards,1,Mikhail Kollontai,Mikhail Kollontai,"More and more billboards these days are electronic AKA capable of changing their image. I can envision a system where social media posts from the immediate vicinity were scraped and analyzed in order to evaluate the response. Not only would mentions be counted, but the sentiment associated with each post - providing a rough idea of not only the degree to which the advertisement caught the public eye, but also the type of feeling the content of the advertisement garnered. This information could be used to pull advertisements resulting in overwhelmingly negative responses earlier than planned and potentially leave the more effective ones up (charging the company more to leave them up having shown the impact data). "
Sentiment Analysis for Improving customer support in new products,1,Vijaya Cherukuri,Vijaya Cherukuri,"Improving customer support for new products:  Research has shown that more than 25 percent of customers stop using a product after a single bad customer service experience. However, with sentiment analysis organizations can track sentiment across various social media platforms, blogs and forums which give the customer service team key areas to improve on. They can also use the opinion generated to put together an emergency plan on how to get over such situations. 

An example interface used by Google Shopping to show sentiment of aspects in customer reviews."
Sentiment Analysis for Improving customer support in new products,2,Priya Shaji,Vijaya Cherukuri,"Good point Vijaya, Giving an overview of sentiment analysis to an organization would help them to improve in many ways. I think sentiment analysis combined with analysis of how variable(sentiment analysis variables) are correlated to each other would provide an in-depth view of the scenario."
Sentiment Analysis of Online Employee Review Data,1,Priya Shaji,Priya Shaji,"The power of online employee reviews extends far beyond the scope of finding employment. John Phillips built `InvestInMe`, a product that facilitates socially responsible investing. He built his product to serve the needs of individual investors who have limited access to the information required to make investment decisions in the rapidly growing environmental, social and governance(ESG) space.


By entering the name of a publicly-traded company in this web app, investors get a dashboard view of the overall sentiment of employees of that company, as well as a breakdown of employee reviews by topic area (Enjoyment, Flexibility, Work/Life Balance, Pay, and Growth Opportunity). The dashboard also displays how employee sentiment has evolved over time, and uses this information to predict future changes in sentiment. Because different investors will have different personal guidelines that shape their ESG strategies, John worked to make the dashboard view as information-rich as possible to maximize the value of his tool to a wide range of investors.

InvestInMe stands as an innovative use of Glassdoor reviews to inform decisions in an unrelated domain. Reviews often contain “insider information” regarding how a company treats its workers, and can provide insights into a company’s philosophy around sustainability. By distilling employee sentiment data, John ensured that individual investors can be confident they have the information they need to invest in line with their own ethics.

The following article describes various use cases which used employee sentiment analysis: 

https://blog.insightdatascience.com/using-nlp-to-gain-insights-from-employee-review-data-da15687f311a

The power of online employee reviews extends far beyond the scope of finding employment. John Phillips built `InvestInMe`, a product that facilitates socially responsible investing. He built his product to serve the needs of individual investors who have limited access to the information required to make investment decisions in the rapidly growing environmental, social and governance(ESG) space.


By entering the name of a publicly-traded company in this web app, investors get a dashboard view of the overall sentiment of employees of that company, as well as a breakdown of employee reviews by topic area (Enjoyment, Flexibility, Work/Life Balance, Pay, and Growth Opportunity). The dashboard also displays how employee sentiment has evolved over time, and uses this information to predict future changes in sentiment. Because different investors will have different personal guidelines that shape their ESG strategies, John worked to make the dashboard view as information-rich as possible to maximize the value of his tool to a wide range of investors.

InvestInMe stands as an innovative use of Glassdoor reviews to inform decisions in an unrelated domain. Reviews often contain “insider information” regarding how a company treats its workers, and can provide insights into a company’s philosophy around sustainability. By distilling employee sentiment data, John ensured that individual investors can be confident they have the information they need to invest in line with their own ethics.

The following article describes various use cases which used employee sentiment analysis: 

https://blog.insightdatascience.com/using-nlp-to-gain-insights-from-employee-review-data-da15687f311a

"
Sentiment Analysis of Online Employee Review Data,2,Vijaya Cherukuri,Priya Shaji,"Good example Priya. Glassdoor is one of the good example where Sentiment Analysis is used in analyzing the reviews.

In some cases sentiment scores are used to determine how similar companies were to one another."
Sentiment Analysis of Online Employee Review Data,2,Jit Seneviratne,Priya Shaji,"This is a good use case for NLP. We all search Glassdoor reviews before applying to a company, and this type of app could be used to help potential employees judge companies against an industry standard for sentiment before applying."
Sentiment Analysis to Measure Competitors,1,Zachary Alexander,Zachary Alexander,"I came across a particular resource that I thought was interesting related to utilizing sentiment analysis to measure internal business services and branding against competitors. In this article titled, ""A novel social media competitive analytics framework with sentiment benchmarks"", the authors discussed pooling together text data and feedback across various social media platforms (Facebook, Twitter, YouTube, blogs, forums, etc.) for a company's competitors, and finding ways to use sentiment analysis to measure concrete components of their shared market. In the article, they used retail and product stores such as Costco, Home Depot, Walmart, KMart, and Kohls to compare textual data related to product and customer service groupings. In the end, they used this idea to develop a dashboard that visualized comparisons across the different companies. This could be a huge asset to any business, to be able to pool data across social media platforms to build measurements about where each competitor seems to be doing well, and where they may have a competitive advantage. It also helps a company focus in on places where they could outcompete their competitors, and find ways to reinnovate their business model.


Many companies have been founded to provide tools and products related to this idea. A few that I found include:"
Sentiment Analysis to Measure Competitors,2,Vijaya Cherukuri,Zachary Alexander,"Good example Zachary, we can use sentiment score with various parameters to determine how similar companies and competitors were to one another."
Sentiment Analysis to Measure Competitors,2,Abdellah Ait Elmouden,Zachary Alexander,Good example. Sentiment analysis should most definitely be part of businesses social listening strategy to ensure that they capitalize on positive mentions and address negative ones.
Sentiment Analysis to Measure Competitors,2,Amber Ferger,Zachary Alexander,"This is really interesting and I can most certainly see the value in this! Identifying the strengths of competitors across a range of topics (products, service, support, etc) can hone in on what works for other companies. Conversely, if a competitor releases a new product or changes something about its business, one can use this as a gauge to see how it performs in the market before releasing a similar sort of thing. It's kind of like letting the competitor be the guinea pig before jumping in oneself!"
Employee Sentiment Analysis,1,Murat Akyildirim,Murat Akyildirim,"Sentiment Analysis can give managers the understanding of the workplace environment and improve accordingly where employees like their jobs. They can use sentiment analysis software or platforms to enhance employee engagement, improve the certain process based on the insights they gather such as onboarding, office structure, collaboration, training and communication.

 

For example, in certain organizations employees might be dissatisfied and do not engage with the company culture. Instead of creating employees surveys, gathering feedback from managers quarterly or annually (which takes a long time) , organization can utilize sentiment analysis solution by analyzing vast among of employee data and records. The organization can analyze the email communications, employee tone via different channels and can gather insights if the employee is dissatisfied with the existing processes. Email analysis can include can also help figure out not only employee engagement but also department engagement within the overall organization.

 

As an example sentiment analysis tool, Jive Software Solutions, tackled a business goal to unite employees in a single community. In order to do that, they created an intranet webapp called the Planet where employees interact with each other, share ideas and engage within the organization. These ideas and engagement combined with email and other communication channels further goes through sentiment analysis to improve employee engagement and satisfaction."
Employee Sentiment Analysis,2,Murat Akyildirim,Mael Illien,"Hi Murat. I also came across the same articles. I'm a bit skeptical of email analysis though, especially for intra company data. Personally, I wouldn't write down my discontent with a company to a colleague for my employer to find.  "
Sentiment Analysis Uses in Business,1,Subhalaxmi Rout,Subhalaxmi Rout,"Sentiment analysis uses machine learning to evaluate text (online conversations, emails, surveys, news articles, etc.) to determine if the sentiment expressed is positive, negative, or neutral. It’s used to automatically pull opinions about companies and products, and analyze them as a whole, without the need for human assistance. 

Improve customer experience company analyze customer support and customer feedback.

Customer Support: Sentiment analysis with natural language understanding (NLU) reads regular human language for meaning, emotion, tone, and more, to understand customer requests, just as a person would. The company can automatically process customer support tickets, online chats, phone calls, and emails by sentiment, which might also indicate urgency and route to the appropriate team.

Customer Feedback: Gain insights from the troves of customer feedback available (online reviews, social media, surveys) by using sentiment analysis, and save hundreds of employee hours. Sentiment analysis can read beyond simple definition to detect sarcasm, read common chat acronyms (lol, rofl, etc.), and correct for common mistakes like misused and misspelled words.

Improve employee satisfaction, the company can perform an analysis on “Voice of employee”.

Voice of employee: Engage employees, reduce turnover, and increase productivity. Use AI to evaluate employee surveys or analyze Glassdoor reviews, emails, Slack messages, and more (without feeling like Big Brother). Sentiment analysis software allows the company to analyze employee opinions subjectively, with no human input.

Similarly, improve product quality, the company apply sentiment analysis on products.

Product Analysis: Sentiment analysis is the automated process of understanding the sentiment or opinion of a review given for a product. Machine learning technology can provide insights by automatically analyzing product reviews and separating them into tags: Positive, Neutral, Negative. By using sentiment analysis to structure product reviews easy to understand if customers like or dislike the products.

Business goals: Improve product quality, reduce employee retention(and keep employees happy), and keeping customers happy.

Potential data sources: Product (product reviews), Employee (Glassdoor reviews, slacks, emails, etc), Customer (customer reviews, and customer support ratings)"
S. A. as decision support in employee recruitment,1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"Employee recruitment activities become important in a company to support its business activities and productivity. But these companies often get employees who do not fit the specified criteria because the company does not have fixed standards. sentiment analysis that will be used as decision Support in employee recruitment.

This study used data taken from the writing or essay of prospective new employees for further analysis using sentiment analysis. Sentiment Analysis was a way to extract one's feelings, opinions and habits from an article. Sentiment analysis could be used as an alternative psychological assessment of someone from writing activities."
Film Production - Script Writing,1,Jack Russo,Jack Russo,"Not that I would ever condone a studio write a film script this way, but it seems possible to me a film studio could use sentiment analysis on a corpora of film scripts mapped to their revenue.  In this manor a studio could identify what themes, characters, actions generated the most revenue. 

Dear Hollywood,

Don't actually do this."
Film Production - Script Writing,2,Murat Akyildirim,Jack Russo,"I am not sure about a film script, but I heard there are content writing systems out there, that applies sentiment analysis based on certain topic and creates web articles to enhance SEO. "
Film Production - Script Writing,2,Zachary Alexander,Jack Russo,"Hey Jack -- yes, definitely agree that I hope Hollywood doesn't actually try to do this, but you are right that the technology is now available to make this happen. Similar to Murat's point, I've been hearing a lot recently that news organizations are starting to automate article writing for very straightforward pieces (such as weather or updates on sports scores) to save costs and time -- I can totally see software being developed at some point, or maybe it's already out there, that can begin to measure the severity of a particular event (based on user feedback or a trained model), and utilizing that to shift the tone of a piece of automated writing. It's a very interesting/scary emerging field (automated journalism), but something that I think sentiment analysis will start to play an increasingly greater role in the years to come. I could definitely see this emerge in ways that you are referring to in your piece around Hollywood and film scripts!"
Film Production - Script Writing,2,Sheryl Piechocki,Jack Russo,"I also read about news organizations utilizing automated article writing software.  I think the programs should be trained to write unbiased fact-based news stories.  A lot of ""news"" these days is really opinion or fake news or leans politically one way or the other.  Unbiased reporting of facts should be the goal of news organizations.  "
Film Production - Script Writing,2,Jeremy O'Brien,Jack Russo,"Indeed, the technology does exist...  Back in 2016, hundreds of Hollywood scripts were fed to a long short-term memory recurrent neural network by Ross Goodwin.  It spat out a script which a bunch of folks. including Oscar Sharp and Thomas Middleditch (of HBO's 'Silicon Valley' fame) actually shot.  Witness it in all its irreducible grandeur here...I give you, Sunspring!

TLDW; don't stop paying your Writer's Guild dues just yet... :)"
Sentiment Analysis of Employee Satisfaction,1,Mael Illien,Mael Illien,"The article provided below takes a look at sentiment analysis within a company by and discusses how ML is used to dissect employee survey, feedback and reviews. The idea is driven by the increasing cost of burnout borne by employers as productive hours decrease and by employee as health concerns become more of a problem. In order to remedy this and keep their employees engaged and happy, companies are turning to sentiment analysis in order to turn qualitative feedback into business insight. The topic mining algorithms, identify the main themes of the feedback or complaints and compute the sentiment score for each topic or category. This can easily be studied more precisely by looking at employee roles and seeing if there is a disconnect in morale between job functions.

While everyone has theories about how to boost productivity and morale, it is very valuable for companies to have data about their own staff. That way, managers are able to make data-driven decisions to remedy any brewing discontent in the company, reduce burnout and manage their image (Glassdoor reviews can be telling)."
Customer Satisfaction,1,Ken Popkin,Ken Popkin,"Prior to the rise of social media, companies had to rely on customers' calls to Customer Service to identify how customers were ""feeling"".  Since very few (if any) customers ever call to say how great things are the information obtained only helped to assess negative areas that could be improved, with no visibility into what was going good or great from the public's point of view. Also, identifying trends would have to be done manually by reading call scripts or listening to recordings - all in all a slow and painful way to try to identify a trend.

With social media channels serving up the data and the advances in applying machine learning to text, companies can now monitor both what's going well and what isn't going so well via this combination of data and technology.

For example, on the site unionmetrics.com they cite nine ways, using data from Twitter and Instagam, to engage sentiment analysis to monitor how a company is doing at achieving a business goal to improve company and/or brand awareness: 1. Monitor changes in brand reputation over time, 2. Track changes in opinion and mood over time, 3. Research customer opinion about your company and products, 4. Compare perception of your brand to your competitors, 5. Evaluate the qualitative success of a campaign, 6. Pinpoint key topics or posts driving sentiment up or down, 7. Identify important trends...,  8. Identify potential issues early..., 9. Assess the actual impact of a crisis.

Risks: Sentiment analysis is far from a completely accurate assessment approach though.  The book ""Sentiment Analysis and Opinion Mining"" cites a number of challenges to keep in mind: 1. Literal versus figurative meaning of words, 2. Neutral meaning of words, 3. Sarcasm, 4. Facts without sentiment words, and 5. Opinion spamming. "
Sentiment Analysis in Health Insurance,1,Amber Ferger,Amber Ferger,"Like many other industries, health insurance companies deal with calls from members on a daily basis. These calls contain a lot of valuable information about the patient's feelings towards (1) the insurance company, (2) their care, and (3) their general wellbeing. This information can (and is!) being analyzed and used to educate providers, make decisions about product offerings, provide better case management, and prevent unhappy customers before they occur. 

Educate Providers: By analyzing the sentiment of calls and linking to specific providers/facilities, executives can get a high-level view of the practitioners that are causing the most unhappy patients and take action to educate. 
Make Decisions about Products: Understanding the insurance packages that cause the most upset/confused members can help lead to better design of explanatory materials and simpler product offerings. 
Providing Better Case Management: Calls to insurance companies can often be from individuals with physical or emotional unhappiness. Identifying the sentiment of the members and notifying the case management department can help set up the individual with the help they need. 
Preventing Unhappy Customers: Analyzing the characteristics of past unhappy customers can help prevent repeat callers or new callers with similar conditions. Once a ""trigger"" (ex: high cost claim) is identified, insurance plans can reach out to the individual asking if they have any questions before the individual calls. 
Data primarily comes in the form of audio recordings of the calls. The sentiment can be analyzed directly from the converted text. In order to link the sentiment to a category, it can be supplemented with additional information about the member, including their current insurance offerings, demographic information, and claims data. This all-encompassing view can help insurance companies provide better service to the members that they have!"
Sentiment Analysis in Health Insurance,2,Ken Popkin,Amber Ferger,"This a good example, Amber.  One thing for the providers to keep in mind (and I'm sure they do) is that members calling in are usually calling to discuss what didn't go right, so the data will probably be skewed towards negative trends and behavior."
Sentiment Analysis in Health Insurance,2,Jack Russo,Amber Ferger,"As you mention, most of the corpora is derived from phone calls. This data has to be transcribed either manually or by a Neural Network. Do you see that as a limiting factor to this approach?"
Sentiment Analysis in Health Insurance,2,Amber Ferger,Amber Ferger,"This is a really great point, and I can definitely see it as a limiting factor! However, with the expansion of voice to text services, I think it is less of a burden than it was 10 or so years ago. "
Analysis of Tweets,1,Habib Khan,Habib Khan,"The following link gives a good example of how tweets can be used for insight analysis through creating word clouds, sentiment analysis and usage of natural language processing. Although this example doesn't show the extraction of tweets using API but it shows enough understanding of how texts can be used for analysis. In this example, analyst has shown how tweets were posted in specific hours by President Trump during the impeachment period. Wordcloud has also made to show the most frequently using words by President Trump along with the sentiments associated with it."
Sentiment Analysis on You Tube Videos,1,Subhalaxmi Rout,Subhalaxmi Rout,"I found this article from AnalyticSteps, this blog shows a very simple way to do sentiment analysis on YouTube video’s comments. The article shows creating and applying sentiment analysis using a machine learning algorithm on YouTube video’s comments. Based on sentiment analysis content creators can maintain their content quality, timing, subtitle, etc.

Domain under discussion?

The domain under discussion is social media.

What problem that sentiment analysis address?

With the help of YouTube sentiment analysis of comments, the user(content creator) can get to know about the community acceptance of its channel/video. 
What is the approach used?

First step is to extract the comments from YouTube.

Follow the below process:

Add the polarity score to the dataset
Data cleanup (remove space and stop words), add tokenization
Data split (train, test)
Apply model (fit train data into the model)
Confusion Matrix
Classification Report (accuracy, F1-score, precision)
Describe a different domain, if possible where the same approach might also be effective?

The same approach can be useful in other domains such as retail domain on product reviews, Social media (Twitter sentiment analysis). "
Twitter Sentiment Analysis for 2013 Colorado Flood,1,Elina Azrilyan,Elina Azrilyan,"The following article talks about using sentiment analysis for Twitter data related to a Flood in Colorado. Twitter data was collected during the 2013 Colorado Flood event. Data was cleaned up and most frequently used words identified as  well as bigrams. Network plot showing grouped terms found in the tweets was created. Then polarity values were plotted in a histogram, to highlight the overall sentiment (i.e. more positivity or negativity) toward the subject. The same approach could be used in other disaster response times to gather the overall sentiment related for instance to the current pandemic and the actions taken in response."
Chatbot for Mental Health,1,Sheryl Piechocki,Sheryl Piechocki,"The paper referenced below presents a chatbot that can be used for mental health.  The chatbot  would use a variety of techniques to determine the emotional state of the user, and would continuously monitor it, tailoring its responses as it learns.   The chatbot would provide counseling services and intervention techniques for the user.  The authors note there is a great demand for psychological services, but that there is a lack of experts.  In addition, costs of such services are high and therefore out of reach for many potential patients.  A chatbot service could provide the expertise at a reduced cost.  Health insurance companies could offer this service to their members to reduce costs for members, while increasing services and improving health."
Chatbot for Mental Health,2,Elina Azrilyan,Sheryl Piechocki,That is a very interesting idea if we really do have the technology to make that a reality. As society is working towards reducing the stigma related to mental illness - this could be a helpful tool. People who are unsure about talking to a therapist could try this as an option and get some ideas about what they need to focus on in the future to improve their mental health.
Sentiment Analysis on Amazon Ratings,1,Amber Ferger,Amber Ferger,"I found an interesting code-based article written by Mick Zhang titled Amazon Reviews using Sentiment Analysis. This was a really great overview of creating and applying a sentiment analysis algorithm to data that virtually everyone is familiar with -- product reviews. 

What is the business domain under discussion? The business domain under discussion is retail shopping. 

What is the problem that sentiment analysis addresses? Zhang mentions 2 business problems: (1) What products have low reviews and may be worse products? (2) What products have high reviews and may be better products?

By understanding the product landscape, Amazon can identify which items to drop from its catalog. Sentiment Analysis fits into this because it can help shed light on the population's feelings about purchased products. 

What is the approach used? 

Data Exploration & Cleansing: It's always a good idea to take a look at the data before diving into an in-depth analysis. The dataset has 30,000 records and includes mostly positive ratings. The author standardizes the product names, splits the data into stratified training and testing sets so as not to train the classifier on imbalanced data. 
Assign Labels: Since the dataset had no ""truth values"" for the sentiment, the author assigns sentiment (positive, neutral, negative) based on rating score. 
Extract Features: Bag of Words Strategy -- assign an id to each word in the text and count the number of times the word appears. Implement TFIDF to weight the words. 
Classifier: Multinomial Naive Bayes classifier is applied to the dataset to fit a model and predict on the data. 
Analysis: The classifier is good at predicting positive ratings, but not great at predicting negative ratings. This is because the dataset is heavily skewed towards products that are highly rated. Additional negative and neutrally rated product information is needed to create a better model. 
Is there a different domain where the same approach might also be effective? I could see this type of method being used in any industry that allows users to purchase goods or services and then review them. For example, one could look at the ratings for attractions on trip advisor and do a similar analysis. "
Sentiment Analysis on Reddit News Headlines,1,Vijaya Cherukuri,Vijaya Cherukuri,"In the below article they are trying to do sentiment analysis on Reddit news headlines. By using sentiment analysis we can predict if a headline is either positive or negative.The dataset has 35% Negative news, 22 % Positive news and 43 % Neutral news.

There needs to be lot of improvement on the architecture of the code and modeling. The confusion matrices are showing roughly half of the positive headlines are being misclassified, so there's a lot more work to be done. Also, There will be lot of insight in the dataset once we consider subreddits for sentiment, like stocks, companies, products, etc"
Sentiment Analysis on Reddit News Headlines,2,Amber Ferger,Vijaya Cherukuri,This is really interesting - I wouldn't have thought to do an analysis on Reddit headlines. I think this could be very helpful in analyzing the content of specific subreddits to gage the general sentiment of the group's postings. It would also be very interesting to apply topic modeling in addition to sentiment analysis to see how the population's general feelings towards certain issues change over time. 
Sentiment Analysis on Reddit News Headlines,2,Mael Illien,Vijaya Cherukuri,"While the news headlines may have a particular sentiment, I agree that there is a lot of sentiment not extracted by not diving into the actual content of the news articles, and even more so in the comments. This is valuable information if we wanted to assign a higher level sentiment score for individual subreddits.  "
Sentiment Analysis on Reddit News Headlines,2,Habib Khan,Vijaya Cherukuri,You are right. Sentiment analysis comes quite handy in almost every field. Thanks for sharing. 
Cell Phone Preferences,1,Mikhail Kollontai,Mikhail Kollontai,"A student from Oklahoma State University conducted a study with the goal of identifying features of Samsung/Apple phones that might drive consumers in their decisions between the two (http://www.scsug.org/wp-content/uploads/2017/10/rn13.pdf) . To do so she scraped reviews of the phones and analyzed them for recurring points being brought up with either positive or negative sentiment with respect to certain features. This sort of sentiment analysis can be used to inform future design decisions, marketing schemes. and cost-based decisions. "
Cell Phone Preferences,2,Vijaya Cherukuri,Mikhail Kollontai,"Hi Mikhail, Nice information. Very good example to show positive and negative sentiment for Phones. It would have been great if we have the dataset and the code available :)"
Cell Phone Preferences,2,Mikhail Kollontai,Mikhail Kollontai,If you can track her down on LinkedIn or something I'm sure she'd be happy to share!
Sentiment Analysis for Stock Trading,1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"Tayloe Draughon shared in his blog the source code explain in his blog  the Twitter social sentiment analysis  from SMA that he used to to see if he could revitalize an underperforming stock trading algo. he said that It did result in a significant improvement.
The test showed some indication that it could help but wasn't nearly long enough or a deep dive. 
Here is the source code "
Sentiment Analysis of Financial News,1,Mael Illien,Mael Illien,"The article referenced below uses sentiment analysis of financial news to devise an algorithmic trading strategy. Exploiting what is being written about a particular stock and leveraging that information to make buy or sell decisions can be very valuable. The author uses the VADER sentiment analysis model built into NLTK to compute an overall sentiment score for a day and makes a trading decision if there are changes in sentiment of more than 0.5. The results are not very satisfactory as the strategy loses money. In fact, by buying the hype instead of selling it, the author is doing the opposite of the conventional wisdom of “selling the (good) news”

Many firms use NLP approaches to try to get an edge not just from news but also from earnings transcripts, speech transcripts from heads of central banks etc..."
Sentiment Analysis of Financial News,2,Murat Akyildirim,Mael Illien,Thanks for sharing. I guess setting up the perception of a publicly traded firm's position is becoming more important every day. There are also many articles on predicting stock market based on Donald Trump's tweets. All of his tweets are being archived here:  http://www.trumptwitterarchive.com/archive or can be connected via twitter api(free version has limiations on tweets per load). 
Classifying IMDB Movie Reviews,1,Priya Shaji,Priya Shaji,"IMDb lets users rate movies on a scale from 1 to 10. To label these reviews the curator of the data labeled anything with ≤ 4 stars as negative and anything with ≥ 7 stars as positive. Reviews with 5 or 6 stars were left out.

Dataset used has 50,000 movie reviews taken from IMDb. 

The data is split evenly with 25k reviews intended for training and 25k for testing classifier. Moreover, each set has 12.5k positive and 12.5k negative reviews.

Same approach can be used in many different domains, like food review, product review etc."
Classifying IMDB Movie Reviews,2,Vijaya Cherukuri,Priya Shaji,"Hi Priya,Good information. Thanks for sharing.

Here is another article which is helpful in Improving a Movie Review Sentiment Classifier"
IBM Watson Tone Analyzer,1,Ken Popkin,Ken Popkin,"IBM Watson's suite of products includes a Tone Analyzer tool that, ""uses linguistic analysis to detect joy, fear, sadness, anger, analytical, confident and tentative tones found in text.  IBM markets this product as a means to evaluate a company's draft content (marketing, promotions, internal memos, etc...) to assess if the overall tone of the content aligns with the message the company desires to communicate.  It accepts content from a number of sources ranging from Tweets to emails to custom text.


Tone Analyzer appears straightforward to use; enter your content, press the ""Analyze"" button, and the results are displayed.  This approach enables the tool to cross any number of industries and business domains. 

Click the link and give it a try."
IBM Watson Tone Analyzer,2,Mikhail Kollontai,Ken Popkin,"Ken, this is very cool. I've been guilty of letting Watson's Jeopardy success blind me to the other work they are doing but I know there's much more to that program. I think an interesting aspect of this is how well it can identify sarcasm, which has become more and more a part of discourse with the emergence of social media."
IBM Watson Tone Analyzer,2,Abdellah Ait Elmouden,Ken Popkin,The fact that analyzing tone of written text is difficult and perhaps inaccurate even for humans. Everyone types differently and sarcasm or aggression are usually understood with heavy context. But it's a cool project.
Spotify Sentiment Analysis,1,Jit Seneviratne,Jit Seneviratne,"Here's a cool article about an app which lets Spotify users determine the sentiment of the lyrics to songs in their playlists (https://towardsdatascience.com/spotify-sentiment-analysis-8d48b0a492f2). The article says that there sometimes is a disconnect between the valence of a track (how euphoric or upbeat the song sounds) and the actual lyrics. To address this, the writer created sentiment scores for the songs based on the lyrics. This could be applied to online book purchases, poems or any other creative content where a significant amount of text is present."
Sentiment Analysis on Reviews,1,Murat Akyildirim,Murat Akyildirim,"Business Domain: We work for an Hotel Chain, which has different acquisition channels including Social Media. And in Social Media naturally users are leaving comments. (positive or negative)

Business Goal: Analyze the social media reviews and define next steps on marketing and business challenges.

Approach Used: The reviews are collected as a serial number, a unique identifier and text that is customer review. We would follow the below process

1-      Identify Topics and Sub Topics

2-      Build Taxonomy

3-      Map Customer Reviews to Topics

4-      Map Customer Reviews to Sentiment

In terms of identifying topics we can look at Term Frequency and Inverse Document Frequency or LDA. For Building Taxonomy we first build the topic hierarchy and then the keywords. We further map the customer reviews to topic.

This can be done with Python NLTK package.

Another use case would be, a brand awareness or advertising in Amazon or other third party integrations (such as Power Reviews, or Price Spider). These platforms allow users to leave comments and feedback on products and servies. Same approach can be used to gain insights and further alter the marketing campaigns , tone and creative accordingly."
Customer Satisfaction - textblob,1,Jack Russo,Jack Russo,"The Text Blob Python Package allows you to gauge customer sentiment out of the box, no model training required!

Check out this medium article."
Customer Satisfaction - textblob,2,Ken Popkin,Jack Russo,"Great example of what this discussion was looking for, Jack!  I'm going to keep this in mind for any text analysis my team does for the Final Project and future NLP work beyond this course."
Customer Satisfaction - textblob,2,Subhalaxmi Rout,Jack Russo,"Interesting article Jack! Using TextBlob and VADER package calculate polarity score and sentiment score (positive, negative, neutral) made easy."
"Shakespearean Plays using W2V and t-SNE
",1,Jit Seneviratne,Jit Seneviratne,"Here's  a short blog post on a project I did comparing Shakespearean Comedies and Tragedies. The Tragedies seem to have a stronger gravitational center in a 2d plane. Naturally, the corpora may not have enough text to make a definite statement about the closeness of words. However, we do know that Tragedies generally have a lot more text spoken by the central antagonist."
"Real-time social media sentiment analysis for brand improvements
",1,Habib Khan,Habib Khan,"Reviews and customer's feedback are the significant factors nowadays due to high competition and easy access of information. I think text mining comes very handy to analyze consumer's mindset on the company's products that would help them to improve their business operations, etc. I believe platforms such as twitter, instagram and facebook are popular sources of information on the products and they can easily can be accessible and filter out the texts. Usage of text mining techniques such as wordcloud, sentiment analysis, etc can be very useful to identify the issues in the products. Automation of data can make it real-time and flow of data would be constant. I found this article quite useful."
Word Frequency in Text Over Time,1,Elina Azrilyan,Elina Azrilyan,"On the webpage below you can see some examples of word frequency in texts over time. The link is providing some examples of Text and Language Processing tools available. There are several interesting graphs, for example of word frequency between “VHS” and “Betamax” between 1960 and 2000s. You can “discover when the pen became mightier than the sword.” by looking at the graph of those word’s frequency between 1700 and 2000. 

https://www.wolfram.com/language/11/text-and-language-processing/word-frequency-over-time.html?product=language"
Word Frequency in Text Over Time,2,Habib Khan,Elina Azrilyan,That was nice example. Thanks for sharing
Global Network of startup mergers and acquistions,1,Subhalaxmi Rout,Subhalaxmi Rout,"The Network analysis is about mergers and acquisitions (M&A), which is an integral aspect of the start-up ecosystem.
What visualization shows?

The network analysis graph shows the major Hubs and countries with most of the start-ups' Mergers & Acquisitions. Data collection Complete list of acquisitions that occurred around the world from January 2015 to September 2016 was used for the analysis.

Do you think that this visualization is accurate and effective? 

Yes, this visualization is mostly accurate because the network graph shows the USA, Great Britain, Canada has the most inbound international M&A deal flow. However, in regular international trade, America’s biggest trading partners are the European Union, Canada, China, Mexico, Japan, South Korea, and Brazil. The network analysis graph shows a very sparse line of trade between the USA to South Korea, Brazil, Mexico.

How might you improve upon it? 

The data collected from January 2015 to September 2016 (about 20 months), if the analysis would have 5 or 10 years of data then we may see some more interesting M&A trade connections between the countries."
Warming the World,1,Vijaya Cherukuri,Vijaya Cherukuri,"Now a days we see the temperatures are increasing gradually every year. There are multiple reasons for it like Earths orbit, Sun's temperature, Human industry emits CO2, Deforestation, Ozone pollution, Aerosol pollution etc.

There will be lot of data elements involved with this and inturn needs huge amount of data. It will be very hard to analyze without proper visualization.

The visualization in the below link provides detailed information of different parameters impacting the increasing temperatures."
Bus Bunching,1,Priya Shaji,Priya Shaji,"A wonderful example of a complex data set boiled down into what that looks and feels like a game. In this visualization, the folks at Setosa are showing how ""bus bunching"" happens, i.e. when a bus gets delayed and later causes multiple buses to arrive at a single stop at the same time.


Telling this story in numbers alone would be pretty difficult, but instead, they turn it into an interactive game.

While the buses rotate along a route, we can click and hold a button (Bus 1 or Bus 2 ) to delay a bus. Then, all we have to do is watch to see how even a short delay causes the buses to bunch together after a time."
Song Lyrics,1,Mikhail Kollontai,Mikhail Kollontai,"The visualization above from Reddit user u/PDBFishsticks is a visualization over time in that each edge in the network corresponds to a word that comes after the other in the lyrics of 99 bottles of beer on the wall. By following the paths you can see the obvious pattern within the song. Obviously this is a very simple song, but it's still interesting to see the pattern, with the edges between ""Bottles"", ""of"" and ""Beer"" coming twice as thick since they are repeated in ""x bottles of beer on the wall, x bottles of beer"". 

I like the addition of the singular bubble for ""bottle"" for when the count drops to 1 bottle. In order to make it clearer though I may change the color of the number nodes to be different from the rest of the words. ""Bottle"" blends in with the numbers as it is now. I think putting together similar networks for songs with a lot of repeated lyrics could be interesting (I have seen it before)."
Song Lyrics,2,Habib Khan,Mikhail Kollontai,Nice find! It is really interesting to see the distribution and observe the pattern here!
Stock Market Data in 30 Seconds,1,Abdellah Ait Elmouden,Abdellah Ait Elmouden,"This data visualization shows Last week's stock market volatility in 30 seconds.

Data was gathered from Google and Yahoo Finance, and visualization done in Javascript with D3. Web version is here:"
Stock Market Data in 30 Seconds,2,Mikhail Kollontai,Abdellah Ait Elmouden,I've been really loving the recent obsession with new ways to present data and this one is so eye-catching. Obviously generalizes a lot of the data but for a big picture presentation it is quite great. 
Stock Market Data in 30 Seconds,2,Vijaya Cherukuri,Abdellah Ait Elmouden,Great example Abdellah. Visualization is key in representing the data. This example clearly details representing large volume of data.
Stock Market Data in 30 Seconds,2,Mael Illien,Abdellah Ait Elmouden,"This is great. It is interesting to see how once some companies leave the swarm in either direction , they tend to remain in that territory (positive or negative returns), especially the outliers,  which makes sense due to momentum.  "
Netherlands Train Network Visualization,1,Mael Illien,Mael Illien,"This pretty amazing visualization shows the network of train travel in the western Netherlands. When trains move from an origin to a destination, the edges between these two points are distorted to reflect this connectivity and as less trains use the routes, the nodes settle back to their geographical location. While visually very pleasing, it is hard to extract information at first glance, especially when the geographical distortion is applied. Without being able to refer to individual trains or routes, it is not obvious how to use this visual tool to make actual improvements to the network.  However, if we use the scroll bar to slow down the speed we can see more clearly how connected some of these network nodes are. This is useful information for deciding future infrastructure development, evaluating demand and usage, etc. This would be a useful visualization and analysis to have for any subway/rail system in order to identify bottlenecks, isolated stations and stations where trains get held up too long."
Netherlands Train Network Visualization,2,Vijaya Cherukuri,Mael Illien,"Hi Mael, 

Good information. Took some time for me to understand but really helpful in analyzing the train network. "
Netherlands Train Network Visualization,2,Subhalaxmi Rout,Mael Illien,Nice post!  It is really interesting to see the centrality measures of the nodes.
Netherlands Train Network Visualization,2,Abdellah Ait Elmouden,Mael Illien,That's a really cool way to visualize periodic behavior.
Shiny App - Word Frequency Analysis Over Time,1,Jack Russo,Jack Russo,Check out this Shiny App that measures word frequency over time. The subreddit from the 2015 NFL draft is used as the base data.
