{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prepare\" data-toc-modified-id=\"Prepare-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prepare</a></span></li><li><span><a href=\"#Base-Metrics\" data-toc-modified-id=\"Base-Metrics-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Base Metrics</a></span></li><li><span><a href=\"#Clean-the-data\" data-toc-modified-id=\"Clean-the-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Clean the data</a></span></li><li><span><a href=\"#Sentiment-Analysis\" data-toc-modified-id=\"Sentiment-Analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sentiment Analysis</a></span></li><li><span><a href=\"#Cosine-Similarity\" data-toc-modified-id=\"Cosine-Similarity-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Cosine Similarity</a></span></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusions</a></span></li><li><span><a href=\"#Credits\" data-toc-modified-id=\"Credits-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Credits</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the DATA620 classes' discussions as data and produces base metrics, a sentiment analysis, and a cosine similarity that allows statements to be made about the general nature of this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Discussions data and prepare it for computing metrics, sentiment analysis, and cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thread_Name</th>\n",
       "      <th>Initial_Post_or_Comment</th>\n",
       "      <th>Author</th>\n",
       "      <th>Response_To</th>\n",
       "      <th>Thread_Content</th>\n",
       "      <th>Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uber API Restrictions Controversy</td>\n",
       "      <td>1</td>\n",
       "      <td>Simon Ustoyev</td>\n",
       "      <td>Simon Ustoyev</td>\n",
       "      <td>I found 2 articles (one siting the other), whi...</td>\n",
       "      <td>Uber API Restrictions Controversy I found 2 ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Thread_Name  Initial_Post_or_Comment         Author  \\\n",
       "0  Uber API Restrictions Controversy                        1  Simon Ustoyev   \n",
       "\n",
       "     Response_To                                     Thread_Content  \\\n",
       "0  Simon Ustoyev  I found 2 articles (one siting the other), whi...   \n",
       "\n",
       "                                            Combined  \n",
       "0  Uber API Restrictions Controversy I found 2 ar...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the Discussions data\n",
    "#indata =pd.read_csv(\"DS620_Discussion_Board_Data.csv\")\n",
    "indata = pd.read_csv('final_thread_data_all.csv')\n",
    "\n",
    "#Combine the discussions' titles with the discussions' content\n",
    "indata['Combined'] = indata[['Thread_Name', 'Thread_Content']].apply(lambda x: ' '.join(x), axis=1)\n",
    "indata = indata.drop(indata.columns[0], 1)\n",
    "\n",
    "indata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe of the columns needed for text analysis\n",
    "indata2 = indata.iloc[:,[2,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdellah Ait Elmouden</td>\n",
       "      <td>Google's monetization of Google Maps API Last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amber Ferger</td>\n",
       "      <td>Flight Prices - Skyscanner Access to travel in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Author                                           Combined\n",
       "0  Abdellah Ait Elmouden  Google's monetization of Google Maps API Last ...\n",
       "1           Amber Ferger  Flight Prices - Skyscanner Access to travel in..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This dataframe has a row for each class member (author) that wrote at least one discussion post, or commented on an \n",
    "#existing post. There is one row per author, so an author who wrote 10 discussions and 10 replies has a single row\n",
    "#that combines all their writing.\n",
    "data = pd.DataFrame(indata2.groupby('Author').agg({'Combined':lambda x: ', '.join(x)}).reset_index())\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a base metrics dataframe that captures some basic statistics (number of words, number of characters, average\n",
    "word length, and number of stopwords) about each author's posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for each author, sorted in descending order by number of words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stop_words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amber Ferger</td>\n",
       "      <td>4081</td>\n",
       "      <td>26115</td>\n",
       "      <td>5.318138</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zachary Alexander</td>\n",
       "      <td>3153</td>\n",
       "      <td>19808</td>\n",
       "      <td>5.196306</td>\n",
       "      <td>1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Murat Akyildirim</td>\n",
       "      <td>3054</td>\n",
       "      <td>20217</td>\n",
       "      <td>5.541544</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ken Popkin</td>\n",
       "      <td>2774</td>\n",
       "      <td>16308</td>\n",
       "      <td>4.995888</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subhalaxmi Rout</td>\n",
       "      <td>2741</td>\n",
       "      <td>19485</td>\n",
       "      <td>5.911681</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Author  num_words  num_chars  avg_word_length  stop_words_count\n",
       "0       Amber Ferger       4081      26115         5.318138              1557\n",
       "1  Zachary Alexander       3153      19808         5.196306              1266\n",
       "2   Murat Akyildirim       3054      20217         5.541544              1040\n",
       "3         Ken Popkin       2774      16308         4.995888               961\n",
       "4    Subhalaxmi Rout       2741      19485         5.911681               884"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_word_length(combined):\n",
    "    words = combined.split()\n",
    "    avg = sum(len(word) for word in words)/len(words)\n",
    "    return avg\n",
    "\n",
    "def stop_words_count(combined):\n",
    "    count = 0\n",
    "    words = combined.split()\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    for w in words:\n",
    "        if w in stop_words:\n",
    "            count = count + 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "base_metrics = data\n",
    "\n",
    "base_metrics = base_metrics.drop(['Combined'], axis=1)\n",
    "\n",
    "base_metrics['num_words'] = data.Combined.apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "base_metrics['num_chars'] = data.Combined.str.len()\n",
    "\n",
    "base_metrics['avg_word_length'] = data.Combined.apply(lambda x: avg_word_length(x)) \n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "base_metrics['stop_words_count'] = data.Combined.apply(lambda x: stop_words_count(x))\n",
    "\n",
    "base_metrics = base_metrics.sort_values(['num_words'], ascending=False).reset_index(drop=True) \n",
    "\n",
    "print('Metrics for each author, sorted in descending order by number of words')\n",
    "base_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stop_words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jeremy OBrien</td>\n",
       "      <td>1081</td>\n",
       "      <td>7047</td>\n",
       "      <td>5.579343</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Vanita Thompson</td>\n",
       "      <td>981</td>\n",
       "      <td>6818</td>\n",
       "      <td>5.777888</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jack Russo</td>\n",
       "      <td>921</td>\n",
       "      <td>5817</td>\n",
       "      <td>5.132135</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Willie Smalls</td>\n",
       "      <td>879</td>\n",
       "      <td>5078</td>\n",
       "      <td>5.014388</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mia Chen</td>\n",
       "      <td>676</td>\n",
       "      <td>4606</td>\n",
       "      <td>5.718248</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Author  num_words  num_chars  avg_word_length  stop_words_count\n",
       "17    Jeremy OBrien       1081       7047         5.579343               345\n",
       "18  Vanita Thompson        981       6818         5.777888               331\n",
       "19       Jack Russo        921       5817         5.132135               349\n",
       "20    Willie Smalls        879       5078         5.014388               282\n",
       "21         Mia Chen        676       4606         5.718248               235"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_metrics.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<I> Base Metric Conclusions: </I>\n",
    "1. The range in number of words is from 676 to 4081.  This indicates a significant delta in the participation rate for discussions across the class.\n",
    "\n",
    "2. It's interesting that the average word length doesn't vary much among the class with everyone in a range of 4 to 6 characters.\n",
    "\n",
    "3. The stop words count appears highly correlated to the number of words, which makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we clean the data by moving to lowercase, removing stop words & the most common words, removing URL's, and removing punctuation.  We also add word and sentence tokenized columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'to', 'and', 'of', 'a', 'in', 'is', 'for', 'that', 'this', 'i', 'on', 'be', 'with', 'can', 'are', 'as', 'data']\n"
     ]
    }
   ],
   "source": [
    "#Identify the most frequently occurring words across all the authors posts, including stop words\n",
    "everyones_text = ''\n",
    "for text in data.Combined:\n",
    "    everyones_text = everyones_text + ' ' + text.lower()\n",
    "\n",
    "words = everyones_text.split()\n",
    "words = Counter(words)\n",
    "common_words = words.most_common(18)\n",
    "common_words = [entries[0] for entries in common_words]\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions used below to clean data\n",
    "def remove_stop_words(inclean):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = inclean.split()\n",
    "    outclean = ''\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            outclean = outclean + ' ' + word\n",
    "    \n",
    "    return outclean\n",
    "    \n",
    "def remove_common_words(inclean):\n",
    "    words = inclean.split()\n",
    "    outclean = ''\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in common_words:\n",
    "            outclean = outclean + ' ' + word\n",
    "    \n",
    "    return outclean\n",
    "\n",
    "def remove_url(inclean):\n",
    "    outclean = re.sub(r\"http\\S+\", \"\", inclean) \n",
    "    \n",
    "    return outclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run each author's text thru the cleaning steps below, then add the cleaned data as a new column (combined_clean) to the\n",
    "#data dataframe, along with word and sentence tokenized columns.\n",
    "cleandf = data\n",
    "\n",
    "clean_data_list = []\n",
    "word_token_list = []\n",
    "sentence_token_list = []\n",
    "\n",
    "for text in cleandf.Combined:\n",
    "    clean = text.lower()     #lower case\n",
    "    \n",
    "    clean = remove_stop_words(clean) #remove stop words\n",
    "    \n",
    "    clean = remove_common_words(clean) #remove the most common words\n",
    "    \n",
    "    clean = remove_url(clean)\n",
    "    \n",
    "    clean_data_list.append(clean)\n",
    "    \n",
    "    #remove punctuation and tokenize by word\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_tokens = tokenizer.tokenize(clean)\n",
    "    word_token_list.append(word_tokens)\n",
    "    \n",
    "    #remove punctuation and tokenize by sentence\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    sentence_tokens = sent_tokenize(clean)\n",
    "    sentence_tokens = [s.translate(translator) for s in sentence_tokens] \n",
    "    sentence_token_list.append(sentence_tokens)\n",
    "    \n",
    "cleandf['combined_clean'] = clean_data_list\n",
    "cleandf['word_tokens'] = word_token_list\n",
    "cleandf['sentence_tokens'] = sentence_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Combined</th>\n",
       "      <th>combined_clean</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sentence_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdellah Ait Elmouden</td>\n",
       "      <td>Google's monetization of Google Maps API Last ...</td>\n",
       "      <td>google's monetization google maps api last ye...</td>\n",
       "      <td>[google, s, monetization, google, maps, api, l...</td>\n",
       "      <td>[ googles monetization google maps api last ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amber Ferger</td>\n",
       "      <td>Flight Prices - Skyscanner Access to travel in...</td>\n",
       "      <td>flight prices - skyscanner access travel info...</td>\n",
       "      <td>[flight, prices, skyscanner, access, travel, i...</td>\n",
       "      <td>[ flight prices  skyscanner access travel info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elina Azrilyan</td>\n",
       "      <td>Managing impacts of data changes The following...</td>\n",
       "      <td>managing impacts changes following article di...</td>\n",
       "      <td>[managing, impacts, changes, following, articl...</td>\n",
       "      <td>[ managing impacts changes following article d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Author                                           Combined  \\\n",
       "0  Abdellah Ait Elmouden  Google's monetization of Google Maps API Last ...   \n",
       "1           Amber Ferger  Flight Prices - Skyscanner Access to travel in...   \n",
       "2         Elina Azrilyan  Managing impacts of data changes The following...   \n",
       "\n",
       "                                      combined_clean  \\\n",
       "0   google's monetization google maps api last ye...   \n",
       "1   flight prices - skyscanner access travel info...   \n",
       "2   managing impacts changes following article di...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [google, s, monetization, google, maps, api, l...   \n",
       "1  [flight, prices, skyscanner, access, travel, i...   \n",
       "2  [managing, impacts, changes, following, articl...   \n",
       "\n",
       "                                     sentence_tokens  \n",
       "0  [ googles monetization google maps api last ye...  \n",
       "1  [ flight prices  skyscanner access travel info...  \n",
       "2  [ managing impacts changes following article d...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleandf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the sentiment of each author's discussions and add the sentiment as a column in the cleandf dataframe. <br> <br>\n",
    "\n",
    "From [Analytics Vidyha](https://www.analyticsvidhya.com/blog/2018/02/natural-language-processing-for-beginners-using-textblob/#:~:text=The%20sentiment%20function%20of%20textblob,1%20means%20a%20negative%20statement.&text=Subjectivity%20is%20also%20a%20float,of%20%5B0%2C1%5D.) the sentiment function of textblob returns two properties, polarity, and subjectivity.  Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement. Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Combined</th>\n",
       "      <th>combined_clean</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdellah Ait Elmouden</td>\n",
       "      <td>Google's monetization of Google Maps API Last ...</td>\n",
       "      <td>google's monetization google maps api last ye...</td>\n",
       "      <td>[google, s, monetization, google, maps, api, l...</td>\n",
       "      <td>[ googles monetization google maps api last ye...</td>\n",
       "      <td>(0.13742170949617766, 0.4622282858984986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amber Ferger</td>\n",
       "      <td>Flight Prices - Skyscanner Access to travel in...</td>\n",
       "      <td>flight prices - skyscanner access travel info...</td>\n",
       "      <td>[flight, prices, skyscanner, access, travel, i...</td>\n",
       "      <td>[ flight prices  skyscanner access travel info...</td>\n",
       "      <td>(0.12432405106832042, 0.4866279804245418)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Author                                           Combined  \\\n",
       "0  Abdellah Ait Elmouden  Google's monetization of Google Maps API Last ...   \n",
       "1           Amber Ferger  Flight Prices - Skyscanner Access to travel in...   \n",
       "\n",
       "                                      combined_clean  \\\n",
       "0   google's monetization google maps api last ye...   \n",
       "1   flight prices - skyscanner access travel info...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [google, s, monetization, google, maps, api, l...   \n",
       "1  [flight, prices, skyscanner, access, travel, i...   \n",
       "\n",
       "                                     sentence_tokens  \\\n",
       "0  [ googles monetization google maps api last ye...   \n",
       "1  [ flight prices  skyscanner access travel info...   \n",
       "\n",
       "                                   sentiment  \n",
       "0  (0.13742170949617766, 0.4622282858984986)  \n",
       "1  (0.12432405106832042, 0.4866279804245418)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_list = []\n",
    "\n",
    "for text in cleandf.combined_clean:\n",
    "    sentiment = TextBlob(text).sentiment\n",
    "    sentiment_list.append(sentiment)\n",
    "\n",
    "cleandf['sentiment'] = sentiment_list\n",
    "cleandf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity values are [0.062194495980210276, 0.07719893742621015, 0.0879208754208754, 0.09643494793494788, 0.09831326249508068, 0.10603092614456244, 0.10856621057513913, 0.12194988973290863, 0.12432405106832042, 0.12991895471347525, 0.13332457225314367, 0.13742170949617766, 0.14432491837664255, 0.14433928571428575, 0.1472027914614121, 0.15431015478985963, 0.15741275899672846, 0.18443309870790792, 0.18936161633326581, 0.19679018445322793, 0.20848260934467835, 0.20877059448488017]\n",
      "\n",
      "Subjectivity values are [0.38159389816532663, 0.40339039748130656, 0.42469916556873083, 0.4251010101010099, 0.4305732901534429, 0.4392274788703359, 0.4415184847081402, 0.44824730252565304, 0.45109799890621805, 0.45485559678416854, 0.4592513775532642, 0.4622282858984986, 0.46330764151797366, 0.469304152637486, 0.4751523526077097, 0.48083420411006605, 0.4810658533385805, 0.4836786996786997, 0.4853824746681892, 0.4866279804245418, 0.4873755038065384, 0.49367320974191214]\n"
     ]
    }
   ],
   "source": [
    "#Below is the range of sentiment scores for polarity and for subjectivity\n",
    "sentiment = cleandf.sentiment\n",
    "sentiment = list(sentiment)\n",
    "\n",
    "polarity = sorted([i[0] for i in sentiment])\n",
    "print(f'Polarity values are {polarity}')\n",
    "\n",
    "print()\n",
    "subjectivity = sorted([i[1] for i in sentiment])\n",
    "print(f'Subjectivity values are {subjectivity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<I> Sentiment Analysis Conclusions: </I> <br>\n",
    "The subject of sentiment is probably not very relevant for this project as the nature of our class and the Discussion topics are not political in nature or emotional topics.  But, for the sake of practice we included sentiment in our analysis. <br>\n",
    "\n",
    "Reviewing the polarity values above, it's safe to state that the discussions are generally positive as the range is 0.38 to 0.49 on a scale of -1 to 1 (negative to positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare each author's discussions to all the other authors and output a dataframe of the comparisons\n",
    "based on the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main</th>\n",
       "      <th>Abdellah Ait Elmouden</th>\n",
       "      <th>Amber Ferger</th>\n",
       "      <th>Elina Azrilyan</th>\n",
       "      <th>Habib Khan</th>\n",
       "      <th>Jack Russo</th>\n",
       "      <th>Jagdish Chhabria</th>\n",
       "      <th>Jeremy OBrien</th>\n",
       "      <th>Jithendra Seneviratne</th>\n",
       "      <th>Ken Popkin</th>\n",
       "      <th>Mael Illien</th>\n",
       "      <th>Mia Chen</th>\n",
       "      <th>Mikhail Kollontai</th>\n",
       "      <th>Murat Akyildirim</th>\n",
       "      <th>Priya Shaji</th>\n",
       "      <th>Sheryl Piechocki</th>\n",
       "      <th>Simon Ustoyev</th>\n",
       "      <th>Steven Ellingson</th>\n",
       "      <th>Subhalaxmi Rout</th>\n",
       "      <th>Vanita Thompson</th>\n",
       "      <th>Vijaya Cherukuri</th>\n",
       "      <th>Willie Smalls</th>\n",
       "      <th>Zachary Alexander</th>\n",
       "      <th>max_author</th>\n",
       "      <th>max_cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdellah Ait Elmouden</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.28</td>\n",
       "      <td>Amber Ferger</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amber Ferger</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Subhalaxmi Rout</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    main  Abdellah Ait Elmouden  Amber Ferger  Elina Azrilyan  \\\n",
       "0  Abdellah Ait Elmouden                    1.0           0.3            0.21   \n",
       "1           Amber Ferger                    0.3           1.0            0.29   \n",
       "\n",
       "   Habib Khan  Jack Russo  Jagdish Chhabria  Jeremy OBrien  \\\n",
       "0        0.22        0.22              0.26           0.22   \n",
       "1        0.27        0.26              0.30           0.27   \n",
       "\n",
       "   Jithendra Seneviratne  Ken Popkin  Mael Illien  Mia Chen  \\\n",
       "0                   0.22        0.30         0.27      0.17   \n",
       "1                   0.29        0.35         0.34      0.22   \n",
       "\n",
       "   Mikhail Kollontai  Murat Akyildirim  Priya Shaji  Sheryl Piechocki  \\\n",
       "0               0.27              0.29         0.25              0.26   \n",
       "1               0.31              0.34         0.32              0.35   \n",
       "\n",
       "   Simon Ustoyev  Steven Ellingson  Subhalaxmi Rout  Vanita Thompson  \\\n",
       "0           0.23              0.22             0.29             0.23   \n",
       "1           0.30              0.28             0.37             0.27   \n",
       "\n",
       "   Vijaya Cherukuri  Willie Smalls  Zachary Alexander       max_author  \\\n",
       "0              0.25           0.16               0.28     Amber Ferger   \n",
       "1              0.32           0.21               0.34  Subhalaxmi Rout   \n",
       "\n",
       "   max_cosine  \n",
       "0        0.30  \n",
       "1        0.37  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindf = cleandf[['Author', 'word_tokens']]\n",
    "maindf = maindf.rename(columns={'Author':'author'})\n",
    "\n",
    "tempdf = maindf\n",
    "\n",
    "mcosine_list = []\n",
    "for mrow in maindf.values:\n",
    "    mauthor = mrow[0]\n",
    "    mtext = mrow[1]\n",
    "    \n",
    "    tcosine_list = []\n",
    "    maxauthor = ''\n",
    "    maxcosine = 0\n",
    "    tcosine_list.append(mauthor)\n",
    "    for trow in tempdf.values:\n",
    "        tauthor = trow[0]\n",
    "        ttext = trow[1]\n",
    "        \n",
    "        l1 = []\n",
    "        l2 = []\n",
    "        \n",
    "        mset = {w for w in mtext}  \n",
    "        tset = {w for w in ttext} \n",
    "        rvector = mset.union(tset)\n",
    "        for w in rvector: \n",
    "            if w in mset: \n",
    "                l1.append(1) \n",
    "            else:\n",
    "                l1.append(0) \n",
    "            \n",
    "            if w in tset:\n",
    "                l2.append(1) \n",
    "            else:\n",
    "                l2.append(0) \n",
    "\n",
    "        c = 0\n",
    "        # cosine formula  \n",
    "        for i in range(len(rvector)): \n",
    "                c+= l1[i]*l2[i] \n",
    "        cosine = round(c / float((sum(l1)*sum(l2))**0.5),2)\n",
    "        \n",
    "        #determine who's cosine is the highest (most similar to the author)\n",
    "        if (cosine != 1):\n",
    "            if (cosine > maxcosine):\n",
    "                maxauthor = tauthor\n",
    "                maxcosine = cosine\n",
    "        \n",
    "        tcosine_list.append(cosine)\n",
    "        \n",
    "    tcosine_list.append(maxauthor)\n",
    "    tcosine_list.append(maxcosine)\n",
    "    mcosine_list.append(tcosine_list)\n",
    "    \n",
    "class_list = list(cleandf.Author)\n",
    "authors_list = ['main'] + class_list + ['max_author'] + ['max_cosine']\n",
    "cosinedf = pd.DataFrame(data=mcosine_list, columns=authors_list)\n",
    "\n",
    "cosinedf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author1</th>\n",
       "      <th>author2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdellah Ait Elmouden</td>\n",
       "      <td>Amber Ferger</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amber Ferger</td>\n",
       "      <td>Subhalaxmi Rout</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elina Azrilyan</td>\n",
       "      <td>Sheryl Piechocki</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Habib Khan</td>\n",
       "      <td>Murat Akyildirim</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jack Russo</td>\n",
       "      <td>Amber Ferger</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author1           author2  weight\n",
       "0  Abdellah Ait Elmouden      Amber Ferger    0.30\n",
       "1           Amber Ferger   Subhalaxmi Rout    0.37\n",
       "2         Elina Azrilyan  Sheryl Piechocki    0.31\n",
       "3             Habib Khan  Murat Akyildirim    0.30\n",
       "4             Jack Russo      Amber Ferger    0.26"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe of each author, the author their discussions are most similar to, and the cosine similarity\n",
    "similarity = cosinedf[['main', 'max_author', 'max_cosine']]\n",
    "similarity.columns = ['author1', 'author2', 'weight']\n",
    "similarity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the graph\n",
    "node1 = list(similarity.author1)\n",
    "node2 = list(similarity.author2)\n",
    "edges = list(similarity.weight)\n",
    "\n",
    "g = nx.Graph()\n",
    "g.add_weighted_edges_from(zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics is using math to make decisions and statements about data drawn from a population.  In this study we have the rare statistical occurrence in which we can make statements about the entire population (our class).  To be respectful of privacy we chose not to call out anyone by name as we share the conclusions below... <br> <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We used this article from Analytics Vidyha titled [Ultimate Guide to Deal with Text Data](https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/) to identify base metrics to describe the data and cleaning recommendations to ensure our data is in a ready state for similarity analysis.\n",
    "<br><br>\n",
    "2. This article, [What is Text Similarity in NLP,](https://rxnlp.com/what-is-text-similarity-nlp/#.XxDDZihKg2w) proved helpful for understanding lexical similarity and it's application.\n",
    "<br><br>\n",
    "3. This [StackOverflow link](https://stackoverflow.com/questions/24399820/expression-to-remove-url-links-from-twitter-tweet/24399874) enabled a simple regex means to remove URL's.\n",
    "<br><br>\n",
    "4. This [geeksforgeeks.org link](https://www.geeksforgeeks.org/python-measure-similarity-between-two-sentences-using-cosine-similarity/) provided a means to calculate cosine similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
